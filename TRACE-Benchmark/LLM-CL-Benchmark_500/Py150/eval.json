[{"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> from os . path import join <EOL> from setuptools import setup , find_packages <EOL> from geokey . version import get_version <EOL> name = '<STR_LIT>' <EOL> version = get_version ( ) <EOL> repository = join ( '<STR_LIT>' , name ) <EOL> def get_install_requires ( ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> requirements = list ( ) <EOL> for line in open ( '<STR_LIT>' ) . readlines ( ) : <EOL> if line . startswith ( '<STR_LIT:#>' ) or line . startswith ( '<STR_LIT>' ) or line == '<STR_LIT>' : <EOL> continue <EOL> requirements . append ( line . rstrip ( ) ) <EOL> return requirements <EOL> setup ( <EOL> name = name , <EOL> version = version , <EOL> description = '<STR_LIT>' , <EOL>", "answer": "url = '<STR_LIT>' ,"}, {"prompt": "<s> from oslo_config import cfg <EOL> from oslo_utils import uuidutils <EOL> import webob <EOL> from nova . api . openstack . compute . legacy_v2 . contrib import server_groups <EOL> from nova . api . openstack . compute import server_groups as sg_v21 <EOL> from nova . api . openstack import extensions <EOL> from nova import context <EOL> from nova import quota <EOL> from nova import test <EOL> from nova . tests . unit . api . openstack import fakes <EOL> from nova . tests import uuidsentinel as uuids <EOL> CONF = cfg . CONF <EOL> class AttrDict ( dict ) : <EOL> def __getattr__ ( self , k ) : <EOL> return self [ k ] <EOL> def server_group_template ( ** kwargs ) : <EOL> sgroup = kwargs . copy ( ) <EOL> sgroup . setdefault ( '<STR_LIT:name>' , '<STR_LIT:test>' ) <EOL> return sgroup <EOL> def server_group_db ( sg ) : <EOL> attrs = sg . copy ( ) <EOL> if '<STR_LIT:id>' in attrs : <EOL> attrs [ '<STR_LIT>' ] = attrs . pop ( '<STR_LIT:id>' ) <EOL> if '<STR_LIT>' in attrs : <EOL> policies = attrs . pop ( '<STR_LIT>' ) <EOL> attrs [ '<STR_LIT>' ] = policies <EOL> else : <EOL> attrs [ '<STR_LIT>' ] = [ ] <EOL> if '<STR_LIT>' in attrs : <EOL> members = attrs . pop ( '<STR_LIT>' ) <EOL> attrs [ '<STR_LIT>' ] = members <EOL> else : <EOL> attrs [ '<STR_LIT>' ] = [ ] <EOL> if '<STR_LIT>' in attrs : <EOL> attrs [ '<STR_LIT>' ] = attrs . pop ( '<STR_LIT>' ) <EOL>", "answer": "else :"}, {"prompt": "<s> from __future__ import absolute_import <EOL> import os <EOL> import string <EOL> import random <EOL> from salttesting import skipIf <EOL> from salttesting . helpers import ( <EOL> destructiveTest , <EOL> ensure_in_syspath , <EOL> requires_system_grains <EOL> ) <EOL> ensure_in_syspath ( '<STR_LIT>' ) <EOL> import salt . utils <EOL> import integration <EOL> from salt . ext . six . moves import range <EOL> @ destructiveTest <EOL> @ skipIf ( os . geteuid ( ) != <NUM_LIT:0> , '<STR_LIT>' ) <EOL> @ skipIf ( not salt . utils . is_linux ( ) , '<STR_LIT>' ) <EOL> class UseraddModuleTest ( integration . ModuleCase ) : <EOL> def setUp ( self ) : <EOL> super ( UseraddModuleTest , self ) . setUp ( ) <EOL> os_grain = self . run_function ( '<STR_LIT>' , [ '<STR_LIT>' ] ) <EOL> if os_grain [ '<STR_LIT>' ] not in ( '<STR_LIT>' , '<STR_LIT>' ) : <EOL> self . skipTest ( <EOL> '<STR_LIT>' . format ( <EOL> ** os_grain <EOL> ) <EOL> ) <EOL> def __random_string ( self , size = <NUM_LIT:6> ) : <EOL> return '<STR_LIT>' + '<STR_LIT>' . join ( <EOL> random . choice ( string . ascii_uppercase + string . digits ) <EOL> for x in range ( size ) <EOL> ) <EOL> @ requires_system_grains <EOL> def test_groups_includes_primary ( self , grains = None ) : <EOL> uname = self . __random_string ( ) <EOL> if self . run_function ( '<STR_LIT>' , [ uname ] ) is not True : <EOL> self . run_function ( '<STR_LIT>' , [ uname , True , True ] ) <EOL> self . skipTest ( '<STR_LIT>' ) <EOL> try : <EOL> uinfo = self . run_function ( '<STR_LIT>' , [ uname ] ) <EOL> if grains [ '<STR_LIT>' ] in ( '<STR_LIT>' , ) : <EOL> self . assertIn ( '<STR_LIT>' , uinfo [ '<STR_LIT>' ] ) <EOL> else : <EOL> self . assertIn ( uname , uinfo [ '<STR_LIT>' ] ) <EOL> uid = uinfo [ '<STR_LIT>' ] <EOL> self . run_function ( '<STR_LIT>' , [ uname , True , True ] ) <EOL> gname = self . __random_string ( ) <EOL> if self . run_function ( '<STR_LIT>' , [ gname ] ) is not True : <EOL> self . run_function ( '<STR_LIT>' , [ gname , True , True ] ) <EOL> self . skipTest ( '<STR_LIT>' ) <EOL> ginfo = self . run_function ( '<STR_LIT>' , [ gname ] ) <EOL> if self . run_function ( '<STR_LIT>' , [ uname , uid , ginfo [ '<STR_LIT>' ] ] ) is False : <EOL> self . run_function ( '<STR_LIT>' , [ uname , True , True ] ) <EOL> self . skipTest ( '<STR_LIT>' ) <EOL> uinfo = self . run_function ( '<STR_LIT>' , [ uname ] ) <EOL> self . assertIn ( gname , uinfo [ '<STR_LIT>' ] ) <EOL> except AssertionError : <EOL> self . run_function ( '<STR_LIT>' , [ uname , True , True ] ) <EOL> raise <EOL> def test_linux_user_primary_group ( self , grains = None ) : <EOL> '''<STR_LIT>''' <EOL> name = '<STR_LIT>' <EOL> if self . run_function ( '<STR_LIT>' , [ name ] ) is not True : <EOL> self . run_function ( '<STR_LIT>' , [ name ] ) <EOL> self . skipTest ( '<STR_LIT>' ) <EOL> try : <EOL>", "answer": "primary_group = self . run_function ( '<STR_LIT>' , [ name ] )"}, {"prompt": "<s> import os <EOL> import os . path as osp <EOL> import PIL <EOL> from utils . cython_bbox import bbox_overlaps <EOL> import numpy as np <EOL> import scipy . sparse <EOL> import datasets <EOL> class imdb ( object ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , name ) : <EOL> self . _name = name <EOL> self . _num_classes = <NUM_LIT:0> <EOL> self . _classes = [ ] <EOL> self . _image_index = [ ] <EOL> self . _obj_proposer = '<STR_LIT>' <EOL> self . _roidb = None <EOL> self . _roidb_handler = self . default_roidb <EOL> self . config = { } <EOL> @ property <EOL> def name ( self ) : <EOL> return self . _name <EOL> @ property <EOL> def num_classes ( self ) : <EOL> return len ( self . _classes ) <EOL> @ property <EOL> def classes ( self ) : <EOL> return self . _classes <EOL> @ property <EOL> def image_index ( self ) : <EOL> return self . _image_index <EOL> @ property <EOL> def roidb_handler ( self ) : <EOL> return self . _roidb_handler <EOL> @ roidb_handler . setter <EOL> def roidb_handler ( self , val ) : <EOL> self . _roidb_handler = val <EOL> @ property <EOL> def roidb ( self ) : <EOL> if self . _roidb is not None : <EOL> return self . _roidb <EOL> self . _roidb = self . roidb_handler ( ) <EOL> return self . _roidb <EOL> @ property <EOL> def cache_path ( self ) : <EOL> cache_path = osp . abspath ( osp . join ( datasets . ROOT_DIR , '<STR_LIT:data>' , '<STR_LIT>' ) ) <EOL> if not os . path . exists ( cache_path ) : <EOL> os . makedirs ( cache_path ) <EOL> return cache_path <EOL> @ property <EOL> def num_images ( self ) : <EOL> return len ( self . image_index ) <EOL> def image_path_at ( self , i ) : <EOL> raise NotImplementedError <EOL> def default_roidb ( self ) : <EOL> raise NotImplementedError <EOL> def evaluate_detections ( self , all_boxes , output_dir = None ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> raise NotImplementedError <EOL> def append_flipped_images ( self ) : <EOL> num_images = self . num_images <EOL> widths = [ PIL . Image . open ( self . image_path_at ( i ) ) . size [ <NUM_LIT:0> ] <EOL> for i in xrange ( num_images ) ] <EOL> for i in xrange ( num_images ) : <EOL> boxes = self . roidb [ i ] [ '<STR_LIT>' ] . copy ( ) <EOL> oldx1 = boxes [ : , <NUM_LIT:0> ] . copy ( ) <EOL> oldx2 = boxes [ : , <NUM_LIT:2> ] . copy ( ) <EOL> boxes [ : , <NUM_LIT:0> ] = widths [ i ] - oldx2 - <NUM_LIT:1> <EOL> boxes [ : , <NUM_LIT:2> ] = widths [ i ] - oldx1 - <NUM_LIT:1> <EOL> assert ( boxes [ : , <NUM_LIT:2> ] >= boxes [ : , <NUM_LIT:0> ] ) . all ( ) <EOL> entry = { '<STR_LIT>' : boxes , <EOL> '<STR_LIT>' : self . roidb [ i ] [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : self . roidb [ i ] [ '<STR_LIT>' ] , <EOL> '<STR_LIT>' : True } <EOL> self . roidb . append ( entry ) <EOL> self . _image_index = self . _image_index * <NUM_LIT:2> <EOL> def evaluate_recall ( self , candidate_boxes , ar_thresh = <NUM_LIT:0.5> ) : <EOL> gt_overlaps = np . zeros ( <NUM_LIT:0> ) <EOL> for i in xrange ( self . num_images ) : <EOL> gt_inds = np . where ( self . roidb [ i ] [ '<STR_LIT>' ] > <NUM_LIT:0> ) [ <NUM_LIT:0> ] <EOL> gt_boxes = self . roidb [ i ] [ '<STR_LIT>' ] [ gt_inds , : ] <EOL> boxes = candidate_boxes [ i ] <EOL> if boxes . shape [ <NUM_LIT:0> ] == <NUM_LIT:0> : <EOL> continue <EOL> overlaps = bbox_overlaps ( boxes . astype ( np . float ) , <EOL> gt_boxes . astype ( np . float ) ) <EOL> _gt_overlaps = np . zeros ( ( gt_boxes . shape [ <NUM_LIT:0> ] ) ) <EOL> for j in xrange ( gt_boxes . shape [ <NUM_LIT:0> ] ) : <EOL> argmax_overlaps = overlaps . argmax ( axis = <NUM_LIT:0> ) <EOL> max_overlaps = overlaps . max ( axis = <NUM_LIT:0> ) <EOL> gt_ind = max_overlaps . argmax ( ) <EOL> gt_ovr = max_overlaps . max ( ) <EOL> assert ( gt_ovr >= <NUM_LIT:0> ) <EOL> box_ind = argmax_overlaps [ gt_ind ] <EOL> _gt_overlaps [ j ] = overlaps [ box_ind , gt_ind ] <EOL> assert ( _gt_overlaps [ j ] == gt_ovr ) <EOL> overlaps [ box_ind , : ] = - <NUM_LIT:1> <EOL> overlaps [ : , gt_ind ] = - <NUM_LIT:1> <EOL> gt_overlaps = np . hstack ( ( gt_overlaps , _gt_overlaps ) ) <EOL> num_pos = gt_overlaps . size <EOL> gt_overlaps = np . sort ( gt_overlaps ) <EOL> step = <NUM_LIT> <EOL> thresholds = np . minimum ( np . arange ( <NUM_LIT:0.5> , <NUM_LIT:1.0> + step , step ) , <NUM_LIT:1.0> ) <EOL> recalls = np . zeros_like ( thresholds ) <EOL> for i , t in enumerate ( thresholds ) : <EOL> recalls [ i ] = ( gt_overlaps >= t ) . sum ( ) / float ( num_pos ) <EOL> ar = <NUM_LIT:2> * np . trapz ( recalls , thresholds ) <EOL> return ar , gt_overlaps , recalls , thresholds <EOL> def create_roidb_from_box_list ( self , box_list , gt_roidb ) : <EOL> assert len ( box_list ) == self . num_images , '<STR_LIT>' <EOL> roidb = [ ] <EOL> for i in xrange ( self . num_images ) : <EOL> boxes = box_list [ i ] <EOL> num_boxes = boxes . shape [ <NUM_LIT:0> ] <EOL>", "answer": "overlaps = np . zeros ( ( num_boxes , self . num_classes ) , dtype = np . float32 )"}, {"prompt": "<s> import re , os <EOL> from . import VCSRoute , ROUTE_REGEX <EOL> from pip . vcs . mercurial import Mercurial <EOL> class MercurialRoute ( VCSRoute ) : <EOL> '''<STR_LIT>''' <EOL> vcs = Mercurial <EOL> def __unicode__ ( self ) : <EOL> return \"<STR_LIT>\" <EOL> def _uid ( self , identifier ) : <EOL> pattern_re = re . compile ( '<STR_LIT>' % ROUTE_REGEX ) <EOL> pattern_match = pattern_re . search ( identifier ) <EOL> pattern_info = pattern_match . groupdict ( ) <EOL>", "answer": "return \"<STR_LIT>\" % ( pattern_info [ '<STR_LIT>' ] , pattern_info [ '<STR_LIT>' ] ) "}, {"prompt": "<s> from core . domain import exp_services <EOL> from core . domain import exp_services_test <EOL> from core . domain import rights_manager <EOL> from core . domain import summary_services <EOL> from core . domain import user_services <EOL> import feconf <EOL> class ExplorationDisplayableSummaries ( <EOL> exp_services_test . ExplorationServicesUnitTests ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> ALBERT_EMAIL = '<STR_LIT>' <EOL> BOB_EMAIL = '<STR_LIT>' <EOL> ALBERT_NAME = '<STR_LIT>' <EOL> BOB_NAME = '<STR_LIT>' <EOL> USER_C_NAME = '<STR_LIT:c>' <EOL> USER_D_NAME = '<STR_LIT:d>' <EOL> USER_C_EMAIL = '<STR_LIT>' <EOL> USER_D_EMAIL = '<STR_LIT>' <EOL> USER_C_PROFILE_PICTURE = '<STR_LIT>' <EOL> EXP_ID_1 = '<STR_LIT>' <EOL> EXP_ID_2 = '<STR_LIT>' <EOL> EXP_ID_3 = '<STR_LIT>' <EOL> EXP_ID_4 = '<STR_LIT>' <EOL> EXP_ID_5 = '<STR_LIT>' <EOL> EXPECTED_VERSION_1 = <NUM_LIT:4> <EOL> EXPECTED_VERSION_2 = <NUM_LIT:2> <EOL> def setUp ( self ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> super ( ExplorationDisplayableSummaries , self ) . setUp ( ) <EOL> self . albert_id = self . get_user_id_from_email ( self . ALBERT_EMAIL ) <EOL> self . bob_id = self . get_user_id_from_email ( self . BOB_EMAIL ) <EOL> self . signup ( self . ALBERT_EMAIL , self . ALBERT_NAME ) <EOL> self . signup ( self . BOB_EMAIL , self . BOB_NAME ) <EOL> self . save_new_valid_exploration ( self . EXP_ID_1 , self . albert_id ) <EOL> exp_services . update_exploration ( <EOL> self . bob_id , self . EXP_ID_1 , [ { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT:title>' , <EOL> '<STR_LIT>' : '<STR_LIT>' <EOL> } ] , '<STR_LIT>' ) <EOL> self . save_new_valid_exploration ( self . EXP_ID_2 , self . albert_id ) <EOL> exp_services . update_exploration ( <EOL> self . albert_id , self . EXP_ID_1 , [ { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT:title>' , <EOL> '<STR_LIT>' : '<STR_LIT>' <EOL> } ] , '<STR_LIT>' ) <EOL> exp_services . update_exploration ( <EOL> self . albert_id , self . EXP_ID_2 , [ { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT:title>' , <EOL> '<STR_LIT>' : '<STR_LIT>' <EOL> } ] , '<STR_LIT>' ) <EOL> exp_services . revert_exploration ( self . bob_id , self . EXP_ID_1 , <NUM_LIT:3> , <NUM_LIT:2> ) <EOL> with self . assertRaisesRegexp ( <EOL> Exception , '<STR_LIT>' <EOL> ) : <EOL> rights_manager . publish_exploration ( self . bob_id , self . EXP_ID_2 ) <EOL> rights_manager . publish_exploration ( self . albert_id , self . EXP_ID_2 ) <EOL> self . save_new_valid_exploration ( self . EXP_ID_3 , self . albert_id ) <EOL> rights_manager . publish_exploration ( self . albert_id , self . EXP_ID_3 ) <EOL>", "answer": "exp_services . delete_exploration ( self . albert_id , self . EXP_ID_3 )"}, {"prompt": "<s> import cStringIO as StringIO <EOL> import subprocess <EOL> import unittest <EOL> import mox <EOL> import portable_platform <EOL> def subprocess_mock ( mox , * args , ** kw ) : <EOL> mock_process = mox . CreateMock ( subprocess . Popen ) <EOL> mox . StubOutWithMock ( subprocess , '<STR_LIT>' , use_mock_anything = True ) <EOL>", "answer": "subprocess . Popen ( * args , ** kw ) . AndReturn ("}, {"prompt": "<s> from molly . conf . provider import Provider <EOL> from datetime import datetime <EOL> import dateutil . parser <EOL> import feedparser <EOL> class RSSModuleServiceStatusProvider ( Provider ) : <EOL> def __init__ ( self , name , slug , url ) : <EOL> self . name , self . slug , self . url = name , slug , url <EOL> def parse_date ( self , s ) : <EOL> try : <EOL> return dateutil . parser . parse ( s ) <EOL> except ( TypeError , ValueError ) : <EOL> return None <EOL> def safe_parse ( self , f , s ) : <EOL> try : <EOL> return f ( s ) <EOL> except ( TypeError , ValueError ) : <EOL> return None <EOL> def get_status ( self ) : <EOL> services_feed = feedparser . parse ( self . url ) <EOL> try : <EOL>", "answer": "lastBuildDate = self . parse_date ( services_feed . entries [ <NUM_LIT:0> ] . get ( '<STR_LIT>' ) )"}, {"prompt": "<s> from neutron . api . v2 import attributes <EOL> from oslo_log import log as logging <EOL> from gbpservice . neutron . db . grouppolicy . extensions import group_proxy_db as db <EOL> from gbpservice . neutron . db . grouppolicy import group_policy_db as gp_db <EOL> from gbpservice . neutron . extensions import driver_proxy_group <EOL> from gbpservice . neutron . services . grouppolicy import ( <EOL> group_policy_driver_api as api ) <EOL> LOG = logging . getLogger ( __name__ ) <EOL> class ProxyGroupDriver ( api . ExtensionDriver ) : <EOL> _supported_extension_alias = '<STR_LIT>' <EOL> _extension_dict = driver_proxy_group . EXTENDED_ATTRIBUTES_2_0 <EOL> def initialize ( self ) : <EOL> pass <EOL> @ property <EOL> def extension_alias ( self ) : <EOL> return self . _supported_extension_alias <EOL> @ api . default_extension_behavior ( db . GroupProxyMapping ) <EOL> def process_create_policy_target_group ( self , session , data , result ) : <EOL> data = data [ '<STR_LIT>' ] <EOL> proxied = data . get ( '<STR_LIT>' ) <EOL> if attributes . is_attr_set ( proxied ) : <EOL> record = ( session . query ( db . GroupProxyMapping ) . filter_by ( <EOL> policy_target_group_id = proxied ) . first ( ) ) <EOL> if record : <EOL> if record . proxy_group_id : <EOL> raise driver_proxy_group . InvalidProxiedGroup ( <EOL> group_id = proxied ) <EOL> record . proxy_group_id = result [ '<STR_LIT:id>' ] <EOL> else : <EOL> record = db . GroupProxyMapping ( <EOL> policy_target_group_id = proxied , <EOL> proxy_group_id = result [ '<STR_LIT:id>' ] , <EOL> proxied_group_id = None ) <EOL> session . add ( record ) <EOL> if not attributes . is_attr_set ( data . get ( '<STR_LIT>' ) ) : <EOL> data [ '<STR_LIT>' ] = driver_proxy_group . DEFAULT_PROXY_TYPE <EOL> record = ( session . query ( db . GroupProxyMapping ) . filter_by ( <EOL> policy_target_group_id = result [ '<STR_LIT:id>' ] ) . one ( ) ) <EOL> record . proxy_type = data [ '<STR_LIT>' ] <EOL> result [ '<STR_LIT>' ] = data [ '<STR_LIT>' ] <EOL> elif attributes . is_attr_set ( data . get ( '<STR_LIT>' ) ) : <EOL> raise driver_proxy_group . ProxyTypeSetWithoutProxiedPTG ( ) <EOL> @ api . default_extension_behavior ( db . GroupProxyMapping ) <EOL> def process_update_policy_target_group ( self , session , data , result ) : <EOL> pass <EOL> @ api . default_extension_behavior ( db . GroupProxyMapping ) <EOL> def extend_policy_target_group_dict ( self , session , result ) : <EOL>", "answer": "pass"}, {"prompt": "<s> import datetime <EOL> from django . shortcuts import get_object_or_404 , render_to_response <EOL> from django . db import connection <EOL> from django . db . models import Q <EOL> from django . template import RequestContext <EOL> from django . shortcuts import redirect <EOL> from django . contrib . localflavor . us . us_states import US_STATES <EOL> from django . db . models import Sum <EOL> from django . http import Http404 <EOL> from fec_alerts . models import new_filing , newCommittee , f1filer <EOL> from summary_data . models import Candidate_Overlay , District , Committee_Overlay , Committee_Time_Summary , Authorized_Candidate_Committees , Pac_Candidate , DistrictWeekly <EOL> from shared_utils . cycle_utils import get_cycle_abbreviation , is_valid_four_digit_string_cycle , get_cycle_endpoints , list_2014_only , list_2016_only , cycle_fake <EOL> this_cycle = '<STR_LIT>' <EOL> this_cycle_start = datetime . date ( <NUM_LIT> , <NUM_LIT:1> , <NUM_LIT:1> ) <EOL> from formdata . models import SkedA , SkedB , SkedE <EOL> from summary_data . utils . summary_utils import map_summary_form_to_dict <EOL> from django . conf import settings <EOL> from summary_data . utils . update_utils import get_update_time <EOL> from summary_data . utils . weekly_update_utils import get_week_number , get_week_start , get_week_end <EOL> from summary_data . election_dates import elections_by_day <EOL> from summary_data . management . commands . write_weekly_files import data_series as weekly_dump_data_series <EOL> from summary_data . utils . chart_reference import chart_name_reference , chart_donor_name_reference <EOL> from django . views . decorators . cache import cache_page , cache_control <EOL> STATE_LIST = [ { '<STR_LIT:name>' : x [ <NUM_LIT:1> ] , '<STR_LIT>' : x [ <NUM_LIT:0> ] } for x in US_STATES ] <EOL> try : <EOL> PAGINATE_BY = settings . REST_FRAMEWORK [ '<STR_LIT>' ] <EOL> except : <EOL> print \"<STR_LIT>\" <EOL> PAGINATE_BY = <NUM_LIT:100> <EOL> try : <EOL> BULK_EXPORT_KEY = settings . BULK_EXPORT_KEY <EOL> except AttributeError : <EOL> print \"<STR_LIT>\" <EOL> try : <EOL> LONG_CACHE_TIME = settings . LONG_CACHE_TIME <EOL> SHORT_CACHE_TIME = settings . SHORT_CACHE_TIME <EOL> except AttributeError : <EOL> print \"<STR_LIT>\" <EOL> LONG_CACHE_TIME = <NUM_LIT> <EOL> SHORT_CACHE_TIME = <NUM_LIT:30> <EOL> try : <EOL> CURRENT_CYCLE = settings . CURRENT_CYCLE <EOL> except : <EOL> print \"<STR_LIT>\" <EOL> CURRENT_CYCLE = '<STR_LIT>' <EOL> def newbase ( request ) : <EOL> return render_to_response ( '<STR_LIT>' , { } , context_instance = RequestContext ( request ) ) <EOL> def home_page ( request ) : <EOL> return redirect ( '<STR_LIT>' ) <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def senate ( request , cycle ) : <EOL> if not is_valid_four_digit_string_cycle ( cycle ) : <EOL> raise Http404 <EOL> title = \"<STR_LIT>\" <EOL> explanatory_text = \"<STR_LIT>\" <EOL> districts = District . objects . filter ( office = '<STR_LIT:S>' , cycle = cycle ) <EOL> legislators = Candidate_Overlay . objects . filter ( office = '<STR_LIT:S>' , cycle = cycle ) . filter ( Q ( cash_on_hand__gte = <NUM_LIT:1000> ) | Q ( is_incumbent = True ) | Q ( total_expenditures__gte = <NUM_LIT:1000> ) ) . select_related ( '<STR_LIT>' ) . order_by ( '<STR_LIT>' ) <EOL> districts = District . objects . filter ( office = '<STR_LIT:H>' , cycle = cycle ) <EOL> other_year = None <EOL> if cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> elif cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> cycle_list = [ cycle_fake ( cycle , \"<STR_LIT>\" % cycle ) , cycle_fake ( other_year , \"<STR_LIT>\" % other_year ) ] <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : STATE_LIST , <EOL> '<STR_LIT>' : districts , <EOL> '<STR_LIT>' : legislators , <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : explanatory_text , <EOL> '<STR_LIT>' : cycle_list <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def senate_redirect ( request ) : <EOL> return redirect ( \"<STR_LIT>\" ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def house ( request , cycle ) : <EOL> if not is_valid_four_digit_string_cycle ( cycle ) : <EOL> raise Http404 <EOL> title = \"<STR_LIT>\" <EOL> explanatory_text = \"<STR_LIT>\" <EOL> legislators = Candidate_Overlay . objects . filter ( office = '<STR_LIT:H>' , cycle = cycle ) . filter ( Q ( cash_on_hand__gte = <NUM_LIT:1000> ) | Q ( is_incumbent = True ) | Q ( total_expenditures__gte = <NUM_LIT:1000> ) ) . select_related ( '<STR_LIT>' ) . order_by ( '<STR_LIT>' ) <EOL> districts = District . objects . filter ( office = '<STR_LIT:H>' , cycle = cycle ) <EOL> other_year = None <EOL> if cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> elif cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> cycle_list = [ cycle_fake ( cycle , \"<STR_LIT>\" % cycle ) , cycle_fake ( other_year , \"<STR_LIT>\" % other_year ) ] <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : legislators , <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : explanatory_text , <EOL> '<STR_LIT>' : STATE_LIST , <EOL> '<STR_LIT>' : districts , <EOL> '<STR_LIT>' : cycle_list <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def house_redirect ( request ) : <EOL> return redirect ( \"<STR_LIT>\" ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def races ( request , cycle ) : <EOL> if not is_valid_four_digit_string_cycle ( cycle ) : <EOL> raise Http404 <EOL> title = \"<STR_LIT>\" % ( cycle ) <EOL> explanatory_text = \"<STR_LIT>\" <EOL> other_year = None <EOL> if cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> elif cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> cycle_list = [ cycle_fake ( cycle , \"<STR_LIT>\" % cycle ) , cycle_fake ( other_year , \"<STR_LIT>\" % other_year ) ] <EOL> districts = District . objects . filter ( cycle = cycle ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : STATE_LIST , <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : explanatory_text , <EOL> '<STR_LIT>' : districts , <EOL> '<STR_LIT>' : cycle_list <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def races_redirect ( request ) : <EOL> return redirect ( \"<STR_LIT>\" ) <EOL> def race_id_redirect ( request , race_id ) : <EOL> race = get_object_or_404 ( District , pk = race_id ) <EOL> return redirect ( race . get_absolute_url ( ) ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def house_race ( request , cycle , state , district ) : <EOL> race = get_object_or_404 ( District , cycle = cycle , state = state , office_district = district , office = '<STR_LIT:H>' ) <EOL> title = race . race_name ( ) <EOL> candidates = Candidate_Overlay . objects . filter ( district = race ) . filter ( Q ( total_receipts__gte = <NUM_LIT:1000> ) | Q ( total_expenditures__gte = <NUM_LIT:1000> ) ) . exclude ( not_seeking_reelection = True ) . order_by ( '<STR_LIT>' ) <EOL> outside_spenders = Pac_Candidate . objects . filter ( candidate__in = candidates , total_ind_exp__gte = <NUM_LIT> ) . select_related ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> candidate_list = [ x . get ( '<STR_LIT>' ) for x in candidates . values ( '<STR_LIT>' ) ] <EOL> cycle_endpoints = get_cycle_endpoints ( int ( cycle ) ) <EOL> recent_ies = SkedE . objects . filter ( candidate_id_checked__in = candidate_list , expenditure_amount__gte = <NUM_LIT:1000> , superceded_by_amendment = False , expenditure_date_formatted__gte = cycle_endpoints [ '<STR_LIT:start>' ] , expenditure_date_formatted__lte = cycle_endpoints [ '<STR_LIT:end>' ] ) . select_related ( '<STR_LIT>' ) . order_by ( '<STR_LIT>' ) [ : <NUM_LIT:5> ] <EOL> committees = Committee_Overlay . objects . filter ( curated_candidate__in = candidates ) <EOL> committee_ids = [ x . get ( '<STR_LIT>' ) for x in committees . values ( '<STR_LIT>' ) ] <EOL> recent_filings = new_filing . objects . filter ( fec_id__in = committee_ids , is_superceded = False ) . exclude ( coverage_to_date__isnull = True ) . order_by ( '<STR_LIT>' ) [ : <NUM_LIT:5> ] <EOL> cycle_values = District . objects . filter ( state = state , office_district = district , office = '<STR_LIT:H>' ) . exclude ( cycle = cycle ) <EOL> cycle_list = [ race ] + list ( cycle_values ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : candidates , <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : race , <EOL> '<STR_LIT>' : outside_spenders , <EOL> '<STR_LIT>' : recent_ies , <EOL> '<STR_LIT>' : recent_filings , <EOL> '<STR_LIT>' : cycle_list <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def presidential_race ( request ) : <EOL> race = get_object_or_404 ( District , cycle = CURRENT_CYCLE , office = '<STR_LIT:P>' ) <EOL> title = \"<STR_LIT>\" <EOL> candidates = Candidate_Overlay . objects . filter ( district = race ) . filter ( Q ( total_receipts__gte = <NUM_LIT> ) | Q ( total_expenditures__gte = <NUM_LIT> ) ) . exclude ( not_seeking_reelection = True ) . order_by ( '<STR_LIT>' ) <EOL> outside_spenders = Pac_Candidate . objects . filter ( candidate__in = candidates , total_ind_exp__gte = <NUM_LIT> ) . select_related ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> candidate_list = [ x . get ( '<STR_LIT>' ) for x in candidates . values ( '<STR_LIT>' ) ] <EOL> cycle_endpoints = get_cycle_endpoints ( int ( CURRENT_CYCLE ) ) <EOL> recent_ies = SkedE . objects . filter ( candidate_id_checked__in = candidate_list , expenditure_amount__gte = <NUM_LIT> , superceded_by_amendment = False , expenditure_date_formatted__gte = cycle_endpoints [ '<STR_LIT:start>' ] , expenditure_date_formatted__lte = cycle_endpoints [ '<STR_LIT:end>' ] ) . select_related ( '<STR_LIT>' ) . order_by ( '<STR_LIT>' ) [ : <NUM_LIT:5> ] <EOL> committees = Committee_Overlay . objects . filter ( curated_candidate__in = candidates ) <EOL> committee_ids = [ x . get ( '<STR_LIT>' ) for x in committees . values ( '<STR_LIT>' ) ] <EOL> recent_filings = new_filing . objects . filter ( fec_id__in = committee_ids , is_superceded = False ) . exclude ( coverage_to_date__isnull = True ) . order_by ( '<STR_LIT>' ) [ : <NUM_LIT:5> ] <EOL> cycle_list = list_2016_only <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : candidates , <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : race , <EOL> '<STR_LIT>' : outside_spenders , <EOL> '<STR_LIT>' : recent_ies , <EOL> '<STR_LIT>' : recent_filings , <EOL> '<STR_LIT>' : cycle_list <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def senate_race ( request , cycle , state , term_class ) : <EOL> race = get_object_or_404 ( District , cycle = cycle , state = state , term_class = term_class , office = '<STR_LIT:S>' ) <EOL> title = race . race_name ( ) <EOL> candidates = Candidate_Overlay . objects . filter ( district = race ) . filter ( Q ( total_receipts__gte = <NUM_LIT:1000> ) | Q ( total_expenditures__gte = <NUM_LIT:1000> ) ) . exclude ( not_seeking_reelection = True ) . order_by ( '<STR_LIT>' ) <EOL> outside_spenders = Pac_Candidate . objects . filter ( candidate__in = candidates , total_ind_exp__gte = <NUM_LIT> ) . select_related ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> candidate_list = [ x . get ( '<STR_LIT>' ) for x in candidates . values ( '<STR_LIT>' ) ] <EOL> cycle_endpoints = get_cycle_endpoints ( int ( cycle ) ) <EOL> recent_ies = SkedE . objects . filter ( candidate_id_checked__in = candidate_list , expenditure_amount__gte = <NUM_LIT:1000> , superceded_by_amendment = False , expenditure_date_formatted__gte = cycle_endpoints [ '<STR_LIT:start>' ] , expenditure_date_formatted__lte = cycle_endpoints [ '<STR_LIT:end>' ] ) . select_related ( '<STR_LIT>' ) . order_by ( '<STR_LIT>' ) [ : <NUM_LIT:5> ] <EOL> cycle_values = District . objects . filter ( state = state , term_class = term_class , office = '<STR_LIT:S>' ) . exclude ( cycle = cycle ) <EOL> cycle_list = [ race ] + list ( cycle_values ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : candidates , <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : race , <EOL> '<STR_LIT>' : outside_spenders , <EOL> '<STR_LIT>' : recent_ies , <EOL> '<STR_LIT>' : cycle_list <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_control ( no_cache = True ) <EOL> def newest_filings ( request ) : <EOL> candidates = Candidate_Overlay . objects . filter ( office__in = [ '<STR_LIT:H>' , '<STR_LIT:P>' ] , cycle = CURRENT_CYCLE ) . order_by ( '<STR_LIT:name>' ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : candidates , <EOL> '<STR_LIT:title>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : PAGINATE_BY , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_control ( no_cache = True ) <EOL> def pacs ( request , cycle ) : <EOL> if not is_valid_four_digit_string_cycle ( cycle ) : <EOL> raise Http404 <EOL> other_year = None <EOL> if cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> elif cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> cycle_list = [ cycle_fake ( cycle , \"<STR_LIT>\" % cycle ) , cycle_fake ( other_year , \"<STR_LIT>\" % other_year ) ] <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:title>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : PAGINATE_BY , <EOL> '<STR_LIT>' : cycle_list <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def pacs_redirect ( request ) : <EOL> return redirect ( \"<STR_LIT>\" ) <EOL> @ cache_control ( no_cache = True ) <EOL> def outside_spenders ( request , cycle ) : <EOL> other_year = None <EOL> if cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> elif cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> cycle_list = [ cycle_fake ( cycle , \"<STR_LIT>\" % cycle ) , cycle_fake ( other_year , \"<STR_LIT>\" % other_year ) ] <EOL> explanatory_text = \"<STR_LIT>\" % cycle <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : explanatory_text , <EOL> '<STR_LIT:title>' : \"<STR_LIT>\" % cycle , <EOL> '<STR_LIT>' : PAGINATE_BY , <EOL> '<STR_LIT>' : cycle_list , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def outside_spenders_redirect ( request ) : <EOL> return redirect ( \"<STR_LIT>\" ) <EOL> @ cache_control ( no_cache = True ) <EOL> def dynamic_ies ( request ) : <EOL> districts = District . objects . filter ( outside_spending__gt = <NUM_LIT:1000> ) . order_by ( '<STR_LIT:state>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> candidates = Candidate_Overlay . objects . filter ( total_expenditures__gt = <NUM_LIT:1> ) . select_related ( '<STR_LIT>' ) . order_by ( '<STR_LIT:name>' ) <EOL> outside_spenders = Committee_Overlay . objects . filter ( total_indy_expenditures__gte = <NUM_LIT:1000> ) . order_by ( '<STR_LIT:name>' ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : STATE_LIST , <EOL> '<STR_LIT:title>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : PAGINATE_BY , <EOL> '<STR_LIT>' : districts , <EOL> '<STR_LIT>' : candidates , <EOL> '<STR_LIT>' : outside_spenders , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def new_committees ( request ) : <EOL> today = datetime . datetime . today ( ) <EOL> month_ago = today - datetime . timedelta ( days = <NUM_LIT:30> ) <EOL> committees = f1filer . objects . filter ( receipt_dt__gte = month_ago ) . order_by ( '<STR_LIT>' ) <EOL> return render_to_response ( '<STR_LIT>' , { <EOL> '<STR_LIT>' : committees , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:title>' : '<STR_LIT>' <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def render_blank_page ( title , explanatory_text , request ) : <EOL> return render_to_response ( '<STR_LIT>' , { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : explanatory_text , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def downloads_redirect ( request ) : <EOL> return redirect ( \"<STR_LIT>\" ) <EOL> def downloads ( request , cycle ) : <EOL> if not is_valid_four_digit_string_cycle ( cycle ) : <EOL> raise Http404 <EOL> other_year = None <EOL> if cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> elif cycle == '<STR_LIT>' : <EOL> other_year = '<STR_LIT>' <EOL> cycle_list = [ cycle_fake ( cycle , \"<STR_LIT>\" % cycle ) , cycle_fake ( other_year , \"<STR_LIT>\" % other_year ) ] <EOL> title = \"<STR_LIT>\" <EOL> update_time = get_update_time ( BULK_EXPORT_KEY ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : cycle , <EOL> '<STR_LIT>' : cycle_list , <EOL> '<STR_LIT>' : update_time , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def about ( request ) : <EOL> title = \"<STR_LIT>\" <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def outside_spending ( request ) : <EOL> title = \"<STR_LIT>\" <EOL> explanatory_text = \"<STR_LIT>\" <EOL> ies = SkedE . objects . filter ( superceded_by_amendment = False , expenditure_amount__gte = <NUM_LIT> , expenditure_date_formatted__gte = datetime . date ( <NUM_LIT> , <NUM_LIT:1> , <NUM_LIT:1> ) ) . select_related ( '<STR_LIT>' , '<STR_LIT>' ) . order_by ( '<STR_LIT>' ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : explanatory_text , <EOL> '<STR_LIT>' : ies , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def filing ( request , filing_num ) : <EOL> filing = get_object_or_404 ( new_filing , filing_number = filing_num ) <EOL> committee = None <EOL> title = \"<STR_LIT>\" % ( filing . committee_name , filing_num ) <EOL> if not filing . committee_name : <EOL> try : <EOL> committee = Committee_Overlay . objects . get ( fec_id = filing . fec_id , cycle = filing . cycle ) <EOL> title = \"<STR_LIT>\" % ( committee . get_absolute_url ( ) , committee . name , filing_num ) <EOL> except : <EOL> pass <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : filing , <EOL> '<STR_LIT>' : committee , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def filings_skeda ( request , filing_num ) : <EOL> filing_data = get_object_or_404 ( new_filing , filing_number = filing_num ) <EOL> title = \"<STR_LIT>\" % ( filing_data . get_committee_url ( ) , filing_data . committee_name , filing_data . get_absolute_url ( ) , filing_num ) <EOL> filings = None <EOL> too_many_to_display = False <EOL> if filing_data . lines_present : <EOL> lines_present = filing_data . lines_present . get ( '<STR_LIT:A>' ) <EOL> if int ( lines_present ) <= <NUM_LIT:1000> : <EOL> filings = SkedA . objects . filter ( filing_number = filing_num ) . order_by ( '<STR_LIT>' ) <EOL> else : <EOL> too_many_to_display = True <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : filings , <EOL> '<STR_LIT>' : too_many_to_display , <EOL> '<STR_LIT>' : filing_data , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def filings_skedb ( request , filing_num ) : <EOL> filing_data = get_object_or_404 ( new_filing , filing_number = filing_num ) <EOL> title = \"<STR_LIT>\" % ( filing_data . get_committee_url ( ) , filing_data . committee_name , filing_data . get_absolute_url ( ) , filing_num ) <EOL> filings = None <EOL> too_many_to_display = False <EOL> if filing_data . lines_present : <EOL> lines_present = filing_data . lines_present . get ( '<STR_LIT:B>' ) <EOL> if int ( lines_present ) <= <NUM_LIT:1000> : <EOL> filings = SkedB . objects . filter ( filing_number = filing_num ) . order_by ( '<STR_LIT>' ) <EOL> else : <EOL> too_many_to_display = True <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : filings , <EOL> '<STR_LIT>' : too_many_to_display , <EOL> '<STR_LIT>' : filing_data , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def filings_skede ( request , filing_num ) : <EOL> filing_data = get_object_or_404 ( new_filing , filing_number = filing_num ) <EOL> title = \"<STR_LIT>\" % ( filing_data . get_committee_url ( ) , filing_data . committee_name , filing_data . get_absolute_url ( ) , filing_num ) <EOL> filings = None <EOL> too_many_to_display = False <EOL> if filing_data . lines_present : <EOL> lines_present = filing_data . lines_present . get ( '<STR_LIT:E>' ) <EOL> if int ( lines_present ) <= <NUM_LIT:1000> : <EOL> filings = SkedE . objects . filter ( filing_number = filing_num ) . order_by ( '<STR_LIT>' ) <EOL> else : <EOL> too_many_to_display = True <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : filings , <EOL> '<STR_LIT>' : too_many_to_display , <EOL> '<STR_LIT>' : filing_data , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def committee ( request , slug , committee_id ) : <EOL> return redirect ( \"<STR_LIT>\" % ( slug , committee_id ) ) <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> @ cache_page ( <NUM_LIT:1> ) <EOL> def committee_cycle ( request , cycle , committee_id ) : <EOL> if not is_valid_four_digit_string_cycle ( cycle ) : <EOL> raise Http404 <EOL> cycle_endpoints = get_cycle_endpoints ( int ( cycle ) ) <EOL> committee_overlay = get_object_or_404 ( Committee_Overlay , fec_id = committee_id , cycle = int ( cycle ) ) <EOL> title = committee_overlay . name + \"<STR_LIT>\" % ( cycle ) <EOL> report_list = Committee_Time_Summary . objects . filter ( com_id = committee_id , coverage_from_date__gte = cycle_endpoints [ '<STR_LIT:start>' ] , coverage_from_date__lte = cycle_endpoints [ '<STR_LIT:end>' ] ) . order_by ( '<STR_LIT>' ) <EOL> end_of_coverage_date = committee_overlay . cash_on_hand_date <EOL> recent_report_list = None <EOL> if end_of_coverage_date : <EOL> relevant_date = max ( end_of_coverage_date , cycle_endpoints [ '<STR_LIT:start>' ] ) <EOL> recent_report_list = new_filing . objects . filter ( fec_id = committee_id , coverage_from_date__gte = relevant_date , coverage_to_date__lte = cycle_endpoints [ '<STR_LIT:end>' ] , form_type__in = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) . exclude ( is_f5_quarterly = True ) . exclude ( is_superceded = True ) <EOL> else : <EOL> recent_report_list = new_filing . objects . filter ( fec_id = committee_id , coverage_from_date__gte = cycle_endpoints [ '<STR_LIT:start>' ] , coverage_to_date__lte = cycle_endpoints [ '<STR_LIT:end>' ] , form_type__in = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) . exclude ( is_f5_quarterly = True ) . exclude ( is_superceded = True ) <EOL> independent_spending = Pac_Candidate . objects . filter ( committee = committee_overlay , total_ind_exp__gte = <NUM_LIT> , cycle = cycle ) . select_related ( '<STR_LIT>' ) <EOL> recent_ies = None <EOL> if committee_overlay . total_indy_expenditures > <NUM_LIT> : <EOL> recent_ies = SkedE . objects . filter ( filer_committee_id_number = committee_id , expenditure_amount__gte = <NUM_LIT> , superceded_by_amendment = False , expenditure_date_formatted__gte = cycle_endpoints [ '<STR_LIT:start>' ] , expenditure_date_formatted__lte = cycle_endpoints [ '<STR_LIT:end>' ] ) . select_related ( '<STR_LIT>' ) . order_by ( '<STR_LIT>' ) [ : <NUM_LIT:10> ] <EOL> cycle_values = Committee_Overlay . objects . filter ( fec_id = committee_id ) . exclude ( cycle = cycle ) <EOL> cycle_list = [ committee_overlay ] + list ( cycle_values ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : report_list , <EOL> '<STR_LIT>' : recent_report_list , <EOL> '<STR_LIT>' : committee_overlay , <EOL> '<STR_LIT>' : independent_spending , <EOL> '<STR_LIT>' : recent_ies , <EOL> '<STR_LIT>' : cycle_list , <EOL> '<STR_LIT>' : cycle , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def candidate ( request , slug , candidate_id ) : <EOL> return redirect ( \"<STR_LIT>\" % ( slug , candidate_id ) ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def candidate_cycle ( request , slug , candidate_id , cycle ) : <EOL> if not is_valid_four_digit_string_cycle ( cycle ) : <EOL> raise Http404 <EOL> cycles = Candidate_Overlay . objects . filter ( fec_id = candidate_id ) <EOL> candidate_overlay = None <EOL> try : <EOL> candidate_overlay = cycles . get ( cycle = cycle ) <EOL> except Candidate_Overlay . DoesNotExist : <EOL> if len ( cycles ) > <NUM_LIT:0> : <EOL> candidate_overlay = cycles . order_by ( '<STR_LIT>' ) [ <NUM_LIT:0> ] <EOL> return redirect ( \"<STR_LIT>\" % ( candidate_overlay . cycle , slug , candidate_id ) ) <EOL> else : <EOL> raise Http404 <EOL> other_cycles = cycles . exclude ( cycle = cycle ) <EOL> cycle_list = [ candidate_overlay ] + list ( other_cycles ) <EOL> cycle_endpoints = get_cycle_endpoints ( int ( cycle ) ) <EOL> title = \"<STR_LIT>\" % ( candidate_overlay . name , candidate_overlay . party , cycle ) <EOL> authorized_committee_list = Authorized_Candidate_Committees . objects . filter ( candidate_id = candidate_id , cycle = cycle ) <EOL> committee_list = [ x . get ( '<STR_LIT>' ) for x in authorized_committee_list . values ( '<STR_LIT>' ) ] <EOL> report_list = Committee_Time_Summary . objects . filter ( com_id__in = committee_list , coverage_from_date__gte = cycle_endpoints [ '<STR_LIT:start>' ] , coverage_through_date__lte = cycle_endpoints [ '<STR_LIT:end>' ] ) . order_by ( '<STR_LIT>' ) <EOL> end_of_coverage_date = None <EOL> recent_report_list = None <EOL> if report_list : <EOL> end_of_coverage_date = report_list [ <NUM_LIT:0> ] . coverage_through_date <EOL> recent_report_total = <NUM_LIT:0> <EOL> if end_of_coverage_date : <EOL> recent_report_list = new_filing . objects . filter ( fec_id__in = committee_list , coverage_from_date__gte = end_of_coverage_date , coverage_to_date__lte = cycle_endpoints [ '<STR_LIT:end>' ] , form_type__in = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) . exclude ( is_superceded = True ) <EOL> if recent_report_list : <EOL> recent_report_total = recent_report_list . aggregate ( spending_total = Sum ( '<STR_LIT>' ) ) [ '<STR_LIT>' ] <EOL> else : <EOL> recent_report_list = new_filing . objects . filter ( fec_id__in = committee_list , coverage_from_date__gte = cycle_endpoints [ '<STR_LIT:start>' ] , coverage_to_date__lte = cycle_endpoints [ '<STR_LIT:end>' ] , form_type__in = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) . exclude ( is_superceded = True ) <EOL> outside_spenders = Pac_Candidate . objects . filter ( candidate = candidate_overlay , cycle = cycle , total_ind_exp__gte = <NUM_LIT:1000> ) . select_related ( '<STR_LIT>' ) <EOL> recent_ies = None <EOL> if outside_spenders : <EOL> recent_ies = SkedE . objects . filter ( candidate_checked = candidate_overlay , expenditure_amount__gte = <NUM_LIT> , superceded_by_amendment = False , expenditure_date_formatted__gte = cycle_endpoints [ '<STR_LIT:start>' ] , expenditure_date_formatted__lte = cycle_endpoints [ '<STR_LIT:end>' ] ) . select_related ( '<STR_LIT>' ) . order_by ( '<STR_LIT>' ) [ : <NUM_LIT:10> ] <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : report_list , <EOL> '<STR_LIT>' : candidate_overlay , <EOL> '<STR_LIT>' : authorized_committee_list , <EOL> '<STR_LIT>' : outside_spenders , <EOL> '<STR_LIT>' : recent_report_list , <EOL> '<STR_LIT>' : recent_ies , <EOL> '<STR_LIT>' : recent_report_total , <EOL> '<STR_LIT>' : cycle_list , <EOL> '<STR_LIT>' : cycle <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def subscribe ( request ) : <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : '<STR_LIT>' , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def committee_search_html ( request ) : <EOL> params = request . GET <EOL> committees = None <EOL> try : <EOL> committee_name_fragment = params [ '<STR_LIT:name>' ] <EOL> if len ( committee_name_fragment ) > <NUM_LIT:3> : <EOL> print committee_name_fragment <EOL> committees = Committee_Overlay . objects . filter ( Q ( name__icontains = committee_name_fragment ) | Q ( curated_candidate__name__icontains = committee_name_fragment ) ) . select_related ( '<STR_LIT>' ) <EOL> else : <EOL> committees = None <EOL> except KeyError : <EOL> committees = None <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : committees , <EOL> } <EOL> ) <EOL> @ cache_control ( no_cache = True ) <EOL> def top_races ( request , week_number ) : <EOL> week_start = get_week_start ( int ( week_number ) ) <EOL> week_start_formatted = week_start . strftime ( '<STR_LIT>' ) <EOL> week_end = get_week_end ( int ( week_number ) ) <EOL> week_end_formatted = week_end . strftime ( '<STR_LIT>' ) <EOL> period_start = week_start - datetime . timedelta ( days = <NUM_LIT> ) <EOL> weeklysummaries = DistrictWeekly . objects . filter ( cycle_week_number = week_number , outside_spending__gte = <NUM_LIT:1000> ) . order_by ( '<STR_LIT>' ) [ : <NUM_LIT:3> ] <EOL> title = \"<STR_LIT>\" % ( week_start_formatted , week_end_formatted ) <EOL> previous_week_number = None <EOL> following_week_number = None <EOL> if int ( week_number ) > <NUM_LIT:1> : <EOL> previous_week_number = int ( week_number ) - <NUM_LIT:1> <EOL> if int ( week_number ) < get_week_number ( datetime . date . today ( ) ) : <EOL> following_week_number = int ( week_number ) + <NUM_LIT:1> <EOL> district_ids = weeklysummaries . values ( \"<STR_LIT>\" ) <EOL> district_id_list = [ str ( x [ '<STR_LIT>' ] ) for x in district_ids ] <EOL> district_list = \"<STR_LIT:U+002C>\" . join ( district_id_list ) <EOL> data_url = \"<STR_LIT>\" % ( int ( week_number ) - <NUM_LIT:2> , week_number , district_list ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : period_start , <EOL> '<STR_LIT>' : week_start , <EOL> '<STR_LIT>' : week_end , <EOL> '<STR_LIT>' : weeklysummaries , <EOL> '<STR_LIT>' : previous_week_number , <EOL> '<STR_LIT>' : following_week_number , <EOL> '<STR_LIT>' : week_number , <EOL> '<STR_LIT>' : data_url , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_control ( no_cache = True ) <EOL> def top_current_races ( request ) : <EOL> week_number = get_week_number ( datetime . date . today ( ) ) - <NUM_LIT:1> <EOL> week_start = get_week_start ( int ( week_number ) ) <EOL> week_start_formatted = week_start . strftime ( '<STR_LIT>' ) <EOL> week_end = get_week_end ( int ( week_number ) ) <EOL> week_end_formatted = week_end . strftime ( '<STR_LIT>' ) <EOL> previous_week_number = int ( week_number ) - <NUM_LIT:1> <EOL> following_week_number = int ( week_number ) + <NUM_LIT:1> <EOL> period_start = week_start - datetime . timedelta ( days = <NUM_LIT> ) <EOL> weeklysummaries = DistrictWeekly . objects . filter ( cycle_week_number = week_number , outside_spending__gt = <NUM_LIT:1000> ) . order_by ( '<STR_LIT>' ) [ : <NUM_LIT:3> ] <EOL> title = \"<STR_LIT>\" % ( week_start_formatted , week_end_formatted ) <EOL> district_ids = weeklysummaries . values ( \"<STR_LIT>\" ) <EOL> district_id_list = [ str ( x [ '<STR_LIT>' ] ) for x in district_ids ] <EOL> district_list = \"<STR_LIT:U+002C>\" . join ( district_id_list ) <EOL> data_url = \"<STR_LIT>\" % ( int ( week_number ) - <NUM_LIT:2> , week_number , district_list ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : previous_week_number , <EOL> '<STR_LIT>' : following_week_number , <EOL> '<STR_LIT:title>' : title , <EOL> '<STR_LIT>' : period_start , <EOL> '<STR_LIT>' : week_start , <EOL> '<STR_LIT>' : week_end , <EOL> '<STR_LIT>' : weeklysummaries , <EOL> '<STR_LIT>' : week_number , <EOL> '<STR_LIT>' : data_url , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> @ cache_page ( LONG_CACHE_TIME ) <EOL> def election_calendar ( request ) : <EOL> title = \"<STR_LIT>\" <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : elections_by_day , <EOL> '<STR_LIT:title>' : title , <EOL> } <EOL> ) <EOL> def chart_test ( request , blog_or_feature ) : <EOL> if not ( blog_or_feature in [ '<STR_LIT>' , '<STR_LIT>' ] ) : <EOL> raise Http404 <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : blog_or_feature <EOL> } <EOL> ) <EOL> def chart_listing ( request ) : <EOL> chart_list = [ ] <EOL> for key in chart_name_reference : <EOL> value = chart_name_reference [ key ] <EOL> value [ '<STR_LIT>' ] = key <EOL> print value <EOL> chart_list . append ( value ) <EOL> chart_list . sort ( key = lambda x : x [ '<STR_LIT:name>' ] ) <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : chart_list , <EOL> '<STR_LIT>' : [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> } <EOL> ) <EOL> def senate_races ( request , blog_or_feature ) : <EOL> if not ( blog_or_feature in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) : <EOL> raise Http404 <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : blog_or_feature , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def roi_chart ( request , blog_or_feature ) : <EOL> if not ( blog_or_feature in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) : <EOL> raise Http404 <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : blog_or_feature , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def weekly_comparison ( request , race_list , blog_or_feature ) : <EOL> print \"<STR_LIT>\" <EOL> if not ( blog_or_feature in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) : <EOL> raise Http404 <EOL> race_ids = race_list . split ( '<STR_LIT:->' ) <EOL> if len ( race_ids ) == <NUM_LIT:0> or len ( race_ids ) > <NUM_LIT:6> : <EOL> raise Http404 <EOL> race_id_text = \"<STR_LIT:U+002C>\" . join ( race_ids ) <EOL> chart_title = \"<STR_LIT>\" <EOL> partisan_colors = '<STR_LIT:false>' <EOL> try : <EOL> chart_data = chart_name_reference [ race_list ] <EOL> chart_title = chart_data [ '<STR_LIT:name>' ] <EOL> partisan_colors = chart_data [ '<STR_LIT>' ] <EOL> except KeyError : <EOL> for i , id in enumerate ( race_ids ) : <EOL> try : <EOL> series_name = weekly_dump_data_series [ int ( id ) ] [ '<STR_LIT>' ] <EOL> if i > <NUM_LIT:0> : <EOL> chart_title = chart_title + \"<STR_LIT>\" <EOL> chart_title = chart_title + series_name <EOL> except IndexError : <EOL> continue <EOL> chart_title = chart_title + \"<STR_LIT>\" <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : race_id_text , <EOL> '<STR_LIT>' : chart_title , <EOL> '<STR_LIT>' : blog_or_feature , <EOL> '<STR_LIT>' : partisan_colors , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : <NUM_LIT:5> , <EOL> '<STR_LIT>' : <NUM_LIT> , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def weekly_comparison_cumulative ( request , race_list , blog_or_feature ) : <EOL> print \"<STR_LIT>\" <EOL> if not ( blog_or_feature in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) : <EOL> raise Http404 <EOL> race_ids = race_list . split ( '<STR_LIT:->' ) <EOL> if len ( race_ids ) == <NUM_LIT:0> or len ( race_ids ) > <NUM_LIT:6> : <EOL> raise Http404 <EOL> race_id_text = \"<STR_LIT:U+002C>\" . join ( race_ids ) <EOL> chart_title = \"<STR_LIT>\" <EOL> partisan_colors = '<STR_LIT:false>' <EOL> try : <EOL> chart_data = chart_name_reference [ race_list ] <EOL> chart_title = chart_data [ '<STR_LIT:name>' ] <EOL> partisan_colors = chart_data [ '<STR_LIT>' ] <EOL> except KeyError : <EOL> for i , id in enumerate ( race_ids ) : <EOL> try : <EOL> series_name = weekly_dump_data_series [ int ( id ) ] [ '<STR_LIT>' ] <EOL> if i > <NUM_LIT:0> : <EOL> chart_title = chart_title + \"<STR_LIT>\" <EOL> chart_title = chart_title + series_name <EOL> except IndexError : <EOL> continue <EOL> chart_title = chart_title + \"<STR_LIT>\" <EOL> return render_to_response ( '<STR_LIT>' , <EOL> { <EOL> '<STR_LIT>' : race_id_text , <EOL> '<STR_LIT>' : chart_title , <EOL> '<STR_LIT>' : blog_or_feature , <EOL> '<STR_LIT>' : partisan_colors , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : <NUM_LIT:5> , <EOL> '<STR_LIT>' : <NUM_LIT> , <EOL> } , <EOL> context_instance = RequestContext ( request ) <EOL> ) <EOL> def contrib_comparison ( request , race_list , blog_or_feature ) : <EOL> print \"<STR_LIT>\" <EOL> if not ( blog_or_feature in [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) : <EOL> raise Http404 <EOL> race_ids = race_list . split ( '<STR_LIT:->' ) <EOL> if len ( race_ids ) == <NUM_LIT:0> or len ( race_ids ) > <NUM_LIT:6> : <EOL>", "answer": "raise Http404"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> try : <EOL> from local import * <EOL> except ImportError as e : <EOL> try : <EOL> from production_heroku import * <EOL> except ImportError as e : <EOL>", "answer": "pass "}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import numpy as np <EOL> from numpy . testing import assert_ , assert_almost_equal <EOL> from statsmodels . sandbox . distributions . extras import ( skewnorm , <EOL> skewnorm2 , ACSkewT_gen ) <EOL> def test_skewnorm ( ) : <EOL> pdf_r = np . array ( [ <NUM_LIT> , <NUM_LIT> , <EOL> <NUM_LIT> , <NUM_LIT> , <EOL> <NUM_LIT> ] ) <EOL> pdf_sn = skewnorm . pdf ( [ - <NUM_LIT:2> , - <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:2> ] , <NUM_LIT:10> ) <EOL> assert_ ( np . allclose ( pdf_sn , pdf_r , rtol = <NUM_LIT> , atol = <NUM_LIT:0> ) ) <EOL> pdf_sn2 = skewnorm2 . pdf ( [ - <NUM_LIT:2> , - <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:2> ] , <NUM_LIT:10> ) <EOL> assert_ ( np . allclose ( pdf_sn2 , pdf_r , rtol = <NUM_LIT> , atol = <NUM_LIT:0> ) ) <EOL> cdf_r = np . array ( [ <NUM_LIT> , <NUM_LIT> , <EOL> <NUM_LIT> , <NUM_LIT> , <EOL> <NUM_LIT> ] ) <EOL> cdf_sn = skewnorm . cdf ( [ - <NUM_LIT:2> , - <NUM_LIT:1> , <NUM_LIT:0> , <NUM_LIT:1> , <NUM_LIT:2> ] , <NUM_LIT:10> ) <EOL>", "answer": "maxabs = np . max ( np . abs ( cdf_sn - cdf_r ) )"}, {"prompt": "<s> from nose . plugins . skip import SkipTest <EOL> from theano . tensor . nnet . tests import test_abstract_conv <EOL> from . . type import GpuArrayType , gpuarray_shared_constructor <EOL> from . . dnn import dnn_available , GpuDnnConv , GpuDnnConvGradW , GpuDnnConvGradI <EOL> from . config import mode_with_gpu , test_ctx_name <EOL> gpu_ftensor4 = GpuArrayType ( dtype = '<STR_LIT>' , broadcastable = ( False , ) * <NUM_LIT:4> ) <EOL> class TestDnnConv2d ( test_abstract_conv . BaseTestConv2d ) : <EOL> def setUp ( self ) : <EOL> super ( TestDnnConv2d , self ) . setUp ( ) <EOL> self . shared = gpuarray_shared_constructor <EOL> self . provide_shape = [ False ] <EOL> def tcase ( self , i , f , s , b , flip , provide_shape ) : <EOL>", "answer": "if not dnn_available ( test_ctx_name ) :"}, {"prompt": "<s> import numpy <EOL> from chainer import cuda <EOL> from chainer import function <EOL> from chainer . utils import type_check <EOL> class Dropout ( function . Function ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , dropout_ratio ) : <EOL> self . dropout_ratio = dropout_ratio <EOL> def check_type_forwrad ( self , in_types ) : <EOL> type_check . expect ( in_types . size ( ) == <NUM_LIT:1> ) <EOL> def forward ( self , x ) : <EOL> scale = x [ <NUM_LIT:0> ] . dtype . type ( <NUM_LIT:1.> / ( <NUM_LIT:1> - self . dropout_ratio ) ) <EOL> xp = cuda . get_array_module ( * x ) <EOL> if xp == numpy : <EOL> flag = xp . random . rand ( * x [ <NUM_LIT:0> ] . shape ) >= self . dropout_ratio <EOL> else : <EOL> flag = ( xp . random . rand ( * x [ <NUM_LIT:0> ] . shape , dtype = numpy . float32 ) >= <EOL> self . dropout_ratio ) <EOL> self . mask = scale * flag <EOL>", "answer": "return x [ <NUM_LIT:0> ] * self . mask ,"}, {"prompt": "<s> from __future__ import print_function <EOL> import os <EOL> import shutil <EOL> import unittest <EOL> import subprocess <EOL> import shlex <EOL> import sqlite3 <EOL> def run_cmd ( cmd ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> process = subprocess . Popen ( shlex . split ( cmd ) , stdout = subprocess . PIPE , <EOL> stderr = subprocess . PIPE ) <EOL>", "answer": "( stdout , stderr ) = process . communicate ( )"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> from facebook import Facebook <EOL> __docformat__ = \"<STR_LIT>\" <EOL> try : <EOL> from paste . registry import StackedObjectProxy <EOL> from webob . exc import _HTTPMove <EOL> from paste . util . quoting import strip_html , html_quote , no_quote <EOL> except ImportError : <EOL> pass <EOL> else : <EOL> facebook = StackedObjectProxy ( name = \"<STR_LIT>\" ) <EOL> class CanvasRedirect ( _HTTPMove ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> title = \"<STR_LIT>\" <EOL> code = <NUM_LIT:200> <EOL> template = '<STR_LIT>' <EOL> def html ( self , environ ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> body = self . make_body ( environ , self . template , html_quote , no_quote ) <EOL> return body <EOL> class FacebookWSGIMiddleware ( object ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , app , config , facebook_class = Facebook ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> self . app = app <EOL> self . config = config <EOL> self . facebook_class = facebook_class <EOL> def __call__ ( self , environ , start_response ) : <EOL> config = self . config <EOL> real_facebook = self . facebook_class ( config [ \"<STR_LIT>\" ] , <EOL> config [ \"<STR_LIT>\" ] ) <EOL> registry = environ . get ( '<STR_LIT>' ) <EOL> if registry : <EOL> registry . register ( facebook , real_facebook ) <EOL> environ [ '<STR_LIT>' ] = real_facebook <EOL> return self . app ( environ , start_response ) <EOL> try : <EOL>", "answer": "import pylons"}, {"prompt": "<s> from . sub_resource import SubResource <EOL> class VpnClientRootCertificate ( SubResource ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL>", "answer": "_attribute_map = {"}, {"prompt": "<s> from pygments . style import Style <EOL> from pygments . token import Keyword , Name , Comment , String , Error , Number , Operator , Generic , Whitespace , Punctuation , Other , Literal <EOL> class KayleeStyle ( Style ) : <EOL> background_color = \"<STR_LIT>\" <EOL> default_style = \"<STR_LIT>\" <EOL> styles = { <EOL> Whitespace : \"<STR_LIT>\" , <EOL> Error : \"<STR_LIT>\" , <EOL> Other : \"<STR_LIT>\" , <EOL> Comment : \"<STR_LIT>\" , <EOL> Comment . Preproc : \"<STR_LIT>\" , <EOL> Keyword : \"<STR_LIT>\" , <EOL> Keyword . Constant : \"<STR_LIT>\" , <EOL> Keyword . Declaration : \"<STR_LIT>\" , <EOL> Keyword . Namespace : \"<STR_LIT>\" , <EOL> Keyword . Pseudo : \"<STR_LIT>\" , <EOL> Keyword . Reserved : \"<STR_LIT>\" , <EOL> Keyword . Type : \"<STR_LIT>\" , <EOL> Operator : \"<STR_LIT>\" , <EOL> Operator . Word : \"<STR_LIT>\" , <EOL> Punctuation : \"<STR_LIT>\" , <EOL> Name : \"<STR_LIT>\" , <EOL> Name . Attribute : \"<STR_LIT>\" , <EOL> Name . Builtin : \"<STR_LIT>\" , <EOL> Name . Builtin . Pseudo : \"<STR_LIT>\" , <EOL> Name . Class : \"<STR_LIT>\" , <EOL> Name . Constant : \"<STR_LIT>\" , <EOL> Name . Decorator : \"<STR_LIT>\" , <EOL> Name . Entity : \"<STR_LIT>\" , <EOL> Name . Exception : \"<STR_LIT>\" , <EOL> Name . Function : \"<STR_LIT>\" , <EOL> Name . Property : \"<STR_LIT>\" , <EOL> Name . Label : \"<STR_LIT>\" , <EOL> Name . Namespace : \"<STR_LIT>\" , <EOL> Name . Other : \"<STR_LIT>\" , <EOL> Name . Tag : \"<STR_LIT>\" , <EOL> Name . Variable : \"<STR_LIT>\" , <EOL> Name . Variable . Class : \"<STR_LIT>\" , <EOL> Name . Variable . Global : \"<STR_LIT>\" , <EOL> Name . Variable . Instance : \"<STR_LIT>\" , <EOL> Number : \"<STR_LIT>\" , <EOL> Literal : \"<STR_LIT>\" , <EOL> Literal . Date : \"<STR_LIT>\" , <EOL> String : \"<STR_LIT>\" , <EOL> String . Backtick : \"<STR_LIT>\" , <EOL>", "answer": "String . Char : \"<STR_LIT>\" ,"}, {"prompt": "<s> import argparse <EOL> import collections <EOL> import logging <EOL> import operator <EOL> import os <EOL> import re <EOL> import time <EOL> from launchpadlib import launchpad <EOL> import elastic_recheck . elasticRecheck as er <EOL> import elastic_recheck . results as er_results <EOL> LPCACHEDIR = os . path . expanduser ( '<STR_LIT>' ) <EOL> def get_options ( ) : <EOL> parser = argparse . ArgumentParser ( <EOL> description = '<STR_LIT>' ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = \"<STR_LIT>\" , <EOL> default = \"<STR_LIT>\" ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = \"<STR_LIT>\" , <EOL> type = bool , <EOL> default = False ) <EOL> parser . add_argument ( '<STR_LIT>' , '<STR_LIT>' , help = \"<STR_LIT>\" , <EOL> type = bool , <EOL> default = True ) <EOL> return parser . parse_args ( ) <EOL> def all_fails ( classifier ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> all_fails = { } <EOL> query = ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> results = classifier . hits_by_query ( query , size = <NUM_LIT> ) <EOL> facets = er_results . FacetSet ( ) <EOL> facets . detect_facets ( results , [ \"<STR_LIT>\" ] ) <EOL> for build in facets : <EOL> for result in facets [ build ] : <EOL> if re . search ( \"<STR_LIT>\" , result . project ) : <EOL> all_fails [ \"<STR_LIT>\" % ( build , result . build_name ) ] = False <EOL> return all_fails <EOL> def num_fails_per_build_name ( all_jobs ) : <EOL> counts = collections . defaultdict ( int ) <EOL> for f in all_jobs : <EOL> build , job = f . split ( '<STR_LIT:.>' , <NUM_LIT:1> ) <EOL> counts [ job ] += <NUM_LIT:1> <EOL> return counts <EOL> def classifying_rate ( fails , data ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> for bugnum in data : <EOL> bug = data [ bugnum ] <EOL> for job in bug [ '<STR_LIT>' ] : <EOL> fails [ job ] = True <EOL> total = len ( fails . keys ( ) ) <EOL> bad_jobs = collections . defaultdict ( int ) <EOL> count = <NUM_LIT:0> <EOL> for f in fails : <EOL> if fails [ f ] is True : <EOL> count += <NUM_LIT:1> <EOL> else : <EOL> build , job = f . split ( '<STR_LIT:.>' , <NUM_LIT:1> ) <EOL> bad_jobs [ job ] += <NUM_LIT:1> <EOL> print ( \"<STR_LIT>\" % <EOL> ( ( float ( count ) / float ( total ) ) * <NUM_LIT> ) ) <EOL> sort = sorted ( <EOL> bad_jobs . iteritems ( ) , <EOL> key = operator . itemgetter ( <NUM_LIT:1> ) , <EOL> reverse = True ) <EOL> print ( \"<STR_LIT>\" ) <EOL> for s in sort : <EOL> print \"<STR_LIT>\" % ( s [ <NUM_LIT:1> ] , s [ <NUM_LIT:0> ] ) <EOL> def _status_count ( results ) : <EOL> counts = { } <EOL> facets = er_results . FacetSet ( ) <EOL> facets . detect_facets ( <EOL> results , <EOL> [ \"<STR_LIT>\" , \"<STR_LIT>\" ] ) <EOL> for key in facets : <EOL> counts [ key ] = len ( facets [ key ] ) <EOL> return counts <EOL> def _failure_count ( hits ) : <EOL> if \"<STR_LIT>\" in hits : <EOL> return hits [ \"<STR_LIT>\" ] <EOL> else : <EOL> return <NUM_LIT:0> <EOL> def _failed_jobs ( results ) : <EOL> failed_jobs = [ ] <EOL> facets = er_results . FacetSet ( ) <EOL> facets . detect_facets ( <EOL> results , <EOL> [ \"<STR_LIT>\" , \"<STR_LIT>\" ] ) <EOL> if \"<STR_LIT>\" in facets : <EOL> for build in facets [ \"<STR_LIT>\" ] : <EOL> for result in facets [ \"<STR_LIT>\" ] [ build ] : <EOL> failed_jobs . append ( \"<STR_LIT>\" % ( build , result . build_name ) ) <EOL> return failed_jobs <EOL> def _count_fails_per_build_name ( hits ) : <EOL> facets = er_results . FacetSet ( ) <EOL> counts = collections . defaultdict ( int ) <EOL>", "answer": "facets . detect_facets ("}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import itertools <EOL> import numpy as np <EOL> import pickle , gzip <EOL> import re <EOL> import scipy . stats as ss <EOL> import sys <EOL> sys . path . append ( '<STR_LIT:.>' ) <EOL> import bbob_pproc as bb <EOL> import bbob_pproc . algportfolio <EOL> import bbob_pproc . bestalg <EOL> import bbob_pproc . readalign as ra <EOL> class PortfolioDataSets : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , algorithms = { } , strategies = { } , pickleFile = None ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if pickleFile is None : <EOL> self . algds = algorithms <EOL> self . stratds = strategies <EOL> self . _bestalg = None <EOL> self . _unifpf = None <EOL> else : <EOL> if pickleFile . find ( '<STR_LIT>' ) < <NUM_LIT:0> : <EOL> pickleFile += '<STR_LIT>' <EOL> with gzip . open ( pickleFile ) as f : <EOL> entry = pickle . load ( f ) <EOL> self . algds = entry . algds <EOL> self . stratds = entry . stratds <EOL> self . _bestalg = entry . _bestalg <EOL> self . _unifpf = entry . _unifpf <EOL> def add_algorithm ( self , name , ds ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> self . algds [ name ] = ds <EOL> self . _bestalg = None <EOL> self . _unfipf = None <EOL> def add_strategy ( self , name , ds ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> self . stratds [ name ] = ds <EOL> def bestalg ( self , dimfun ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if self . _bestalg is None : <EOL> self . _bestalg = bb . bestalg . generate ( self . algds ) <EOL> return self . _bestalg [ dimfun ] if dimfun is not None else self . _bestalg <EOL> def oracle ( self , dimfun ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> ( dim , funcId ) = dimfun <EOL> bestfinalfunval = max ( np . median ( self . bestalg ( dimfun ) . bestfinalfunvals ) , <NUM_LIT> ) <EOL> algs = list ( self . algds_dimfunc ( dimfun ) ) <EOL> maxevals = np . max ( [ ds . maxevals for ( name , ds ) in algs ] ) <EOL> evals = np . array ( [ ds . detEvals ( [ bestfinalfunval ] ) for ( name , ds ) in algs ] ) <EOL> nanmask = np . isnan ( evals ) <EOL> medevals = [ maxevals ] * len ( algs ) <EOL> for i in range ( len ( algs ) ) : <EOL> algnanmask = ~ np . isnan ( evals ) [ i ] <EOL> if np . any ( algnanmask ) : <EOL> medevals [ i ] = np . median ( evals [ i , algnanmask ] ) <EOL> else : <EOL> medevals [ i ] = maxevals <EOL> nametarget = [ ( algs [ i ] [ <NUM_LIT:0> ] , medevals [ i ] ) for i in range ( len ( algs ) ) ] <EOL> ( name , target ) = min ( nametarget , key = lambda k : k [ <NUM_LIT:1> ] ) <EOL> return self . algds [ name ] . dictByDimFunc ( ) [ dim ] [ funcId ] [ <NUM_LIT:0> ] <EOL> def unifpf ( self ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if self . _unifpf is None : <EOL> self . _unifpf = bb . algportfolio . build ( self . algds ) <EOL> return self . _unifpf <EOL> def pickle ( self , pickleFile ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if pickleFile . find ( '<STR_LIT>' ) < <NUM_LIT:0> : <EOL> pickleFile += '<STR_LIT>' <EOL> with gzip . open ( pickleFile , '<STR_LIT:w>' ) as f : <EOL> pickle . dump ( self , f ) <EOL> def algds_dimfunc ( self , dimfun ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> ( dim , funcId ) = dimfun <EOL> for ( algname , dset ) in self . algds . iteritems ( ) : <EOL> yield ( algname , dset . dictByDimFunc ( ) [ dim ] [ funcId ] [ <NUM_LIT:0> ] ) <EOL> def stratds_dimfunc ( self , dimfun ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> ( dim , funcId ) = dimfun <EOL> for ( stratname , dset ) in self . stratds . iteritems ( ) : <EOL> yield ( stratname , dset . dictByDimFunc ( ) [ dim ] [ funcId ] [ <NUM_LIT:0> ] ) <EOL> def maxevals ( self , dimfun ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> evals = [ np . median ( ds . maxevals ) for ( name , ds ) in self . algds_dimfunc ( dimfun ) ] <EOL> return max ( evals ) / dimfun [ <NUM_LIT:0> ] <EOL> def ranking ( self , dimfun , groupby , ftarget = <NUM_LIT:10> ** - <NUM_LIT:8> ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> nameds = list ( itertools . chain ( self . algds_dimfunc ( dimfun ) , self . stratds_dimfunc ( dimfun ) ) ) <EOL> count = len ( nameds ) <EOL> fvset = [ ] <EOL> for ( name , ds ) in nameds : <EOL> budgets = ds . funvals [ : , <NUM_LIT:0> ] <EOL> f1vals = np . maximum ( groupby ( ds . funvals [ : , <NUM_LIT:1> : ] , axis = <NUM_LIT:1> ) , ftarget ) <EOL> fv = np . transpose ( np . vstack ( [ budgets , f1vals ] ) ) <EOL> fvset . append ( fv ) <EOL> fva = ra . alignArrayData ( ra . VArrayMultiReader ( fvset ) ) <EOL> budgets = fva [ : , <NUM_LIT:0> ] <EOL> values = fva [ : , <NUM_LIT:1> : ] . copy ( ) <EOL> firstconv = np . ones ( count ) * ( np . size ( budgets ) + <NUM_LIT:1> ) <EOL> for i in range ( count ) : <EOL> try : <EOL> firstconv [ i ] = np . nonzero ( values [ : , i ] == ftarget ) [ <NUM_LIT:0> ] [ <NUM_LIT:0> ] <EOL> except IndexError : <EOL> continue <EOL> firstconvranks = ss . mstats . rankdata ( firstconv ) <EOL> for i in range ( count ) : <EOL> r = firstconvranks [ i ] <EOL> values [ firstconv [ i ] : , i ] = ftarget - ( <NUM_LIT:1> - r / count ) * ftarget <EOL> ranks = ss . mstats . rankdata ( values , axis = <NUM_LIT:1> ) <EOL> return np . transpose ( np . vstack ( [ budgets , ranks . T ] ) ) <EOL>", "answer": "def resolve_fid ( fid ) :"}, {"prompt": "<s> from jinja2 import Template <EOL> from urllib import urlencode <EOL> from graphitepager . level import Level <EOL> ALERT_MISSING_TEMPLATE = r\"\"\"<STR_LIT>\"\"\" <EOL> HTML_ALERT_MISSING_TEMPLATE = r\"\"\"<STR_LIT>\"\"\" <EOL> SLACK_ALERT_MISSING_TEMPLATE = r\"\"\"<STR_LIT>\"\"\" <EOL> STDOUT_MISSING_TEMPLATE = r\"\"\"<STR_LIT>\"\"\" <EOL> ALERT_TEMPLATE = r\"\"\"<STR_LIT>\"\"\" <EOL> HTML_ALERT_TEMPLATE = r\"\"\"<STR_LIT>\"\"\" <EOL> SLACK_ALERT_TEMPLATE = r\"\"\"<STR_LIT>\"\"\" <EOL> STDOUT_TEMPLATE = r\"\"\"<STR_LIT>\"\"\" <EOL> class Description ( object ) : <EOL> def __init__ ( self , template , graphite_url , alert , record , level , value ) : <EOL> self . template = template <EOL> self . graphite_url = graphite_url <EOL> self . alert = alert <EOL> self . record = record <EOL> self . level = level <EOL> self . value = value <EOL> def __str__ ( self ) : <EOL> return self . description_for_alert ( <EOL> self . template , <EOL> self . graphite_url , <EOL> self . alert , <EOL> self . record , <EOL> self . level , <EOL> self . value , <EOL> ) <EOL> def stdout ( self ) : <EOL> template = STDOUT_TEMPLATE <EOL> if self . level == Level . NO_DATA : <EOL> template = STDOUT_MISSING_TEMPLATE <EOL> return self . description_for_alert ( <EOL> template , <EOL> self . graphite_url , <EOL> self . alert , <EOL> self . record , <EOL> self . level , <EOL> self . value , <EOL> ) <EOL> def html ( self ) : <EOL> template = HTML_ALERT_TEMPLATE <EOL> if self . level == Level . NO_DATA : <EOL> template = HTML_ALERT_MISSING_TEMPLATE <EOL> return self . description_for_alert ( <EOL> template , <EOL> self . graphite_url , <EOL> self . alert , <EOL> self . record , <EOL> self . level , <EOL> self . value , <EOL> ) <EOL> def slack ( self ) : <EOL> template = SLACK_ALERT_TEMPLATE <EOL> if self . level == Level . NO_DATA : <EOL> template = SLACK_ALERT_MISSING_TEMPLATE <EOL> return self . description_for_alert ( <EOL> template , <EOL> self . graphite_url , <EOL> self . alert , <EOL> self . record , <EOL> self . level , <EOL> self . value , <EOL> ) <EOL> def description_for_alert ( self , <EOL> template , <EOL> graphite_url , <EOL> alert , <EOL> record , <EOL> level , <EOL> current_value ) : <EOL> context = dict ( locals ( ) ) <EOL> context [ '<STR_LIT>' ] = graphite_url <EOL> if type ( record ) == str : <EOL> context [ '<STR_LIT>' ] = alert . documentation_url ( ) <EOL> else : <EOL> context [ '<STR_LIT>' ] = alert . documentation_url ( record . target ) <EOL> url_params = ( <EOL> ( '<STR_LIT:width>' , <NUM_LIT> ) , <EOL> ( '<STR_LIT>' , <NUM_LIT> ) , <EOL> ( '<STR_LIT:target>' , alert . get ( '<STR_LIT:target>' ) ) , <EOL> ( '<STR_LIT:target>' , '<STR_LIT>' . format ( <EOL> alert . get ( '<STR_LIT>' ) ) ) , <EOL> ( '<STR_LIT:target>' , '<STR_LIT>' . format ( <EOL> alert . get ( '<STR_LIT>' ) ) ) , <EOL> ( '<STR_LIT>' , '<STR_LIT>' ) , <EOL> ) <EOL> url_args = urlencode ( url_params ) <EOL> url = '<STR_LIT>' . format ( graphite_url , url_args ) <EOL> context [ '<STR_LIT>' ] = url . replace ( '<STR_LIT>' , '<STR_LIT:http>' ) <EOL> context [ '<STR_LIT>' ] = alert . value_for_level ( level ) <EOL> if level == Level . NOMINAL : <EOL> context [ '<STR_LIT>' ] = '<STR_LIT>' <EOL> else : <EOL> context [ '<STR_LIT>' ] = level <EOL> return Template ( template ) . render ( context ) <EOL> def _get_description ( graphite_url , <EOL> alert , <EOL> record , <EOL> alert_level , <EOL> value , <EOL> alert_template ) : <EOL> return Description ( <EOL> alert_template , <EOL> graphite_url , <EOL> alert , <EOL> record , <EOL> alert_level , <EOL> value <EOL> ) <EOL> def get_description ( graphite_url , <EOL> alert , <EOL> record , <EOL> alert_level , <EOL> value ) : <EOL> return _get_description ( graphite_url , <EOL> alert , <EOL> record , <EOL> alert_level , <EOL> value , <EOL> ALERT_TEMPLATE ) <EOL> def missing_target_description ( graphite_url , <EOL> alert , <EOL> record , <EOL> alert_level , <EOL> value ) : <EOL>", "answer": "return _get_description ( graphite_url ,"}, {"prompt": "<s> import unittest <EOL> from freezer . openstack import openstack <EOL> from freezer . openstack import osclients <EOL> from freezer . storage import swift <EOL> from freezer . storage import base <EOL> class TestSwiftStorage ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . storage = swift . SwiftStorage ( <EOL> osclients . ClientManager ( <EOL> openstack . OpenstackOptions . create_from_env ( ) <EOL> ) , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> <NUM_LIT:100> , skip_prepare = True <EOL> ) <EOL> self . files = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> self . increments = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> ] <EOL> self . cycles_increments = [ <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL>", "answer": "\"<STR_LIT>\" ,"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> from django . conf . urls import url <EOL>", "answer": "from views import status"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> from django . conf import settings <EOL> from django . contrib import auth <EOL> from django . core . cache import cache <EOL> from django . core . mail import send_mail <EOL> from django . core . urlresolvers import reverse <EOL> from django . template . loader import render_to_string <EOL> from django . utils . decorators import method_decorator <EOL> from django . views . decorators . csrf import ensure_csrf_cookie <EOL> from django . views . generic import View <EOL> from wwwhisper_auth import http <EOL> from wwwhisper_auth import login_token <EOL> from wwwhisper_auth import models <EOL> from wwwhisper_auth import url_utils <EOL> from wwwhisper_auth . backend import AuthenticationError <EOL> import logging <EOL> import urllib <EOL> logger = logging . getLogger ( __name__ ) <EOL> def get_user ( request ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> user_id = request . session . get ( '<STR_LIT>' , None ) <EOL> if user_id is not None : <EOL> return request . site . users . get_unique ( lambda user : user . id == user_id ) <EOL> return None <EOL> class Auth ( View ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> @ http . never_ever_cache <EOL> def get ( self , request ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> encoded_path = self . _extract_encoded_path_argument ( request ) <EOL> if encoded_path is None : <EOL> return http . HttpResponseBadRequest ( <EOL> \"<STR_LIT>\" ) <EOL> if '<STR_LIT>' in request . META : <EOL> return http . HttpResponseBadRequest ( <EOL> \"<STR_LIT>\" ) <EOL> debug_msg = \"<STR_LIT>\" % ( encoded_path ) <EOL> path_validation_error = None <EOL> if url_utils . contains_fragment ( encoded_path ) : <EOL> path_validation_error = \"<STR_LIT>\" <EOL> else : <EOL> stripped_path = url_utils . strip_query ( encoded_path ) <EOL> decoded_path = url_utils . decode ( stripped_path ) <EOL> decoded_path = url_utils . collapse_slashes ( decoded_path ) <EOL> if not url_utils . is_canonical ( decoded_path ) : <EOL> path_validation_error = '<STR_LIT>' '<STR_LIT>' <EOL> if path_validation_error is not None : <EOL> logger . debug ( '<STR_LIT>' % ( debug_msg ) ) <EOL> return http . HttpResponseBadRequest ( path_validation_error ) <EOL> user = get_user ( request ) <EOL> location = request . site . locations . find_location ( decoded_path ) <EOL> if user is not None : <EOL> debug_msg += \"<STR_LIT>\" % ( user . email ) <EOL> respone = None <EOL> if location is not None and location . can_access ( user ) : <EOL> logger . debug ( '<STR_LIT>' % ( debug_msg ) ) <EOL> response = http . HttpResponseOK ( '<STR_LIT>' ) <EOL> else : <EOL> logger . debug ( '<STR_LIT>' % ( debug_msg ) ) <EOL> response = http . HttpResponseNotAuthorized ( <EOL> self . _html_or_none ( request , '<STR_LIT>' , <EOL> { '<STR_LIT:email>' : user . email } ) ) <EOL> response [ '<STR_LIT>' ] = user . email <EOL> return response <EOL> if ( location is not None and location . open_access_granted ( ) and <EOL> not location . open_access_requires_login ( ) ) : <EOL> logger . debug ( '<STR_LIT>' <EOL> % ( debug_msg ) ) <EOL> return http . HttpResponseOK ( '<STR_LIT>' ) <EOL> logger . debug ( '<STR_LIT>' % ( debug_msg ) ) <EOL> return http . HttpResponseNotAuthenticated ( <EOL> self . _html_or_none ( request , '<STR_LIT>' , request . site . skin ( ) ) ) <EOL> def _html_or_none ( self , request , template , context = { } ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if ( http . accepts_html ( request . META . get ( '<STR_LIT>' ) ) ) : <EOL> return render_to_string ( template , context ) <EOL> return None <EOL> @ staticmethod <EOL> def _extract_encoded_path_argument ( request ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> request_path_and_args = request . get_full_path ( ) <EOL> assert request_path_and_args . startswith ( request . path ) <EOL> args = request_path_and_args [ len ( request . path ) : ] <EOL> if not args . startswith ( '<STR_LIT>' ) : <EOL> return None <EOL> return args [ len ( '<STR_LIT>' ) : ] <EOL> class CsrfToken ( View ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> @ http . never_ever_cache <EOL> @ method_decorator ( ensure_csrf_cookie ) <EOL> def get ( self , request ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> return http . HttpResponseNoContent ( ) <EOL> class Login ( http . RestView ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def post ( self , request , assertion ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if assertion == None : <EOL> return http . HttpResponseBadRequest ( '<STR_LIT>' ) <EOL> try : <EOL> user = auth . authenticate ( site = request . site , <EOL> site_url = request . site_url , <EOL> assertion = assertion ) <EOL> except AuthenticationError as ex : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> return http . HttpResponseBadRequest ( str ( ex ) ) <EOL> if user is not None : <EOL> auth . login ( request , user ) <EOL> request . session [ '<STR_LIT>' ] = user . id <EOL> logger . debug ( '<STR_LIT>' % ( user . email ) ) <EOL> return http . HttpResponseNoContent ( ) <EOL> else : <EOL> return http . HttpResponseNotAuthorized ( ) <EOL> class LoginToken ( View ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> @ http . never_ever_cache <EOL> def get ( self , request ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> token = request . GET . get ( '<STR_LIT>' ) <EOL> if token == None : <EOL> return http . HttpResponseBadRequest ( '<STR_LIT>' ) <EOL> try : <EOL> user = auth . authenticate ( site = request . site , <EOL> site_url = request . site_url , <EOL> token = token ) <EOL> except AuthenticationError as ex : <EOL> logger . debug ( '<STR_LIT>' ) <EOL> return http . HttpResponseBadRequest ( str ( ex ) ) <EOL> if user is not None : <EOL> auth . login ( request , user ) <EOL> request . session [ '<STR_LIT>' ] = user . id <EOL>", "answer": "logger . debug ( '<STR_LIT>' % ( user . email ) )"}, {"prompt": "<s> import mock <EOL> from nose . tools import * <EOL> from tests . base import OsfTestCase <EOL> from website . addons . dropbox . tests . factories import ( <EOL> DropboxUserSettingsFactory , <EOL> DropboxNodeSettingsFactory , <EOL> DropboxAccountFactory <EOL> ) <EOL>", "answer": "from website . addons . dropbox . model import DropboxNodeSettings"}, {"prompt": "<s> from django import template <EOL> from adv_cache_tag . tag import CacheTag , Node <EOL> register = template . Library ( ) <EOL> class TestNode ( Node ) : <EOL> def __init__ ( self , nodename , nodelist , expire_time , multiplicator , fragment_name , vary_on ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> super ( TestNode , self ) . __init__ ( nodename , nodelist , expire_time , fragment_name , vary_on ) <EOL> self . multiplicator = multiplicator <EOL> class TestCacheTag ( CacheTag ) : <EOL> class Meta ( CacheTag . Meta ) : <EOL> compress_spaces = True <EOL> Node = TestNode <EOL> @ classmethod <EOL> def get_template_node_arguments ( cls , tokens ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if len ( tokens ) < <NUM_LIT:4> : <EOL> raise template . TemplateSyntaxError ( <EOL> \"<STR_LIT>\" % tokens [ <NUM_LIT:0> ] ) <EOL> return tokens [ <NUM_LIT:1> ] , tokens [ <NUM_LIT:2> ] , tokens [ <NUM_LIT:3> ] , tokens [ <NUM_LIT:4> : ] <EOL>", "answer": "def prepare_params ( self ) :"}, {"prompt": "<s> from pyswagger import SwaggerApp , SwaggerSecurity <EOL> from . . utils import get_test_data_folder <EOL> import unittest <EOL> app = SwaggerApp . _create_ ( get_test_data_folder ( version = '<STR_LIT>' , which = '<STR_LIT>' ) ) <EOL> class BasicAuthAndApiKeyTestCase ( unittest . TestCase ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def setUp ( self ) : <EOL> self . s = SwaggerSecurity ( app ) <EOL> self . s . update_with ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> self . s . update_with ( '<STR_LIT>' , ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> self . s . update_with ( '<STR_LIT>' , ( '<STR_LIT>' , '<STR_LIT>' ) ) <EOL> self . s . update_with ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> def test_deleteUser ( self ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> req , _ = app . op [ '<STR_LIT>' ] ( username = '<STR_LIT>' ) <EOL> self . s ( req ) . prepare ( ) <EOL> self . assertTrue ( '<STR_LIT>' in req . header ) <EOL> self . assertEqual ( req . header [ '<STR_LIT>' ] , '<STR_LIT>' ) <EOL> def test_getUserByName ( self ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL>", "answer": "req , _ = app . op [ '<STR_LIT>' ] ( username = '<STR_LIT>' )"}, {"prompt": "<s> from django . utils . translation import ugettext as _ <EOL> from django . contrib . syndication . views import Feed <EOL> from django . shortcuts import get_object_or_404 <EOL> from django . core . urlresolvers import reverse <EOL> from models import Vote , Bill <EOL> class Votes ( Feed ) : <EOL>", "answer": "title = _ ( \"<STR_LIT>\" )"}, {"prompt": "<s> from __future__ import absolute_import , unicode_literals <EOL>", "answer": "from django . apps import AppConfig"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import os <EOL> import sys <EOL> from django . core . wsgi import get_wsgi_application <EOL> sys . path . insert ( <EOL>", "answer": "<NUM_LIT:0> ,"}, {"prompt": "<s> from __future__ import ( absolute_import , division , generators , nested_scopes , print_function , <EOL> unicode_literals , with_statement ) <EOL> import unittest <EOL> from pants . engine . exp . addressable import ( Exactly , MutationError , NotSerializableError , <EOL> SubclassesOf , SuperclassesOf , TypeConstraintError , <EOL> addressable , addressable_dict , addressable_list ) <EOL> from pants . engine . exp . objects import Resolvable , Serializable <EOL> class TypeConstraintTestBase ( unittest . TestCase ) : <EOL> class A ( object ) : <EOL> pass <EOL> class B ( A ) : <EOL> pass <EOL> class C ( B ) : <EOL> pass <EOL> class BPrime ( A ) : <EOL> pass <EOL> class SuperclassesOfTest ( TypeConstraintTestBase ) : <EOL> def test_none ( self ) : <EOL> with self . assertRaises ( ValueError ) : <EOL> SubclassesOf ( ) <EOL> def test_single ( self ) : <EOL> superclasses_of_b = SuperclassesOf ( self . B ) <EOL> self . assertEqual ( ( self . B , ) , superclasses_of_b . types ) <EOL> self . assertTrue ( superclasses_of_b . satisfied_by ( self . A ( ) ) ) <EOL> self . assertTrue ( superclasses_of_b . satisfied_by ( self . B ( ) ) ) <EOL> self . assertFalse ( superclasses_of_b . satisfied_by ( self . BPrime ( ) ) ) <EOL> self . assertFalse ( superclasses_of_b . satisfied_by ( self . C ( ) ) ) <EOL> def test_multiple ( self ) : <EOL> superclasses_of_a_or_b = SuperclassesOf ( self . A , self . B ) <EOL> self . assertEqual ( ( self . A , self . B ) , superclasses_of_a_or_b . types ) <EOL> self . assertTrue ( superclasses_of_a_or_b . satisfied_by ( self . A ( ) ) ) <EOL> self . assertTrue ( superclasses_of_a_or_b . satisfied_by ( self . B ( ) ) ) <EOL> self . assertFalse ( superclasses_of_a_or_b . satisfied_by ( self . BPrime ( ) ) ) <EOL> self . assertFalse ( superclasses_of_a_or_b . satisfied_by ( self . C ( ) ) ) <EOL> class ExactlyTest ( TypeConstraintTestBase ) : <EOL> def test_none ( self ) : <EOL> with self . assertRaises ( ValueError ) : <EOL> Exactly ( ) <EOL> def test_single ( self ) : <EOL> exactly_b = Exactly ( self . B ) <EOL> self . assertEqual ( ( self . B , ) , exactly_b . types ) <EOL> self . assertFalse ( exactly_b . satisfied_by ( self . A ( ) ) ) <EOL> self . assertTrue ( exactly_b . satisfied_by ( self . B ( ) ) ) <EOL> self . assertFalse ( exactly_b . satisfied_by ( self . BPrime ( ) ) ) <EOL> self . assertFalse ( exactly_b . satisfied_by ( self . C ( ) ) ) <EOL> def test_multiple ( self ) : <EOL> exactly_a_or_b = Exactly ( self . A , self . B ) <EOL> self . assertEqual ( ( self . A , self . B ) , exactly_a_or_b . types ) <EOL> self . assertTrue ( exactly_a_or_b . satisfied_by ( self . A ( ) ) ) <EOL> self . assertTrue ( exactly_a_or_b . satisfied_by ( self . B ( ) ) ) <EOL> self . assertFalse ( exactly_a_or_b . satisfied_by ( self . BPrime ( ) ) ) <EOL> self . assertFalse ( exactly_a_or_b . satisfied_by ( self . C ( ) ) ) <EOL> class SubclassesOfTest ( TypeConstraintTestBase ) : <EOL> def test_none ( self ) : <EOL> with self . assertRaises ( ValueError ) : <EOL> SubclassesOf ( ) <EOL> def test_single ( self ) : <EOL> subclasses_of_b = SubclassesOf ( self . B ) <EOL> self . assertEqual ( ( self . B , ) , subclasses_of_b . types ) <EOL> self . assertFalse ( subclasses_of_b . satisfied_by ( self . A ( ) ) ) <EOL> self . assertTrue ( subclasses_of_b . satisfied_by ( self . B ( ) ) ) <EOL> self . assertFalse ( subclasses_of_b . satisfied_by ( self . BPrime ( ) ) ) <EOL> self . assertTrue ( subclasses_of_b . satisfied_by ( self . C ( ) ) ) <EOL> def test_multiple ( self ) : <EOL> subclasses_of_b_or_c = SubclassesOf ( self . B , self . C ) <EOL> self . assertEqual ( ( self . B , self . C ) , subclasses_of_b_or_c . types ) <EOL> self . assertTrue ( subclasses_of_b_or_c . satisfied_by ( self . B ( ) ) ) <EOL> self . assertTrue ( subclasses_of_b_or_c . satisfied_by ( self . C ( ) ) ) <EOL> self . assertFalse ( subclasses_of_b_or_c . satisfied_by ( self . BPrime ( ) ) ) <EOL> self . assertFalse ( subclasses_of_b_or_c . satisfied_by ( self . A ( ) ) ) <EOL> class SimpleSerializable ( Serializable ) : <EOL> def __init__ ( self , ** kwargs ) : <EOL> self . _kwargs = kwargs <EOL> def _asdict ( self ) : <EOL> return self . _kwargs <EOL> class CountingResolvable ( Resolvable ) : <EOL> def __init__ ( self , address , value ) : <EOL> self . _address = address <EOL> self . _value = value <EOL> self . _resolutions = <NUM_LIT:0> <EOL> @ property <EOL> def address ( self ) : <EOL> return self . _address <EOL> def resolve ( self ) : <EOL> try : <EOL> return self . _value <EOL> finally : <EOL> self . _resolutions += <NUM_LIT:1> <EOL> @ property <EOL> def resolutions ( self ) : <EOL> return self . _resolutions <EOL> class AddressableDescriptorTest ( unittest . TestCase ) : <EOL> def test_inappropriate_application ( self ) : <EOL> class NotSerializable ( object ) : <EOL> def __init__ ( self , count ) : <EOL> super ( NotSerializable , self ) . __init__ ( ) <EOL> self . count = count <EOL> @ addressable ( Exactly ( int ) ) <EOL> def count ( self ) : <EOL> pass <EOL> with self . assertRaises ( NotSerializableError ) : <EOL> NotSerializable ( <NUM_LIT> ) <EOL> class AddressableTest ( unittest . TestCase ) : <EOL> class Person ( SimpleSerializable ) : <EOL> def __init__ ( self , age ) : <EOL> super ( AddressableTest . Person , self ) . __init__ ( ) <EOL> self . age = age <EOL> @ addressable ( Exactly ( int ) ) <EOL> def age ( self ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def test_none ( self ) : <EOL> person = self . Person ( None ) <EOL> self . assertIsNone ( person . age , None ) <EOL> def test_value ( self ) : <EOL> person = self . Person ( <NUM_LIT> ) <EOL> self . assertEqual ( <NUM_LIT> , person . age ) <EOL> def test_address ( self ) : <EOL> person = self . Person ( '<STR_LIT>' ) <EOL> self . assertEqual ( '<STR_LIT>' , person . age ) <EOL> def test_resolvable ( self ) : <EOL> resolvable_age = CountingResolvable ( '<STR_LIT>' , <NUM_LIT> ) <EOL> person = self . Person ( resolvable_age ) <EOL> self . assertEqual ( <NUM_LIT:0> , resolvable_age . resolutions ) <EOL> self . assertEqual ( <NUM_LIT> , person . age ) <EOL> self . assertEqual ( <NUM_LIT:1> , resolvable_age . resolutions ) <EOL> self . assertEqual ( <NUM_LIT> , person . age ) <EOL> self . assertEqual ( <NUM_LIT:2> , resolvable_age . resolutions ) <EOL> def test_type_mismatch_value ( self ) : <EOL> with self . assertRaises ( TypeConstraintError ) : <EOL> self . Person ( <NUM_LIT> ) <EOL> def test_type_mismatch_resolvable ( self ) : <EOL> resolvable_age = CountingResolvable ( '<STR_LIT>' , <NUM_LIT> ) <EOL> person = self . Person ( resolvable_age ) <EOL> with self . assertRaises ( TypeConstraintError ) : <EOL> person . age <EOL> def test_single_assignment ( self ) : <EOL> person = self . Person ( <NUM_LIT> ) <EOL>", "answer": "with self . assertRaises ( MutationError ) :"}, {"prompt": "<s> from django . contrib . staticfiles . urls import staticfiles_urlpatterns <EOL> from django . conf . urls import patterns , include , url <EOL> from django . core . urlresolvers import reverse , RegexURLPattern <EOL> from django . conf import settings <EOL> from django . conf . urls . i18n import i18n_patterns <EOL>", "answer": "from django . utils import importlib"}, {"prompt": "<s> from __future__ import unicode_literals <EOL>", "answer": "default_app_config = '<STR_LIT>' "}, {"prompt": "<s> import sys <EOL> import re <EOL> from gdcmdtools . base import BASE_INFO <EOL> from gdcmdtools . base import DEBUG_LEVEL <EOL> from gdcmdtools . get import GDGet <EOL> from gdcmdtools . get import export_format <EOL> import argparse <EOL> from argparse import RawTextHelpFormatter <EOL> from pprint import pprint <EOL> import logging <EOL> logger = logging . getLogger ( ) <EOL> __THIS_APP = '<STR_LIT>' <EOL> __THIS_DESCRIPTION = '<STR_LIT>' <EOL> __THIS_VERSION = BASE_INFO [ \"<STR_LIT:version>\" ] <EOL> def test ( ) : <EOL> assert True <EOL> if __name__ == '<STR_LIT:__main__>' : <EOL> arg_parser = argparse . ArgumentParser ( <EOL> description = '<STR_LIT>' % <EOL> ( __THIS_APP , <EOL> __THIS_VERSION , <EOL> __THIS_DESCRIPTION , <EOL> BASE_INFO [ \"<STR_LIT>\" ] , <EOL> BASE_INFO [ \"<STR_LIT:description>\" ] ) , <EOL> formatter_class = RawTextHelpFormatter ) <EOL> arg_parser . add_argument ( <EOL> '<STR_LIT>' , <EOL> help = '<STR_LIT>' ) <EOL> help_export_format = \"<STR_LIT:\\n>\" . join ( <EOL> [ <EOL> re . search ( <EOL>", "answer": "\"<STR_LIT>\" ,"}, {"prompt": "<s> import py <EOL> class TestCollectDeprecated : <EOL> def test_collect_with_deprecated_run_and_join ( self , testdir , recwarn ) : <EOL> testdir . makepyfile ( conftest = \"\"\"<STR_LIT>\"\"\" ) <EOL> p = testdir . makepyfile ( somefile = \"\"\"<STR_LIT>\"\"\" ) <EOL> config = testdir . parseconfig ( ) <EOL> dirnode = config . getfsnode ( p . dirpath ( ) ) <EOL> colitems = dirnode . collect ( ) <EOL> w = recwarn . pop ( DeprecationWarning ) <EOL> assert w . filename . find ( \"<STR_LIT>\" ) != - <NUM_LIT:1> <EOL> assert len ( colitems ) == <NUM_LIT:1> <EOL> modcol = colitems [ <NUM_LIT:0> ] <EOL> assert modcol . name == \"<STR_LIT>\" <EOL>", "answer": "colitems = modcol . collect ( )"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import click <EOL> from SoftLayer . CLI import formatting <EOL> TEMPLATE_MSG = \"<STR_LIT>\" <EOL> def get_ticket_results ( mgr , ticket_id , update_count = <NUM_LIT:1> ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> ticket = mgr . get_ticket ( ticket_id ) <EOL> table = formatting . KeyValueTable ( [ '<STR_LIT:name>' , '<STR_LIT:value>' ] ) <EOL> table . align [ '<STR_LIT:name>' ] = '<STR_LIT:r>' <EOL> table . align [ '<STR_LIT:value>' ] = '<STR_LIT:l>' <EOL> table . add_row ( [ '<STR_LIT:id>' , ticket [ '<STR_LIT:id>' ] ] ) <EOL> table . add_row ( [ '<STR_LIT:title>' , ticket [ '<STR_LIT:title>' ] ] ) <EOL> if ticket . get ( '<STR_LIT>' ) : <EOL> user = ticket [ '<STR_LIT>' ] <EOL>", "answer": "table . add_row ( ["}, {"prompt": "<s> import shutil <EOL> import sys <EOL> import os , os . path <EOL> import imp <EOL> import blogofile . main <EOL> from blogofile import argparse <EOL> def setup ( parent_parser , parser_template ) : <EOL> from . import __dist__ <EOL> cmd_subparsers = parent_parser . add_subparsers ( ) <EOL> command1 = cmd_subparsers . add_parser ( <EOL>", "answer": "\"<STR_LIT>\" , help = \"<STR_LIT>\" , parents = [ parser_template ] )"}, {"prompt": "<s> try : <EOL> import unittest2 as unittest <EOL> except ImportError : <EOL> import unittest <EOL> from sourcemap . objects import Token , SourceMapIndex <EOL> class TokenTestCase ( unittest . TestCase ) : <EOL> def test_eq ( self ) : <EOL> assert Token ( <NUM_LIT:1> , <NUM_LIT:1> , '<STR_LIT>' , <NUM_LIT:1> , <NUM_LIT:1> , '<STR_LIT>' ) == Token ( <NUM_LIT:1> , <NUM_LIT:1> , '<STR_LIT>' , <NUM_LIT:1> , <NUM_LIT:1> , '<STR_LIT>' ) <EOL> assert Token ( <NUM_LIT> , <NUM_LIT:1> , '<STR_LIT>' , <NUM_LIT:1> , <NUM_LIT:1> , '<STR_LIT>' ) != Token ( <NUM_LIT:1> , <NUM_LIT:1> , '<STR_LIT>' , <NUM_LIT:1> , <NUM_LIT:1> , '<STR_LIT>' ) <EOL> class SourceMapIndexTestCase ( unittest . TestCase ) : <EOL> def get_index ( self ) : <EOL> tokens = [ <EOL> Token ( dst_line = <NUM_LIT:0> , dst_col = <NUM_LIT:0> ) , <EOL> Token ( dst_line = <NUM_LIT:0> , dst_col = <NUM_LIT:5> ) , <EOL> Token ( dst_line = <NUM_LIT:1> , dst_col = <NUM_LIT:0> ) , <EOL> Token ( dst_line = <NUM_LIT:1> , dst_col = <NUM_LIT:12> ) , <EOL> ] <EOL> rows = [ <EOL> [ <NUM_LIT:0> , <NUM_LIT:5> ] , <EOL> [ <NUM_LIT:0> , <NUM_LIT:12> ] , <EOL> ] <EOL> index = { <EOL> ( <NUM_LIT:0> , <NUM_LIT:0> ) : tokens [ <NUM_LIT:0> ] , <EOL> ( <NUM_LIT:0> , <NUM_LIT:5> ) : tokens [ <NUM_LIT:1> ] , <EOL> ( <NUM_LIT:1> , <NUM_LIT:0> ) : tokens [ <NUM_LIT:2> ] , <EOL> ( <NUM_LIT:1> , <NUM_LIT:12> ) : tokens [ <NUM_LIT:3> ] , <EOL> } <EOL> raw = { } <EOL> return SourceMapIndex ( raw , tokens , rows , index ) , tokens <EOL> def test_lookup ( self ) : <EOL> index , tokens = self . get_index ( ) <EOL> for i in range ( <NUM_LIT:5> ) : <EOL> assert index . lookup ( <NUM_LIT:0> , i ) is tokens [ <NUM_LIT:0> ] <EOL> for i in range ( <NUM_LIT:5> , <NUM_LIT:10> ) : <EOL> assert index . lookup ( <NUM_LIT:0> , i ) is tokens [ <NUM_LIT:1> ] <EOL> for i in range ( <NUM_LIT:12> ) : <EOL> assert index . lookup ( <NUM_LIT:1> , i ) is tokens [ <NUM_LIT:2> ] <EOL> for i in range ( <NUM_LIT:12> , <NUM_LIT:20> ) : <EOL> assert index . lookup ( <NUM_LIT:1> , i ) is tokens [ <NUM_LIT:3> ] <EOL> def test_getitem ( self ) : <EOL> index , tokens = self . get_index ( ) <EOL> for i in range ( <NUM_LIT:4> ) : <EOL> assert index [ i ] is tokens [ i ] <EOL> def test_iter ( self ) : <EOL> index , tokens = self . get_index ( ) <EOL> for idx , token in enumerate ( index ) : <EOL>", "answer": "assert token is tokens [ idx ]"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import sys <EOL> import time <EOL> from subprocess import call as subcall <EOL> app = '<STR_LIT>' <EOL> version = __import__ ( app ) . __version__ <EOL> def call ( cmd ) : <EOL>", "answer": "try :"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> from __future__ import division , absolute_import <EOL> from functools import wraps <EOL> class DummyLock ( object ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __reduce__ ( self ) : <EOL> return ( unpickle_lock , ( ) ) <EOL> def unpickle_lock ( ) : <EOL> if threadingmodule is not None : <EOL> return XLock ( ) <EOL> else : <EOL> return DummyLock ( ) <EOL> unpickle_lock . __safe_for_unpickling__ = True <EOL> def _synchPre ( self ) : <EOL> if '<STR_LIT>' not in self . __dict__ : <EOL> _synchLockCreator . acquire ( ) <EOL> if '<STR_LIT>' not in self . __dict__ : <EOL> self . __dict__ [ '<STR_LIT>' ] = XLock ( ) <EOL> _synchLockCreator . release ( ) <EOL> self . _threadable_lock . acquire ( ) <EOL> def _synchPost ( self ) : <EOL> self . _threadable_lock . release ( ) <EOL> def _sync ( klass , function ) : <EOL> @ wraps ( function ) <EOL> def sync ( self , * args , ** kwargs ) : <EOL> _synchPre ( self ) <EOL> try : <EOL> return function ( self , * args , ** kwargs ) <EOL> finally : <EOL> _synchPost ( self ) <EOL> return sync <EOL> def synchronize ( * klasses ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if threadingmodule is not None : <EOL> for klass in klasses : <EOL> for methodName in klass . synchronized : <EOL> sync = _sync ( klass , klass . __dict__ [ methodName ] ) <EOL> setattr ( klass , methodName , sync ) <EOL> def init ( with_threads = <NUM_LIT:1> ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> global threaded , _synchLockCreator , XLock <EOL> if with_threads : <EOL> if not threaded : <EOL> if threadingmodule is not None : <EOL> threaded = True <EOL> class XLock ( threadingmodule . _RLock , object ) : <EOL> def __reduce__ ( self ) : <EOL> return ( unpickle_lock , ( ) ) <EOL> _synchLockCreator = XLock ( ) <EOL> else : <EOL> raise RuntimeError ( \"<STR_LIT>\" ) <EOL> else : <EOL> if threaded : <EOL> raise RuntimeError ( \"<STR_LIT>\" ) <EOL> else : <EOL> pass <EOL> _dummyID = object ( ) <EOL> def getThreadID ( ) : <EOL> if threadingmodule is None : <EOL> return _dummyID <EOL> return threadingmodule . currentThread ( ) . ident <EOL> def isInIOThread ( ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> return ioThread == getThreadID ( ) <EOL> def registerAsIOThread ( ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> global ioThread <EOL> ioThread = getThreadID ( ) <EOL> ioThread = None <EOL> threaded = False <EOL>", "answer": "try :"}, {"prompt": "<s> import eventlet <EOL> import random <EOL> import six <EOL> from oslo_config import cfg <EOL> from oslo_serialization import jsonutils <EOL> from neutron . agent . linux . utils import wait_until_true <EOL> from dragonflow . common import utils as df_utils <EOL> from dragonflow . db . db_common import DbUpdate , SEND_ALL_TOPIC <EOL> from dragonflow . db . pub_sub_api import TableMonitor <EOL> from dragonflow . tests . common import utils as test_utils <EOL> from dragonflow . tests . fullstack import test_base <EOL> from dragonflow . tests . fullstack import test_objects as objects <EOL> events_num = <NUM_LIT:0> <EOL> def get_publisher ( ) : <EOL> pub_sub_driver = df_utils . load_driver ( <EOL> cfg . CONF . df . pub_sub_multiproc_driver , <EOL> df_utils . DF_PUBSUB_DRIVER_NAMESPACE ) <EOL> publisher = pub_sub_driver . get_publisher ( ) <EOL> publisher . initialize ( ) <EOL> return publisher <EOL> def get_subscriber ( callback ) : <EOL> pub_sub_driver = df_utils . load_driver ( <EOL> cfg . CONF . df . pub_sub_driver , <EOL> df_utils . DF_PUBSUB_DRIVER_NAMESPACE ) <EOL> subscriber = pub_sub_driver . get_subscriber ( ) <EOL> subscriber . initialize ( callback ) <EOL> uri = '<STR_LIT>' % ( <EOL> cfg . CONF . df . publisher_transport , <EOL> '<STR_LIT:127.0.0.1>' , <EOL> cfg . CONF . df . publisher_port <EOL> ) <EOL> subscriber . register_listen_address ( uri ) <EOL> subscriber . daemonize ( ) <EOL> return subscriber <EOL> class Namespace ( object ) : <EOL> pass <EOL> class TestPubSub ( test_base . DFTestBase ) : <EOL> def setUp ( self ) : <EOL> super ( TestPubSub , self ) . setUp ( ) <EOL> self . events_num = <NUM_LIT:0> <EOL> self . do_test = cfg . CONF . df . enable_df_pub_sub <EOL> self . key = '<STR_LIT>' . format ( random . random ( ) ) <EOL> def test_pub_sub_add_port ( self ) : <EOL> global events_num <EOL> local_event_num = <NUM_LIT:0> <EOL> if not self . do_test : <EOL> return <EOL> def _db_change_callback ( table , key , action , value , topic ) : <EOL> global events_num <EOL> events_num += <NUM_LIT:1> <EOL> subscriber = get_subscriber ( _db_change_callback ) <EOL> network = self . store ( objects . NetworkTestObj ( self . neutron , self . nb_api ) ) <EOL> network_id = network . create ( ) <EOL> eventlet . sleep ( test_utils . DEFAULT_CMD_TIMEOUT ) <EOL> self . assertNotEqual ( local_event_num , events_num ) <EOL> local_event_num = events_num <EOL> port = self . store ( objects . PortTestObj ( <EOL> self . neutron , <EOL> self . nb_api , <EOL> network_id <EOL> ) ) <EOL> port . create ( ) <EOL> eventlet . sleep ( test_utils . DEFAULT_CMD_TIMEOUT ) <EOL> self . assertNotEqual ( local_event_num , events_num ) <EOL> local_event_num = events_num <EOL> port . close ( ) <EOL> eventlet . sleep ( test_utils . DEFAULT_CMD_TIMEOUT ) <EOL> self . assertNotEqual ( local_event_num , events_num ) <EOL> local_event_num = events_num <EOL> network . close ( ) <EOL> eventlet . sleep ( test_utils . DEFAULT_CMD_TIMEOUT ) <EOL> self . assertNotEqual ( local_event_num , events_num ) <EOL> subscriber . stop ( ) <EOL> self . assertFalse ( network . exists ( ) ) <EOL> def test_pub_sub_update_port ( self ) : <EOL> ns = Namespace ( ) <EOL> ns . events_num = <NUM_LIT:0> <EOL> local_event_num = <NUM_LIT:0> <EOL> if not self . do_test : <EOL> return <EOL> def _db_change_callback ( table , key , action , value , topic ) : <EOL> ns . events_num += <NUM_LIT:1> <EOL> subscriber = get_subscriber ( _db_change_callback ) <EOL> network = self . store ( objects . NetworkTestObj ( self . neutron , self . nb_api ) ) <EOL> network_id = network . create ( ) <EOL> eventlet . sleep ( test_utils . DEFAULT_CMD_TIMEOUT ) <EOL> self . assertNotEqual ( local_event_num , ns . events_num ) <EOL> port = self . store ( objects . PortTestObj ( <EOL> self . neutron , <EOL> self . nb_api , <EOL> network_id <EOL> ) ) <EOL> local_event_num = ns . events_num <EOL> port_id = port . create ( ) <EOL> eventlet . sleep ( test_utils . DEFAULT_CMD_TIMEOUT ) <EOL> self . assertNotEqual ( local_event_num , ns . events_num ) <EOL> local_event_num = ns . events_num <EOL> update = { '<STR_LIT:port>' : { '<STR_LIT:name>' : '<STR_LIT:test>' } } <EOL> for i in six . moves . range ( <NUM_LIT:100> ) : <EOL> name = \"<STR_LIT>\" % i <EOL> update [ '<STR_LIT:port>' ] [ '<STR_LIT:name>' ] = name <EOL> self . neutron . update_port ( port_id , update ) <EOL> eventlet . sleep ( <NUM_LIT:0> ) <EOL> eventlet . sleep ( <NUM_LIT:1> ) <EOL> self . assertGreaterEqual ( ns . events_num , local_event_num + <NUM_LIT:100> ) <EOL> local_event_num = ns . events_num <EOL> port . close ( ) <EOL> eventlet . sleep ( test_utils . DEFAULT_CMD_TIMEOUT ) <EOL> self . assertNotEqual ( local_event_num , ns . events_num ) <EOL> local_event_num = ns . events_num <EOL> network . close ( ) <EOL> eventlet . sleep ( test_utils . DEFAULT_CMD_TIMEOUT ) <EOL> self . assertNotEqual ( local_event_num , events_num ) <EOL> subscriber . stop ( ) <EOL> self . assertFalse ( network . exists ( ) ) <EOL> def test_pub_sub_event_number_diffrent_port ( self ) : <EOL> if not self . do_test : <EOL> return <EOL> ns = Namespace ( ) <EOL> ns . events_num = <NUM_LIT:0> <EOL> ns . events_action = None <EOL> def _db_change_callback ( table , key , action , value , topic ) : <EOL> if '<STR_LIT>' == key : <EOL> ns . events_num += <NUM_LIT:1> <EOL> ns . events_action = action <EOL> publisher = get_publisher ( ) <EOL> subscriber = get_subscriber ( _db_change_callback ) <EOL> eventlet . sleep ( <NUM_LIT:2> ) <EOL> local_events_num = ns . events_num <EOL> action = \"<STR_LIT>\" <EOL> update = DbUpdate ( '<STR_LIT:info>' , '<STR_LIT>' , action , \"<STR_LIT>\" ) <EOL> publisher . send_event ( update ) <EOL> eventlet . sleep ( <NUM_LIT:1> ) <EOL> self . assertEqual ( local_events_num + <NUM_LIT:1> , ns . events_num ) <EOL> self . assertEqual ( ns . events_action , action ) <EOL> local_events_num = ns . events_num <EOL> for i in six . moves . range ( <NUM_LIT:100> ) : <EOL> publisher . send_event ( update ) <EOL> eventlet . sleep ( <NUM_LIT> ) <EOL> eventlet . sleep ( <NUM_LIT:1> ) <EOL> self . assertEqual ( local_events_num + <NUM_LIT:100> , ns . events_num ) <EOL> subscriber . stop ( ) <EOL> def test_pub_sub_add_topic ( self ) : <EOL> if not self . do_test : <EOL> return <EOL> self . events_num_t = <NUM_LIT:0> <EOL> self . events_action_t = None <EOL> def _db_change_callback_topic ( table , key , action , value , topic ) : <EOL> if '<STR_LIT>' == key : <EOL> self . events_num_t += <NUM_LIT:1> <EOL> self . events_action_t = action <EOL> publisher = get_publisher ( ) <EOL> subscriber = get_subscriber ( _db_change_callback_topic ) <EOL> eventlet . sleep ( <NUM_LIT:2> ) <EOL> topic = \"<STR_LIT>\" <EOL> subscriber . register_topic ( topic ) <EOL> eventlet . sleep ( <NUM_LIT:0.5> ) <EOL> local_events_num = self . events_num_t <EOL> action = \"<STR_LIT>\" <EOL> update = DbUpdate ( <EOL> '<STR_LIT:info>' , <EOL> '<STR_LIT>' , <EOL> action , <EOL> \"<STR_LIT>\" <EOL> ) <EOL> publisher . send_event ( update , topic ) <EOL> eventlet . sleep ( <NUM_LIT:1> ) <EOL> self . assertEqual ( self . events_action_t , action ) <EOL> self . assertEqual ( local_events_num + <NUM_LIT:1> , self . events_num_t ) <EOL> no_topic_action = '<STR_LIT>' <EOL> other_topic = \"<STR_LIT>\" <EOL> self . events_action_t = None <EOL> update = DbUpdate ( '<STR_LIT:info>' , None , no_topic_action , \"<STR_LIT>\" ) <EOL> publisher . send_event ( update , other_topic ) <EOL> eventlet . sleep ( <NUM_LIT:1> ) <EOL> self . assertEqual ( self . events_action_t , None ) <EOL> self . assertNotEqual ( local_events_num + <NUM_LIT:2> , self . events_num_t ) <EOL> subscriber . unregister_topic ( topic ) <EOL> publisher . send_event ( update , topic ) <EOL> self . assertEqual ( self . events_action_t , None ) <EOL> subscriber . stop ( ) <EOL> class TestMultiprocPubSub ( test_base . DFTestBase ) : <EOL> def setUp ( self ) : <EOL> super ( TestMultiprocPubSub , self ) . setUp ( ) <EOL> self . do_test = cfg . CONF . df . enable_df_pub_sub <EOL> self . key = '<STR_LIT>' . format ( random . random ( ) ) <EOL> self . event = DbUpdate ( <EOL> '<STR_LIT:info>' , <EOL> None , <EOL> \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , <EOL> topic = SEND_ALL_TOPIC , <EOL> ) <EOL> self . subscriber = None <EOL> def tearDown ( self ) : <EOL> if self . subscriber : <EOL> self . subscriber . stop ( ) <EOL> super ( TestMultiprocPubSub , self ) . tearDown ( ) <EOL> def _verify_event ( self , table , key , action , value , topic ) : <EOL> self . assertEqual ( self . event . table , table ) <EOL> self . assertEqual ( self . event . key , key ) <EOL> self . assertEqual ( self . event . action , action ) <EOL> self . assertEqual ( self . event . topic , topic ) <EOL> self . event_received = True <EOL> def test_multiproc_pub_sub ( self ) : <EOL> if not self . do_test : <EOL> return <EOL> self . event_received = False <EOL> cfg . CONF . df . publisher_multiproc_socket = '<STR_LIT>' <EOL> pub_sub_driver = df_utils . load_driver ( <EOL> cfg . CONF . df . pub_sub_multiproc_driver , <EOL> df_utils . DF_PUBSUB_DRIVER_NAMESPACE ) <EOL> publisher = pub_sub_driver . get_publisher ( ) <EOL> publisher . initialize ( ) <EOL> self . subscriber = pub_sub_driver . get_subscriber ( ) <EOL> self . subscriber . initialize ( self . _verify_event ) <EOL> self . subscriber . daemonize ( ) <EOL> publisher . send_event ( self . event ) <EOL> wait_until_true ( lambda : self . event_received ) <EOL> self . subscriber . stop ( ) <EOL> self . subscriber = None <EOL> class TestDbTableMonitors ( test_base . DFTestBase ) : <EOL> def setUp ( self ) : <EOL> super ( TestDbTableMonitors , self ) . setUp ( ) <EOL> self . events_num = <NUM_LIT:0> <EOL> enable_df_pub_sub = cfg . CONF . df . enable_df_pub_sub <EOL> self . do_test = enable_df_pub_sub <EOL> if not self . do_test : <EOL> return <EOL> self . namespace = Namespace ( ) <EOL> self . namespace . events = [ ] <EOL> self . publisher = get_publisher ( ) <EOL> self . subscriber = get_subscriber ( self . _db_change_callback ) <EOL> self . monitor = self . _create_monitor ( '<STR_LIT>' ) <EOL> def tearDown ( self ) : <EOL> if self . do_test : <EOL> self . monitor . stop ( ) <EOL> self . subscriber . stop ( ) <EOL> super ( TestDbTableMonitors , self ) . tearDown ( ) <EOL> def _db_change_callback ( self , table , key , action , value , topic ) : <EOL> self . namespace . events . append ( { <EOL> '<STR_LIT>' : table , <EOL> '<STR_LIT:key>' : key , <EOL> '<STR_LIT:action>' : action , <EOL> '<STR_LIT:value>' : value , <EOL> } ) <EOL> def _create_monitor ( self , table_name ) : <EOL> table_monitor = TableMonitor ( <EOL> table_name , <EOL> self . nb_api . driver , <EOL> self . publisher , <EOL> <NUM_LIT:1> , <EOL> ) <EOL> table_monitor . daemonize ( ) <EOL> return table_monitor <EOL> def test_operations ( self ) : <EOL> if not self . do_test : <EOL> return <EOL> expected_event = { <EOL> '<STR_LIT>' : unicode ( '<STR_LIT>' ) , <EOL> '<STR_LIT:key>' : unicode ( '<STR_LIT>' ) , <EOL> '<STR_LIT:action>' : unicode ( '<STR_LIT>' ) , <EOL> '<STR_LIT:value>' : None , <EOL> } <EOL> self . assertNotIn ( expected_event , self . namespace . events ) <EOL> self . nb_api . driver . create_key ( <EOL> '<STR_LIT>' , <EOL> '<STR_LIT>' , <EOL> jsonutils . dumps ( { '<STR_LIT:name>' : '<STR_LIT>' , '<STR_LIT:data>' : '<STR_LIT>' } ) ) <EOL> eventlet . sleep ( test_utils . DEFAULT_CMD_TIMEOUT ) <EOL> self . assertIn ( expected_event , self . namespace . events ) <EOL> expected_event = { <EOL> '<STR_LIT>' : unicode ( '<STR_LIT>' ) , <EOL> '<STR_LIT:key>' : unicode ( '<STR_LIT>' ) , <EOL>", "answer": "'<STR_LIT:action>' : unicode ( '<STR_LIT>' ) ,"}, {"prompt": "<s> from __future__ import print_function <EOL> from __future__ import unicode_literals <EOL> from __future__ import absolute_import <EOL> from __future__ import generators <EOL> import os , sys , inspect , copy <EOL> if - <NUM_LIT:1> != sys . path [ <NUM_LIT:0> ] . find ( '<STR_LIT>' ) : raise Exception ( '<STR_LIT>' ) <EOL> exampleFileDirectory = sys . path [ <NUM_LIT:0> ] [ : sys . path [ <NUM_LIT:0> ] . rfind ( os . sep ) ] <EOL> pyeq2IimportDirectory = os . path . join ( os . path . join ( exampleFileDirectory , '<STR_LIT:..>' ) , '<STR_LIT:..>' ) <EOL> if pyeq2IimportDirectory not in sys . path : <EOL> sys . path . append ( pyeq2IimportDirectory ) <EOL> import pyeq2 <EOL> def UniqueCombinations ( items , n ) : <EOL> if n == <NUM_LIT:0> : <EOL> yield [ ] <EOL> else : <EOL> for i in xrange ( len ( items ) ) : <EOL> for cc in UniqueCombinations ( items [ i + <NUM_LIT:1> : ] , n - <NUM_LIT:1> ) : <EOL> yield [ items [ i ] ] + cc <EOL> def UniqueCombinations2 ( items2 , n2 ) : <EOL> if n2 == <NUM_LIT:0> : <EOL> yield [ ] <EOL> else : <EOL> for i2 in xrange ( len ( items2 ) ) : <EOL> for cc2 in UniqueCombinations2 ( items2 [ i2 + <NUM_LIT:1> : ] , n2 - <NUM_LIT:1> ) : <EOL> yield [ items2 [ i2 ] ] + cc2 <EOL> def SetParametersAndFit ( inEquation , resultList , inPrintStatus ) : <EOL> try : <EOL> if len ( inEquation . GetCoefficientDesignators ( ) ) > len ( inEquation . dataCache . allDataCacheDictionary [ '<STR_LIT>' ] ) : <EOL> return <EOL> if inEquation . ShouldDataBeRejected ( inEquation ) : <EOL> return <EOL> if inPrintStatus : <EOL> print ( '<STR_LIT>' , inEquation . __module__ , \"<STR_LIT:'>\" + inEquation . GetDisplayName ( ) + \"<STR_LIT:'>\" ) <EOL> inEquation . Solve ( ) <EOL> target = inEquation . CalculateAllDataFittingTarget ( inEquation . solvedCoefficients ) <EOL> if target > <NUM_LIT> : <EOL>", "answer": "return"}, {"prompt": "<s> from __future__ import print_function <EOL> import getpass <EOL> import inspect <EOL> import json <EOL> import os <EOL> import sys <EOL> import textwrap <EOL> from oslo_utils import encodeutils <EOL> from oslo_utils import strutils <EOL> import prettytable <EOL> import six <EOL> from six import moves <EOL> from ironicclient . common . i18n import _ <EOL> class MissingArgs ( Exception ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , missing ) : <EOL> self . missing = missing <EOL> msg = _ ( \"<STR_LIT>\" ) % \"<STR_LIT:U+002CU+0020>\" . join ( missing ) <EOL> super ( MissingArgs , self ) . __init__ ( msg ) <EOL> def validate_args ( fn , * args , ** kwargs ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> argspec = inspect . getargspec ( fn ) <EOL> num_defaults = len ( argspec . defaults or [ ] ) <EOL> required_args = argspec . args [ : len ( argspec . args ) - num_defaults ] <EOL> def isbound ( method ) : <EOL> return getattr ( method , '<STR_LIT>' , None ) is not None <EOL> if isbound ( fn ) : <EOL> required_args . pop ( <NUM_LIT:0> ) <EOL> missing = [ arg for arg in required_args if arg not in kwargs ] <EOL> missing = missing [ len ( args ) : ] <EOL> if missing : <EOL> raise MissingArgs ( missing ) <EOL> def arg ( * args , ** kwargs ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def _decorator ( func ) : <EOL> add_arg ( func , * args , ** kwargs ) <EOL> return func <EOL> return _decorator <EOL> def env ( * args , ** kwargs ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> for arg in args : <EOL> value = os . environ . get ( arg ) <EOL> if value : <EOL> return value <EOL> return kwargs . get ( '<STR_LIT:default>' , '<STR_LIT>' ) <EOL> def add_arg ( func , * args , ** kwargs ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if not hasattr ( func , '<STR_LIT>' ) : <EOL> func . arguments = [ ] <EOL> if ( args , kwargs ) not in func . arguments : <EOL> func . arguments . insert ( <NUM_LIT:0> , ( args , kwargs ) ) <EOL> def unauthenticated ( func ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> func . unauthenticated = True <EOL> return func <EOL> def isunauthenticated ( func ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> return getattr ( func , '<STR_LIT>' , False ) <EOL> def print_list ( objs , fields , formatters = None , sortby_index = <NUM_LIT:0> , <EOL> mixed_case_fields = None , field_labels = None , json_flag = False ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if json_flag : <EOL> print ( json . dumps ( [ o . _info for o in objs ] , indent = <NUM_LIT:4> , <EOL> separators = ( '<STR_LIT:U+002C>' , '<STR_LIT>' ) ) ) <EOL> return <EOL> formatters = formatters or { } <EOL> mixed_case_fields = mixed_case_fields or [ ] <EOL> field_labels = field_labels or fields <EOL> if len ( field_labels ) != len ( fields ) : <EOL> raise ValueError ( _ ( \"<STR_LIT>\" <EOL> \"<STR_LIT>\" ) , <EOL> { '<STR_LIT>' : field_labels , '<STR_LIT>' : fields } ) <EOL> if sortby_index is None : <EOL>", "answer": "kwargs = { }"}, {"prompt": "<s> import ddt <EOL> import mock <EOL> from rally import exceptions <EOL> from rally . plugins . openstack . wrappers import cinder as cinder_wrapper <EOL> from tests . unit import test <EOL> @ ddt . ddt <EOL> class CinderWrapperTestCase ( test . ScenarioTestCase ) : <EOL> @ ddt . data ( <EOL> { \"<STR_LIT:version>\" : \"<STR_LIT:1>\" , \"<STR_LIT>\" : cinder_wrapper . CinderV1Wrapper } , <EOL> { \"<STR_LIT:version>\" : \"<STR_LIT:2>\" , \"<STR_LIT>\" : cinder_wrapper . CinderV2Wrapper } <EOL> ) <EOL> @ ddt . unpack <EOL> def test_wrap ( self , version , expected_class ) : <EOL> client = mock . MagicMock ( ) <EOL> client . choose_version . return_value = version <EOL> self . assertIsInstance ( cinder_wrapper . wrap ( client , mock . Mock ( ) ) , <EOL>", "answer": "expected_class )"}, {"prompt": "<s> import glob , os , sys , unittest , getopt , time <EOL> use_resources = [ ] <EOL> class ResourceDenied ( Exception ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def is_resource_enabled ( resource ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if sys . _getframe ( ) . f_back . f_globals . get ( \"<STR_LIT>\" ) == \"<STR_LIT:__main__>\" : <EOL> return True <EOL> result = use_resources is not None and ( resource in use_resources or \"<STR_LIT:*>\" in use_resources ) <EOL> if not result : <EOL> _unavail [ resource ] = None <EOL> return result <EOL> _unavail = { } <EOL> def requires ( resource , msg = None ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if sys . _getframe ( ) . f_back . f_globals . get ( \"<STR_LIT>\" ) == \"<STR_LIT:__main__>\" : <EOL> return <EOL> if not is_resource_enabled ( resource ) : <EOL> if msg is None : <EOL> msg = \"<STR_LIT>\" % resource <EOL> raise ResourceDenied ( msg ) <EOL> def find_package_modules ( package , mask ) : <EOL> import fnmatch <EOL> if hasattr ( package , \"<STR_LIT>\" ) : <EOL> path = package . __name__ . replace ( \"<STR_LIT:.>\" , os . path . sep ) <EOL> mask = os . path . join ( path , mask ) <EOL> for fnm in package . __loader__ . _files . iterkeys ( ) : <EOL> if fnmatch . fnmatchcase ( fnm , mask ) : <EOL> yield os . path . splitext ( fnm ) [ <NUM_LIT:0> ] . replace ( os . path . sep , \"<STR_LIT:.>\" ) <EOL> else : <EOL> path = package . __path__ [ <NUM_LIT:0> ] <EOL> for fnm in os . listdir ( path ) : <EOL> if fnmatch . fnmatchcase ( fnm , mask ) : <EOL> yield \"<STR_LIT>\" % ( package . __name__ , os . path . splitext ( fnm ) [ <NUM_LIT:0> ] ) <EOL> def get_tests ( package , mask , verbosity ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> tests = [ ] <EOL> skipped = [ ] <EOL> for modname in find_package_modules ( package , mask ) : <EOL> try : <EOL> mod = __import__ ( modname , globals ( ) , locals ( ) , [ '<STR_LIT:*>' ] ) <EOL> except ResourceDenied , detail : <EOL> skipped . append ( modname ) <EOL> if verbosity > <NUM_LIT:1> : <EOL> print >> sys . stderr , \"<STR_LIT>\" % ( modname , detail ) <EOL> continue <EOL> except Exception , detail : <EOL> print >> sys . stderr , \"<STR_LIT>\" % ( modname , detail ) <EOL> continue <EOL> for name in dir ( mod ) : <EOL> if name . startswith ( \"<STR_LIT:_>\" ) : <EOL> continue <EOL> o = getattr ( mod , name ) <EOL> if type ( o ) is type ( unittest . TestCase ) and issubclass ( o , unittest . TestCase ) : <EOL> tests . append ( o ) <EOL> return skipped , tests <EOL> def usage ( ) : <EOL> print __doc__ <EOL> return <NUM_LIT:1> <EOL> def test_with_refcounts ( runner , verbosity , testcase ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> import gc <EOL> import ctypes <EOL> ptc = ctypes . _pointer_type_cache . copy ( ) <EOL> cfc = ctypes . _c_functype_cache . copy ( ) <EOL> wfc = ctypes . _win_functype_cache . copy ( ) <EOL> def cleanup ( ) : <EOL> ctypes . _pointer_type_cache = ptc . copy ( ) <EOL> ctypes . _c_functype_cache = cfc . copy ( ) <EOL> ctypes . _win_functype_cache = wfc . copy ( ) <EOL> gc . collect ( ) <EOL> test = unittest . makeSuite ( testcase ) <EOL> for i in range ( <NUM_LIT:5> ) : <EOL> rc = sys . gettotalrefcount ( ) <EOL> runner . run ( test ) <EOL> cleanup ( ) <EOL> COUNT = <NUM_LIT:5> <EOL> refcounts = [ None ] * COUNT <EOL> for i in range ( COUNT ) : <EOL> rc = sys . gettotalrefcount ( ) <EOL> runner . run ( test ) <EOL> cleanup ( ) <EOL> refcounts [ i ] = sys . gettotalrefcount ( ) - rc <EOL> if filter ( None , refcounts ) : <EOL> print \"<STR_LIT>\" % testcase , refcounts <EOL> elif verbosity : <EOL> print \"<STR_LIT>\" % testcase <EOL> class TestRunner ( unittest . TextTestRunner ) : <EOL> def run ( self , test , skipped ) : <EOL> \"<STR_LIT>\" <EOL> result = self . _makeResult ( ) <EOL> startTime = time . time ( ) <EOL> test ( result ) <EOL> stopTime = time . time ( ) <EOL> timeTaken = stopTime - startTime <EOL> result . printErrors ( ) <EOL> self . stream . writeln ( result . separator2 ) <EOL> run = result . testsRun <EOL> if _unavail : <EOL> requested = _unavail . keys ( ) <EOL> requested . sort ( ) <EOL> self . stream . writeln ( \"<STR_LIT>\" % <EOL> ( run , run != <NUM_LIT:1> and \"<STR_LIT:s>\" or \"<STR_LIT>\" , timeTaken , <EOL> len ( skipped ) , <EOL> len ( skipped ) != <NUM_LIT:1> and \"<STR_LIT:s>\" or \"<STR_LIT>\" ) ) <EOL> self . stream . writeln ( \"<STR_LIT>\" % \"<STR_LIT:U+002CU+0020>\" . join ( requested ) ) <EOL> else : <EOL> self . stream . writeln ( \"<STR_LIT>\" % <EOL> ( run , run != <NUM_LIT:1> and \"<STR_LIT:s>\" or \"<STR_LIT>\" , timeTaken ) ) <EOL> self . stream . writeln ( ) <EOL> if not result . wasSuccessful ( ) : <EOL> self . stream . write ( \"<STR_LIT>\" ) <EOL> failed , errored = map ( len , ( result . failures , result . errors ) ) <EOL> if failed : <EOL> self . stream . write ( \"<STR_LIT>\" % failed ) <EOL> if errored : <EOL> if failed : self . stream . write ( \"<STR_LIT:U+002CU+0020>\" ) <EOL> self . stream . write ( \"<STR_LIT>\" % errored ) <EOL> self . stream . writeln ( \"<STR_LIT:)>\" ) <EOL> else : <EOL> self . stream . writeln ( \"<STR_LIT:OK>\" ) <EOL> return result <EOL> def main ( * packages ) : <EOL> try : <EOL> opts , args = getopt . getopt ( sys . argv [ <NUM_LIT:1> : ] , \"<STR_LIT>\" ) <EOL> except getopt . error : <EOL> return usage ( ) <EOL> verbosity = <NUM_LIT:1> <EOL> search_leaks = False <EOL> for flag , value in opts : <EOL> if flag == \"<STR_LIT>\" : <EOL> verbosity -= <NUM_LIT:1> <EOL> elif flag == \"<STR_LIT>\" : <EOL> verbosity += <NUM_LIT:1> <EOL> elif flag == \"<STR_LIT>\" : <EOL> try : <EOL> sys . gettotalrefcount <EOL> except AttributeError : <EOL> print >> sys . stderr , \"<STR_LIT>\" <EOL> return - <NUM_LIT:1> <EOL> search_leaks = True <EOL> elif flag == \"<STR_LIT>\" : <EOL> use_resources . extend ( value . split ( \"<STR_LIT:U+002C>\" ) ) <EOL> mask = \"<STR_LIT>\" <EOL> if args : <EOL> mask = args [ <NUM_LIT:0> ] <EOL> for package in packages : <EOL> run_tests ( package , mask , verbosity , search_leaks ) <EOL> def run_tests ( package , mask , verbosity , search_leaks ) : <EOL> skipped , testcases = get_tests ( package , mask , verbosity ) <EOL> runner = TestRunner ( verbosity = verbosity ) <EOL> suites = [ unittest . makeSuite ( o ) for o in testcases ] <EOL>", "answer": "suite = unittest . TestSuite ( suites )"}, {"prompt": "<s> '''<STR_LIT>''' <EOL> class NvvmSupportError ( ImportError ) : <EOL> pass <EOL> class NVVM ( object ) : <EOL> def __init__ ( self ) : <EOL> raise NvvmSupportError ( '<STR_LIT>' ) <EOL> CompilationUnit = None <EOL> llvm_to_ptx = None <EOL> set_cuda_kernel = None <EOL> fix_data_layout = None <EOL> get_arch_option = None <EOL> SUPPORTED_CC = None <EOL>", "answer": "LibDevice = None"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> from __future__ import absolute_import <EOL> import hashlib <EOL> import json <EOL> import os <EOL> import re <EOL> from pkg_resources import resource_string <EOL> import requests <EOL> import six <EOL> from plotly import files , utils <EOL> GRAPH_REFERENCE_PATH = '<STR_LIT>' <EOL> GRAPH_REFERENCE_DOWNLOAD_TIMEOUT = <NUM_LIT:5> <EOL> _BACKWARDS_COMPAT_CLASS_NAMES = { <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : list } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT:bar>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT:data>' , '<STR_LIT>' : list } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : None , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } , <EOL> '<STR_LIT>' : { '<STR_LIT:object_name>' : '<STR_LIT>' , '<STR_LIT>' : dict } <EOL> } <EOL> def get_graph_reference ( ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> default_config = files . FILE_CONTENT [ files . CONFIG_FILE ] <EOL> if files . check_file_permissions ( ) : <EOL> graph_reference = utils . load_json_dict ( files . GRAPH_REFERENCE_FILE ) <EOL> config = utils . load_json_dict ( files . CONFIG_FILE ) <EOL> plotly_api_domain = config . get ( '<STR_LIT>' , <EOL> default_config [ '<STR_LIT>' ] ) <EOL> else : <EOL> graph_reference = { } <EOL> plotly_api_domain = default_config [ '<STR_LIT>' ] <EOL> sha1 = hashlib . sha1 ( six . b ( str ( graph_reference ) ) ) . hexdigest ( ) <EOL> graph_reference_url = '<STR_LIT>' . format ( plotly_api_domain , <EOL> GRAPH_REFERENCE_PATH , sha1 ) <EOL> try : <EOL> response = requests . get ( graph_reference_url , <EOL> timeout = GRAPH_REFERENCE_DOWNLOAD_TIMEOUT ) <EOL> response . raise_for_status ( ) <EOL> except requests . exceptions . RequestException : <EOL> if not graph_reference : <EOL> path = os . path . join ( '<STR_LIT>' , '<STR_LIT>' ) <EOL> s = resource_string ( '<STR_LIT>' , path ) . decode ( '<STR_LIT:utf-8>' ) <EOL> graph_reference = json . loads ( s ) <EOL> else : <EOL> if six . PY3 : <EOL> content = str ( response . content , encoding = '<STR_LIT:utf-8>' ) <EOL> else : <EOL> content = response . content <EOL> data = json . loads ( content ) <EOL> if data [ '<STR_LIT>' ] : <EOL> graph_reference = data [ '<STR_LIT>' ] <EOL> return utils . decode_unicode ( graph_reference ) <EOL> def string_to_class_name ( string ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> string = re . sub ( r'<STR_LIT>' , lambda m : m . group ( ) . title ( ) , string , count = <NUM_LIT:1> ) <EOL> string = re . sub ( r'<STR_LIT>' , lambda m : m . group ( ) [ <NUM_LIT:1> : ] . title ( ) , string ) <EOL> return str ( string ) <EOL> def object_name_to_class_name ( object_name ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if object_name in TRACE_NAMES : <EOL> return string_to_class_name ( object_name ) <EOL> if object_name in OBJECT_NAME_TO_CLASS_NAME : <EOL> return OBJECT_NAME_TO_CLASS_NAME [ object_name ] <EOL> if object_name in ARRAYS : <EOL> return '<STR_LIT:list>' <EOL> else : <EOL> return '<STR_LIT>' <EOL> def get_attributes_dicts ( object_name , parent_object_names = ( ) ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> object_dict = OBJECTS [ object_name ] <EOL> additional_attributes = object_dict [ '<STR_LIT>' ] <EOL> attribute_paths = list ( object_dict [ '<STR_LIT>' ] ) <EOL> for parent_object_name in reversed ( parent_object_names ) : <EOL> if parent_object_name in ARRAYS : <EOL> continue <EOL> parent_object_dict = OBJECTS [ parent_object_name ] <EOL> parent_attribute_paths = parent_object_dict [ '<STR_LIT>' ] <EOL> for path in list ( attribute_paths ) : <EOL> if not _is_valid_sub_path ( path , parent_attribute_paths ) : <EOL> attribute_paths . remove ( path ) <EOL> attributes_dicts = { path : utils . get_by_path ( GRAPH_REFERENCE , path ) <EOL> for path in attribute_paths } <EOL> attributes_dicts [ '<STR_LIT>' ] = additional_attributes <EOL> return attributes_dicts <EOL> def get_valid_attributes ( object_name , parent_object_names = ( ) ) : <EOL> attributes = get_attributes_dicts ( object_name , parent_object_names ) <EOL> valid_attributes = set ( ) <EOL> for attributes_dict in attributes . values ( ) : <EOL> for key , val in attributes_dict . items ( ) : <EOL> if key not in GRAPH_REFERENCE [ '<STR_LIT>' ] [ '<STR_LIT>' ] : <EOL> valid_attributes . add ( key ) <EOL> deprecated_attributes = attributes_dict . get ( '<STR_LIT>' , { } ) <EOL> for key , val in deprecated_attributes . items ( ) : <EOL> if key not in GRAPH_REFERENCE [ '<STR_LIT>' ] [ '<STR_LIT>' ] : <EOL> valid_attributes . add ( key ) <EOL> return valid_attributes <EOL> def get_deprecated_attributes ( object_name , parent_object_names = ( ) ) : <EOL> attributes = get_attributes_dicts ( object_name , parent_object_names ) <EOL> deprecated_attributes = set ( ) <EOL> for attributes_dict in attributes . values ( ) : <EOL> deprecated_attributes_dict = attributes_dict . get ( '<STR_LIT>' , { } ) <EOL> for key , val in deprecated_attributes_dict . items ( ) : <EOL> if key not in GRAPH_REFERENCE [ '<STR_LIT>' ] [ '<STR_LIT>' ] : <EOL> deprecated_attributes . add ( key ) <EOL> return deprecated_attributes <EOL> def get_subplot_attributes ( object_name , parent_object_names = ( ) ) : <EOL> attributes = get_attributes_dicts ( object_name , parent_object_names ) <EOL> subplot_attributes = set ( ) <EOL> for attributes_dict in attributes . values ( ) : <EOL> for key , val in attributes_dict . items ( ) : <EOL> if key not in GRAPH_REFERENCE [ '<STR_LIT>' ] [ '<STR_LIT>' ] : <EOL> if isinstance ( val , dict ) and val . get ( '<STR_LIT>' ) : <EOL> subplot_attributes . add ( key ) <EOL> deprecated_attributes = attributes_dict . get ( '<STR_LIT>' , { } ) <EOL> for key , val in deprecated_attributes . items ( ) : <EOL> if key not in GRAPH_REFERENCE [ '<STR_LIT>' ] [ '<STR_LIT>' ] : <EOL> if isinstance ( val , dict ) and val . get ( '<STR_LIT>' ) : <EOL> subplot_attributes . add ( key ) <EOL> return subplot_attributes <EOL> def attribute_path_to_object_names ( attribute_container_path ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> object_names = [ '<STR_LIT>' ] <EOL> if '<STR_LIT>' in attribute_container_path : <EOL> for path_part in attribute_container_path : <EOL> if path_part in OBJECTS : <EOL> object_names . append ( path_part ) <EOL> if path_part in ARRAYS : <EOL> object_names . append ( path_part ) <EOL> object_names . append ( path_part [ : - <NUM_LIT:1> ] ) <EOL> elif '<STR_LIT>' in attribute_container_path : <EOL> object_names . append ( '<STR_LIT>' ) <EOL> start_index = attribute_container_path . index ( '<STR_LIT>' ) <EOL> for path_part in attribute_container_path [ start_index : ] : <EOL> if path_part in OBJECTS : <EOL> object_names . append ( path_part ) <EOL> if path_part in ARRAYS : <EOL> object_names . append ( path_part ) <EOL> object_names . append ( path_part [ : - <NUM_LIT:1> ] ) <EOL> else : <EOL> object_names . append ( '<STR_LIT:data>' ) <EOL> for path_part in attribute_container_path : <EOL> if path_part in OBJECTS : <EOL> object_names . append ( path_part ) <EOL> if path_part in ARRAYS : <EOL> object_names . append ( path_part ) <EOL> object_names . append ( path_part [ : - <NUM_LIT:1> ] ) <EOL> return tuple ( object_names ) <EOL> def get_role ( object_name , attribute , value = None , parent_object_names = ( ) ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if object_name in TRACE_NAMES and attribute == '<STR_LIT:type>' : <EOL> return '<STR_LIT:info>' <EOL> attributes_dicts = get_attributes_dicts ( object_name , parent_object_names ) <EOL> matches = [ ] <EOL> for attributes_dict in attributes_dicts . values ( ) : <EOL> for key , val in attributes_dict . items ( ) : <EOL> if key == attribute : <EOL> matches . append ( val ) <EOL> for key , val in attributes_dict . get ( '<STR_LIT>' , { } ) . items ( ) : <EOL> if key == attribute : <EOL> matches . append ( val ) <EOL> roles = [ ] <EOL> for match in matches : <EOL> role = match [ '<STR_LIT>' ] <EOL> array_ok = match . get ( '<STR_LIT>' ) <EOL> if value is not None and array_ok : <EOL> iterable = hasattr ( value , '<STR_LIT>' ) <EOL> stringy = isinstance ( value , six . string_types ) <EOL> dicty = isinstance ( value , dict ) <EOL> if iterable and not stringy and not dicty : <EOL> role = '<STR_LIT:data>' <EOL> roles . append ( role ) <EOL> if '<STR_LIT:data>' in roles : <EOL> role = '<STR_LIT:data>' <EOL> else : <EOL> role = roles [ <NUM_LIT:0> ] <EOL> return role <EOL> def _is_valid_sub_path ( path , parent_paths ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if not parent_paths : <EOL> return True <EOL> for parent_path in parent_paths : <EOL> if path [ : len ( parent_path ) ] == parent_path : <EOL> return True <EOL> return False <EOL> def _get_objects ( ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> objects = { } <EOL> for node , path in utils . node_generator ( GRAPH_REFERENCE ) : <EOL> if any ( [ key in path for key in GRAPH_REFERENCE [ '<STR_LIT>' ] [ '<STR_LIT>' ] ] ) : <EOL> continue <EOL> if node . get ( '<STR_LIT>' ) != '<STR_LIT:object>' : <EOL> continue <EOL> if '<STR_LIT>' in node : <EOL> continue <EOL> object_name = path [ - <NUM_LIT:1> ] <EOL> if object_name not in objects : <EOL> objects [ object_name ] = { '<STR_LIT>' : [ ] , '<STR_LIT>' : [ ] , <EOL> '<STR_LIT>' : { } } <EOL> if node . get ( '<STR_LIT>' ) : <EOL> objects [ object_name ] [ '<STR_LIT>' ] . append ( <EOL> path + ( '<STR_LIT>' , ) <EOL> ) <EOL> else : <EOL> objects [ object_name ] [ '<STR_LIT>' ] . append ( path ) <EOL> objects [ object_name ] [ '<STR_LIT>' ] . append ( path ) <EOL> return objects <EOL> def _patch_objects ( ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> layout_attribute_paths = [ ] <EOL> for node , path in utils . node_generator ( GRAPH_REFERENCE ) : <EOL> if any ( [ key in path for key in GRAPH_REFERENCE [ '<STR_LIT>' ] [ '<STR_LIT>' ] ] ) : <EOL> continue <EOL> if path and path [ - <NUM_LIT:1> ] == '<STR_LIT>' : <EOL> layout_attribute_paths . append ( path ) <EOL> for trace_name in TRACE_NAMES : <EOL> OBJECTS [ trace_name ] = { <EOL> '<STR_LIT>' : [ ( '<STR_LIT>' , trace_name ) ] , <EOL> '<STR_LIT>' : [ ( '<STR_LIT>' , trace_name , '<STR_LIT>' ) ] , <EOL> '<STR_LIT>' : { } <EOL> } <EOL> OBJECTS [ '<STR_LIT>' ] = { '<STR_LIT>' : [ ( '<STR_LIT>' , ) ] , <EOL> '<STR_LIT>' : layout_attribute_paths , <EOL>", "answer": "'<STR_LIT>' : { } }"}, {"prompt": "<s> from __future__ import division <EOL> import numpy as np <EOL> def mymean ( x ) : <EOL>", "answer": "return np . ma . mean ( x ) "}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> __docformat__ = '<STR_LIT>' <EOL> COPYRIGHT = \"\"\"<STR_LIT>\"\"\" <EOL> TITLE = __doc__ <EOL> SOURCE = \"\"\"<STR_LIT>\"\"\" <EOL> DESCRSHORT = \"\"\"<STR_LIT>\"\"\" <EOL> DESCRLONG = \"\"\"<STR_LIT>\"\"\" <EOL> NOTE = \"\"\"<STR_LIT>\"\"\" <EOL> from numpy import recfromtxt , column_stack , array <EOL> from statsmodels . datasets import utils as du <EOL> from os . path import dirname , abspath <EOL> def load ( ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> data = _get_data ( ) <EOL> return du . process_recarray ( data , endog_idx = <NUM_LIT:0> , dtype = float ) <EOL> def load_pandas ( ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> data = _get_data ( ) <EOL> return du . process_recarray_pandas ( data , endog_idx = <NUM_LIT:0> , dtype = float ) <EOL>", "answer": "def _get_data ( ) :"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import contextlib <EOL> import cStringIO as StringIO <EOL> import csv <EOL> from google . appengine . ext import ndb <EOL> from src . clients import gcs <EOL> from src . pipelines import pipeline <EOL> class DatastoreInput ( pipeline . Pipeline ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> @ staticmethod <EOL> def GetHelp ( ) : <EOL> return \"\"\"<STR_LIT>\"\"\" <EOL> def run ( self , config ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> storage = gcs . Gcs ( ) <EOL> gql = config . get ( '<STR_LIT>' ) <EOL> if not gql : <EOL> with contextlib . closing ( <EOL> storage . OpenObject ( url = config [ '<STR_LIT:object>' ] ) ) as stream : <EOL> with contextlib . closing ( StringIO . StringIO ( ) ) as gql_buf : <EOL> while True : <EOL> buf = stream . read ( gcs . Gcs . READ_CHUNK_SIZE ) <EOL> if buf and len ( buf ) : <EOL> gql_buf . write ( buf ) <EOL> else : <EOL> break <EOL> gql = gql_buf . getvalue ( ) <EOL> qkwargs = { } <EOL> consistency = None <EOL> keys_only = False <EOL> projection = None <EOL> if '<STR_LIT>' in config : <EOL> params = config [ '<STR_LIT>' ] <EOL> qkwargs = params . get ( '<STR_LIT>' , { } ) <EOL> consistency = params . get ( '<STR_LIT>' ) <EOL> if '<STR_LIT>' in params and params [ '<STR_LIT>' ] is '<STR_LIT>' : <EOL> consistency = ndb . EVENTUAL_CONSISTENCY <EOL> keys_only = params . get ( '<STR_LIT>' , False ) <EOL> projection = params . get ( '<STR_LIT>' ) <EOL> writer = None <EOL> with contextlib . closing ( StringIO . StringIO ( ) ) as buf : <EOL> query = ndb . gql ( gql , ** qkwargs ) <EOL> for entity in query . iter ( read_policy = consistency , <EOL> keys_only = keys_only , <EOL> projection = projection ) : <EOL> if not projection : <EOL> projection = entity . _properties . keys ( ) <EOL> if not writer : <EOL> writer = csv . DictWriter ( buf , projection ) <EOL> headers = dict ( ( p , p ) for p in projection ) <EOL> writer . writerow ( headers ) <EOL> writer . writerow ( entity . to_dict ( ) ) <EOL> buf . seek ( <NUM_LIT:0> ) <EOL> storage . InsertObject ( buf , url = config [ '<STR_LIT>' ] [ <NUM_LIT:0> ] ) <EOL> def Lint ( self , linter ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> linter . AtLeastOneFieldRequiredCheck ( [ '<STR_LIT>' , '<STR_LIT:object>' ] ) <EOL> linter . FieldCheck ( '<STR_LIT>' ) <EOL>", "answer": "linter . FieldCheck ( '<STR_LIT:object>' , validator = gcs . Gcs . UrlToBucketAndName )"}, {"prompt": "<s> import pytest <EOL> sa = pytest . importorskip ( \"<STR_LIT>\" ) <EOL> import os <EOL> import responses <EOL> import flask <EOL> from lazy import lazy <EOL> from flask_sqlalchemy import SQLAlchemy <EOL> from sqlalchemy import event <EOL> from sqlalchemy . orm . exc import NoResultFound <EOL> from flask_cache import Cache <EOL>", "answer": "from flask_login import LoginManager , UserMixin , current_user , login_user , logout_user"}, {"prompt": "<s> import sys <EOL> from django . template import Library <EOL> from optional_django import six <EOL> from . . compiler import webpack <EOL>", "answer": "from . . exceptions import BundlingError"}, {"prompt": "<s> try : <EOL> from itertools import zip_longest <EOL> except ImportError : <EOL> from itertools import izip_longest as zip_longest <EOL> from django . utils . six . moves import zip <EOL> from django . db . backends . util import truncate_name , typecast_timestamp <EOL> from django . db . models . sql import compiler <EOL> from django . db . models . sql . constants import MULTI <EOL> from django . utils import six <EOL> SQLCompiler = compiler . SQLCompiler <EOL> class GeoSQLCompiler ( compiler . SQLCompiler ) : <EOL> def get_columns ( self , with_aliases = False ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> qn = self . quote_name_unless_alias <EOL> qn2 = self . connection . ops . quote_name <EOL> result = [ '<STR_LIT>' % ( self . get_extra_select_format ( alias ) % col [ <NUM_LIT:0> ] , qn2 ( alias ) ) <EOL> for alias , col in six . iteritems ( self . query . extra_select ) ] <EOL> aliases = set ( self . query . extra_select . keys ( ) ) <EOL> if with_aliases : <EOL> col_aliases = aliases . copy ( ) <EOL> else : <EOL> col_aliases = set ( ) <EOL> if self . query . select : <EOL> only_load = self . deferred_to_columns ( ) <EOL> for col , field in zip ( self . query . select , self . query . select_fields ) : <EOL> if isinstance ( col , ( list , tuple ) ) : <EOL> alias , column = col <EOL> table = self . query . alias_map [ alias ] . table_name <EOL> if table in only_load and column not in only_load [ table ] : <EOL> continue <EOL> r = self . get_field_select ( field , alias , column ) <EOL> if with_aliases : <EOL> if col [ <NUM_LIT:1> ] in col_aliases : <EOL> c_alias = '<STR_LIT>' % len ( col_aliases ) <EOL> result . append ( '<STR_LIT>' % ( r , c_alias ) ) <EOL> aliases . add ( c_alias ) <EOL> col_aliases . add ( c_alias ) <EOL> else : <EOL>", "answer": "result . append ( '<STR_LIT>' % ( r , qn2 ( col [ <NUM_LIT:1> ] ) ) )"}, {"prompt": "<s> from __future__ import unicode_literals <EOL> import codecs <EOL> import collections <EOL> import copy <EOL> from functools import wraps <EOL> import os <EOL> import re <EOL> import six <EOL> import shutil <EOL> import tempfile <EOL> from unittest import TestCase <EOL> from click . testing import CliRunner <EOL> from taxi . backends import BaseBackend , PushEntryFailed , PushEntriesFailed <EOL> from taxi . backends . registry import backends_registry <EOL> from taxi . commands . base import cli <EOL> from taxi . projects import ProjectsDb <EOL> from taxi . utils . file import expand_date <EOL> class TestBackendEntryPoint ( object ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> class TestBackend ( BaseBackend ) : <EOL> def __init__ ( self , * args , ** kwargs ) : <EOL> super ( TestBackendEntryPoint . TestBackend , self ) . __init__ ( <EOL> * args , ** kwargs <EOL> ) <EOL> self . entries = [ ] <EOL> def push_entry ( self , date , entry ) : <EOL> self . entries . append ( entry ) <EOL> if entry . alias == '<STR_LIT>' : <EOL> raise PushEntryFailed ( ) <EOL> def post_push_entries ( self ) : <EOL> failed_entries = { } <EOL> for entry in self . entries : <EOL> if entry . alias == '<STR_LIT>' : <EOL> failed_entries [ entry ] = '<STR_LIT>' <EOL> if failed_entries : <EOL> raise PushEntriesFailed ( entries = failed_entries ) <EOL> def load ( self ) : <EOL> return self . TestBackend <EOL> class CommandTestCase ( TestCase ) : <EOL> def setUp ( self ) : <EOL> _ , self . config_file = tempfile . mkstemp ( ) <EOL> _ , self . entries_file = tempfile . mkstemp ( ) <EOL> self . taxi_dir = tempfile . mkdtemp ( ) <EOL> self . backends_original_entry_points = backends_registry . _entry_points <EOL> backends_registry . _entry_points = { <EOL> '<STR_LIT:test>' : TestBackendEntryPoint ( ) , <EOL> '<STR_LIT>' : TestBackendEntryPoint ( ) , <EOL> } <EOL> projects_db_file = os . path . join ( self . taxi_dir , <EOL> ProjectsDb . PROJECTS_FILE ) <EOL> with open ( projects_db_file , '<STR_LIT:w>' ) as f : <EOL> f . close ( ) <EOL> existing_settings = ( self . _settings <EOL> if hasattr ( self , '<STR_LIT>' ) <EOL> else { } ) <EOL> self . _settings = recursive_update ( { <EOL> '<STR_LIT:default>' : { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:file>' : self . entries_file , <EOL> '<STR_LIT>' : '<STR_LIT:0>' <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:test>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> } , <EOL> } , existing_settings ) <EOL> def tearDown ( self ) : <EOL> backends_registry . _entry_points = self . backends_original_entry_points <EOL> entries_file = expand_date ( self . entries_file ) <EOL> os . remove ( self . config_file ) <EOL> if os . path . exists ( entries_file ) : <EOL> os . remove ( entries_file ) <EOL> shutil . rmtree ( self . taxi_dir ) <EOL> def assertLineIn ( self , line , content ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def remove_spaces ( text ) : <EOL> chars_to_strip = [ '<STR_LIT:U+0020>' , '<STR_LIT:\\t>' ] <EOL> for char in chars_to_strip : <EOL> text = text . replace ( char , '<STR_LIT>' ) <EOL> return text <EOL> self . assertIn ( <EOL> remove_spaces ( line ) , <EOL> remove_spaces ( content ) , <EOL> \"<STR_LIT>\" % ( line , content ) <EOL> ) <EOL> def settings ( self , * args , ** kwargs ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> return override_settings ( * args , container = self , ** kwargs ) <EOL> def write_config ( self , config ) : <EOL> with open ( self . config_file , '<STR_LIT:w>' ) as f : <EOL> for ( section , params ) in six . iteritems ( config ) : <EOL> f . write ( \"<STR_LIT>\" % section ) <EOL> for ( param , value ) in six . iteritems ( params ) : <EOL> f . write ( \"<STR_LIT>\" % ( param , value ) ) <EOL> def write_entries ( self , contents ) : <EOL>", "answer": "with codecs . open ( expand_date ( self . entries_file ) , '<STR_LIT:a>' , '<STR_LIT:utf-8>' ) as f :"}, {"prompt": "<s> import sys <EOL> import numpy <EOL> from threshold_finder import Threshold_Finder <EOL> class Average_Threshold_Finder ( object ) : <EOL> def get_average_noise_threshold ( self , file_with_samples , no_of_samples ) : <EOL> with open ( file_with_samples ) as f : <EOL> samples = [ line [ : - <NUM_LIT:1> ] for line in f ] <EOL> noise_spectra = [ ] <EOL> avg_noise_powers = [ ] <EOL> for i in range ( <NUM_LIT:0> , int ( no_of_samples ) , <NUM_LIT:4> ) : <EOL> chord = samples [ i ] <EOL> first = samples [ i + <NUM_LIT:1> ] <EOL> second = samples [ i + <NUM_LIT:2> ] <EOL> third = samples [ i + <NUM_LIT:3> ] <EOL> t_finder = Threshold_Finder ( chord , first , second , third ) <EOL> coefficients , residual , average_noise_power = t_finder . find_least_squares ( ) <EOL> noise = residual ** <NUM_LIT:2> <EOL> noise_spectra . append ( noise ) <EOL> avg_noise_powers . append ( average_noise_power ) <EOL> average_noise = numpy . mean ( noise_spectra ) <EOL> sd_noise = numpy . std ( noise_spectra ) <EOL>", "answer": "avg_power = numpy . mean ( avg_noise_powers )"}, {"prompt": "<s> import tornado . httpserver <EOL> import tornado . ioloop <EOL> from tornadows import soaphandler <EOL> from tornadows import webservices <EOL> from tornadows import complextypes <EOL> from tornadows . soaphandler import webservice <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> class Input ( complextypes . ComplexType ) : <EOL> idList = int <EOL> class Product ( complextypes . ComplexType ) : <EOL> id = int <EOL> name = str <EOL> price = float <EOL> stock = int <EOL> class List ( complextypes . ComplexType ) : <EOL> idList = int <EOL> product = [ Product ] <EOL> class ProductListService ( soaphandler . SoapHandler ) : <EOL> @ webservice ( _params = Input , _returns = List ) <EOL> def getProductList ( self , input ) : <EOL> id = input . idList <EOL> listOfProduct = List ( ) <EOL> listOfProduct . idList = id <EOL> for i in [ <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> , <NUM_LIT:4> , <NUM_LIT:5> , <NUM_LIT:6> ] : <EOL> reg = self . database ( i ) <EOL> output = Product ( ) <EOL> output . id = i <EOL> output . name = reg [ <NUM_LIT:0> ] <EOL> output . price = reg [ <NUM_LIT:1> ] <EOL> output . stock = reg [ <NUM_LIT:2> ] <EOL> listOfProduct . product . append ( output ) <EOL> return listOfProduct <EOL> def database ( self , id ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> db = { <NUM_LIT:1> : ( '<STR_LIT>' , <NUM_LIT> , <NUM_LIT:100> ) , <EOL> <NUM_LIT:2> : ( '<STR_LIT>' , <NUM_LIT> , <NUM_LIT> ) , <EOL> <NUM_LIT:3> : ( '<STR_LIT>' , <NUM_LIT> , <NUM_LIT> ) , <EOL> <NUM_LIT:4> : ( '<STR_LIT>' , <NUM_LIT> , <NUM_LIT> ) , <EOL> <NUM_LIT:5> : ( '<STR_LIT>' , <NUM_LIT> , <NUM_LIT> ) , <EOL> <NUM_LIT:6> : ( '<STR_LIT>' , <NUM_LIT> , <NUM_LIT> ) , <EOL> } <EOL> row = ( None , <NUM_LIT:0.0> , <NUM_LIT:0> ) <EOL> try : <EOL>", "answer": "row = db [ id ]"}, {"prompt": "<s> import os <EOL> import base64 <EOL> from datetime import datetime <EOL> from xos . config import Config <EOL> from xos . logger import Logger , logging <EOL> from synchronizers . base . steps import * <EOL> from django . db . models import F , Q <EOL> from core . models import * <EOL> from django . db import reset_queries <EOL> import json <EOL> import time <EOL> import pdb <EOL> import traceback <EOL> logger = Logger ( level = logging . INFO ) <EOL> def f7 ( seq ) : <EOL> seen = set ( ) <EOL> seen_add = seen . add <EOL> return [ x for x in seq if not ( x in seen or seen_add ( x ) ) ] <EOL> def elim_dups ( backend_str ) : <EOL> strs = backend_str . split ( '<STR_LIT:/>' ) <EOL> strs = map ( lambda x : x . split ( '<STR_LIT:(>' ) [ <NUM_LIT:0> ] , strs ) <EOL> strs2 = f7 ( strs ) <EOL> return '<STR_LIT:/>' . join ( strs2 ) <EOL>", "answer": "def deepgetattr ( obj , attr ) :"}, {"prompt": "<s> from videocore import __version__ <EOL> from distutils . core import setup <EOL> setup ( name = '<STR_LIT>' , <EOL> version = __version__ , <EOL> description = '<STR_LIT>' , <EOL> author = '<STR_LIT>' , <EOL> author_email = '<STR_LIT>' , <EOL> url = '<STR_LIT>' , <EOL>", "answer": "packages = [ '<STR_LIT>' ]"}, {"prompt": "<s> from django . db import models <EOL> class Page ( models . Model ) : <EOL> title = models . CharField ( max_length = <NUM_LIT:255> , default = \"<STR_LIT>\" , blank = True ) <EOL> type = models . CharField ( max_length = <NUM_LIT:50> , default = \"<STR_LIT>\" , blank = True ) <EOL> content = models . TextField ( default = \"<STR_LIT>\" , blank = True ) <EOL> @ models . permalink <EOL> def get_absolute_url ( self ) : <EOL> return ( '<STR_LIT>' , [ self . type ] , { } ) <EOL> def __unicode__ ( self ) : <EOL> return self . title or self . content <EOL> class Product ( models . Model ) : <EOL> meta_description = models . TextField ( default = \"<STR_LIT>\" ) <EOL> meta_keywords = models . CharField ( max_length = <NUM_LIT:255> , default = \"<STR_LIT>\" ) <EOL> meta_title = models . CharField ( max_length = <NUM_LIT:255> , default = \"<STR_LIT>\" ) <EOL> @ models . permalink <EOL> def get_absolute_url ( self ) : <EOL> return ( '<STR_LIT>' , [ self . id ] , { } ) <EOL> def __unicode__ ( self ) : <EOL> return self . meta_title <EOL> class Category ( models . Model ) : <EOL> name = models . CharField ( max_length = <NUM_LIT:255> , default = \"<STR_LIT>\" ) <EOL> page_title = models . CharField ( max_length = <NUM_LIT:255> , default = \"<STR_LIT>\" ) <EOL> @ models . permalink <EOL> def get_absolute_url ( self ) : <EOL> return ( '<STR_LIT>' , [ \"<STR_LIT:abc>\" ] , { } ) <EOL> class NoPath ( models . Model ) : <EOL> pass <EOL> class Tag ( models . Model ) : <EOL> name = models . CharField ( max_length = <NUM_LIT:255> , default = \"<STR_LIT>\" ) <EOL> @ models . permalink <EOL>", "answer": "def get_absolute_url ( self ) :"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import numpy as np <EOL> import os <EOL> np . random . seed ( <NUM_LIT> ) <EOL> ngroup = <NUM_LIT:100> <EOL> n_min = <NUM_LIT:1> <EOL> n_max = <NUM_LIT:5> <EOL> dsix = <NUM_LIT:0> <EOL> for pr in <NUM_LIT:1> , <NUM_LIT:2> : <EOL> re_sd = np . linspace ( - <NUM_LIT:0.5> , <NUM_LIT> , pr ) <EOL> for pf in <NUM_LIT:1> , <NUM_LIT:2> , <NUM_LIT:3> : <EOL> for sig in <NUM_LIT:0.5> , <NUM_LIT:2> : <EOL> params = np . linspace ( - <NUM_LIT:1> , <NUM_LIT:1> , pf ) <EOL> endog = [ ] <EOL> exog_fe = [ ] <EOL> exog_re = [ ] <EOL> groups = [ ] <EOL> for i in range ( ngroup ) : <EOL> n = np . random . randint ( n_min , n_max , <NUM_LIT:1> ) <EOL> x_fe = np . random . normal ( size = ( n , pf ) ) <EOL> x_re = np . zeros ( ( n , pr ) ) <EOL> u = np . linspace ( - <NUM_LIT:1> , <NUM_LIT:1> , n ) <EOL> for j in range ( pr ) : <EOL> x_re [ : , j ] = u ** j <EOL> re = np . random . normal ( size = pr ) * re_sd <EOL> expval = np . dot ( x_fe , params ) + np . dot ( x_re , re ) <EOL> endog . append ( expval + sig * np . random . normal ( size = n ) ) <EOL> exog_fe . append ( x_fe ) <EOL> exog_re . append ( x_re ) <EOL> groups . append ( i * np . ones ( n ) ) <EOL> endog = np . concatenate ( endog ) <EOL> exog_fe = np . concatenate ( exog_fe , axis = <NUM_LIT:0> ) <EOL> exog_re = np . concatenate ( exog_re , axis = <NUM_LIT:0> ) <EOL> groups = np . concatenate ( groups , axis = <NUM_LIT:0> ) <EOL> data = np . concatenate ( ( groups [ : , None ] , endog [ : , None ] , <EOL>", "answer": "exog_fe , exog_re ) , axis = <NUM_LIT:1> )"}, {"prompt": "<s> import time <EOL> from oslo_utils import timeutils <EOL> from saharaclient . api import base as sab <EOL> from tempest import config <EOL> from tempest import exceptions <EOL> from tempest . lib . common . utils import data_utils <EOL> from tempest . lib import decorators <EOL> from tempest import test <EOL> from sahara . tests . tempest . scenario . data_processing . client_tests import base <EOL> TEMPEST_CONF = config . CONF <EOL> class JobExecutionTest ( base . BaseDataProcessingTest ) : <EOL> def _check_register_image ( self , image_id ) : <EOL> self . client . images . update_image ( <EOL> image_id , TEMPEST_CONF . scenario . ssh_user , '<STR_LIT>' ) <EOL> reg_image = self . client . images . get ( image_id ) <EOL> self . assertDictContainsSubset ( <EOL> { '<STR_LIT>' : TEMPEST_CONF . scenario . ssh_user } , <EOL> reg_image . metadata ) <EOL> def _check_image_get ( self , image_id ) : <EOL> image = self . client . images . get ( image_id ) <EOL> self . assertEqual ( image_id , image . id ) <EOL> def _check_image_list ( self , image_id ) : <EOL> image_list = self . client . images . list ( ) <EOL> images_info = [ image . id for image in image_list ] <EOL> self . assertIn ( image_id , images_info ) <EOL> def _check_adding_tags ( self , image_id ) : <EOL> self . client . images . update_tags ( image_id , [ '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> image = self . client . images . get ( image_id ) <EOL> self . assertDictContainsSubset ( { '<STR_LIT>' : '<STR_LIT:True>' , <EOL> '<STR_LIT>' : '<STR_LIT:True>' } , <EOL> image . metadata ) <EOL> def _check_deleting_tags ( self , image_id ) : <EOL> self . client . images . update_tags ( image_id , [ ] ) <EOL> image = self . client . images . get ( image_id ) <EOL> self . assertNotIn ( '<STR_LIT>' , image . metadata ) <EOL> self . assertNotIn ( '<STR_LIT>' , image . metadata ) <EOL> def _check_unregister_image ( self , image_id ) : <EOL> self . client . images . unregister_image ( image_id ) <EOL> image_list = self . client . images . list ( ) <EOL> self . assertNotIn ( image_id , [ image . id for image in image_list ] ) <EOL> def _check_cluster_create ( self ) : <EOL> worker = self . create_node_group_template ( <EOL> data_utils . rand_name ( '<STR_LIT>' ) , ** self . worker_template ) <EOL> master = self . create_node_group_template ( <EOL> data_utils . rand_name ( '<STR_LIT>' ) , ** self . master_template ) <EOL> cluster_templ = self . cluster_template . copy ( ) <EOL> cluster_templ [ '<STR_LIT>' ] = [ <EOL> { <EOL> '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : master . id , <EOL> '<STR_LIT:count>' : <NUM_LIT:1> <EOL> } , <EOL> { <EOL> '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : worker . id , <EOL> '<STR_LIT:count>' : <NUM_LIT:3> <EOL> } <EOL> ] <EOL> if TEMPEST_CONF . service_available . neutron : <EOL> cluster_templ [ '<STR_LIT>' ] = self . get_private_network_id ( ) <EOL> cluster_template = self . create_cluster_template ( <EOL> data_utils . rand_name ( '<STR_LIT>' ) , ** cluster_templ ) <EOL> cluster_name = data_utils . rand_name ( '<STR_LIT>' ) <EOL> self . cluster_info = { <EOL> '<STR_LIT:name>' : cluster_name , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : cluster_template . id , <EOL> '<STR_LIT>' : TEMPEST_CONF . data_processing . fake_image_id <EOL> } <EOL> cluster = self . create_cluster ( ** self . cluster_info ) <EOL> self . check_cluster_active ( cluster . id ) <EOL> self . assertEqual ( cluster_name , cluster . name ) <EOL> self . assertDictContainsSubset ( self . cluster_info , cluster . __dict__ ) <EOL> return cluster . id , cluster . name <EOL> def _check_cluster_list ( self , cluster_id , cluster_name ) : <EOL> cluster_list = self . client . clusters . list ( ) <EOL> clusters_info = [ ( clust . id , clust . name ) for clust in cluster_list ] <EOL> self . assertIn ( ( cluster_id , cluster_name ) , clusters_info ) <EOL> def _check_cluster_get ( self , cluster_id , cluster_name ) : <EOL> cluster = self . client . clusters . get ( cluster_id ) <EOL> self . assertEqual ( cluster_name , cluster . name ) <EOL> self . assertDictContainsSubset ( self . cluster_info , cluster . __dict__ ) <EOL> def _check_cluster_update ( self , cluster_id ) : <EOL> values = { <EOL> '<STR_LIT:name>' : data_utils . rand_name ( '<STR_LIT>' ) , <EOL> '<STR_LIT:description>' : '<STR_LIT:description>' <EOL> } <EOL> cluster = self . client . clusters . update ( cluster_id ) <EOL> self . assertDictContainsSubset ( values , cluster . __dict__ ) <EOL> def _check_cluster_scale ( self , cluster_id ) : <EOL> big_worker = self . create_node_group_template ( <EOL> data_utils . rand_name ( '<STR_LIT>' ) , ** self . worker_template ) <EOL> scale_body = { <EOL> '<STR_LIT>' : [ <EOL> { <EOL> '<STR_LIT:count>' : <NUM_LIT:2> , <EOL> '<STR_LIT:name>' : '<STR_LIT>' <EOL> } , <EOL> { <EOL> \"<STR_LIT:count>\" : <NUM_LIT:2> , <EOL> \"<STR_LIT:name>\" : '<STR_LIT>' <EOL> } <EOL> ] , <EOL> '<STR_LIT>' : [ <EOL> { <EOL> '<STR_LIT:count>' : <NUM_LIT:1> , <EOL> '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : big_worker . id <EOL> } <EOL> ] <EOL> } <EOL> self . client . clusters . scale ( cluster_id , scale_body ) <EOL> self . check_cluster_active ( cluster_id ) <EOL> cluster = self . client . clusters . get ( cluster_id ) <EOL> for ng in cluster . node_groups : <EOL> if ng [ '<STR_LIT:name>' ] == scale_body [ '<STR_LIT>' ] [ <NUM_LIT:0> ] [ '<STR_LIT:name>' ] : <EOL> self . assertDictContainsSubset ( <EOL> scale_body [ '<STR_LIT>' ] [ <NUM_LIT:0> ] , ng ) <EOL> elif ng [ '<STR_LIT:name>' ] == scale_body [ '<STR_LIT>' ] [ <NUM_LIT:1> ] [ '<STR_LIT:name>' ] : <EOL> self . assertDictContainsSubset ( <EOL> scale_body [ '<STR_LIT>' ] [ <NUM_LIT:1> ] , ng ) <EOL> elif ng [ '<STR_LIT:name>' ] == scale_body [ '<STR_LIT>' ] [ <NUM_LIT:0> ] [ '<STR_LIT:name>' ] : <EOL> self . assertDictContainsSubset ( <EOL> scale_body [ '<STR_LIT>' ] [ <NUM_LIT:0> ] , ng ) <EOL> def _check_cluster_delete ( self , cluster_id ) : <EOL> self . client . clusters . delete ( cluster_id ) <EOL> cluster = self . client . clusters . get ( cluster_id ) <EOL> self . assertEqual ( '<STR_LIT>' , cluster . status ) <EOL> timeout = TEMPEST_CONF . data_processing . cluster_timeout <EOL> s_time = timeutils . utcnow ( ) <EOL> while timeutils . delta_seconds ( s_time , timeutils . utcnow ( ) ) < timeout : <EOL> try : <EOL> self . client . clusters . get ( cluster_id ) <EOL> except sab . APIException : <EOL> return <EOL> time . sleep ( TEMPEST_CONF . data_processing . request_timeout ) <EOL> raise exceptions . TimeoutException ( '<STR_LIT>' <EOL> '<STR_LIT>' % timeout ) <EOL> def _check_job_execution_create ( self , cluster_id ) : <EOL> container_name = data_utils . rand_name ( '<STR_LIT>' ) <EOL> self . create_container ( container_name ) <EOL> input_file_name = data_utils . rand_name ( '<STR_LIT:input>' ) <EOL> self . object_client . create_object ( container_name , input_file_name , <EOL> '<STR_LIT>' ) <EOL> input_file_url = '<STR_LIT>' % ( container_name , input_file_name ) <EOL> input_source_name = data_utils . rand_name ( '<STR_LIT>' ) <EOL> input_source = self . create_data_source ( <EOL> input_source_name , input_file_url , '<STR_LIT>' , '<STR_LIT>' , <EOL> { '<STR_LIT:user>' : '<STR_LIT:test>' , '<STR_LIT:password>' : '<STR_LIT>' } ) <EOL> output_dir_name = data_utils . rand_name ( '<STR_LIT>' ) <EOL> output_dir_url = '<STR_LIT>' % ( container_name , output_dir_name ) <EOL> output_source_name = data_utils . rand_name ( '<STR_LIT>' ) <EOL> output_source = self . create_data_source ( <EOL> output_source_name , output_dir_url , '<STR_LIT>' , '<STR_LIT>' , <EOL> { '<STR_LIT:user>' : '<STR_LIT:test>' , '<STR_LIT:password>' : '<STR_LIT>' } ) <EOL> job_binary = { <EOL> '<STR_LIT:name>' : data_utils . rand_name ( '<STR_LIT>' ) , <EOL> '<STR_LIT:url>' : input_file_url , <EOL> '<STR_LIT:description>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:user>' : '<STR_LIT:test>' , <EOL> '<STR_LIT:password>' : '<STR_LIT>' <EOL> } <EOL> } <EOL> job_binary = self . create_job_binary ( ** job_binary ) <EOL> job_name = data_utils . rand_name ( '<STR_LIT>' ) <EOL> job = self . create_job ( job_name , '<STR_LIT>' , [ job_binary . id ] ) <EOL> self . job_exec_info = { <EOL> '<STR_LIT>' : job . id , <EOL> '<STR_LIT>' : cluster_id , <EOL> '<STR_LIT>' : input_source . id , <EOL> '<STR_LIT>' : output_source . id , <EOL> '<STR_LIT>' : { } <EOL> } <EOL> job_execution = self . create_job_execution ( ** self . job_exec_info ) <EOL> return job_execution . id <EOL> def _check_job_execution_list ( self , job_exec_id ) : <EOL> job_exec_list = self . client . job_executions . list ( ) <EOL> self . assertIn ( job_exec_id , [ job_exec . id for job_exec in job_exec_list ] ) <EOL> def _check_job_execution_get ( self , job_exec_id ) : <EOL> job_exec = self . client . job_executions . get ( job_exec_id ) <EOL> job_exec_info = self . job_exec_info . copy ( ) <EOL> del job_exec_info [ '<STR_LIT>' ] <EOL> self . assertDictContainsSubset ( job_exec_info , job_exec . __dict__ ) <EOL> def _check_job_execution_update ( self , job_exec_id ) : <EOL> values = { <EOL> '<STR_LIT>' : True <EOL> } <EOL> job_exec = self . client . job_executions . update ( job_exec_id , ** values ) <EOL> self . assertDictContainsSubset ( values , job_exec . __dict__ ) <EOL> def _check_job_execution_delete ( self , job_exec_id ) : <EOL> self . client . job_executions . delete ( job_exec_id ) <EOL> job_exec_list = self . client . jobs . list ( ) <EOL> self . assertNotIn ( job_exec_id , [ job_exec . id for <EOL> job_exec in job_exec_list ] ) <EOL> @ decorators . skip_because ( bug = \"<STR_LIT>\" ) <EOL> @ test . attr ( type = '<STR_LIT>' ) <EOL> @ test . services ( '<STR_LIT>' ) <EOL> def test_job_executions ( self ) : <EOL> image_id = TEMPEST_CONF . data_processing . fake_image_id <EOL> self . _check_register_image ( image_id ) <EOL> self . _check_image_get ( image_id ) <EOL> self . _check_image_list ( image_id ) <EOL> self . _check_adding_tags ( image_id ) <EOL> cluster_id , cluster_name = self . _check_cluster_create ( ) <EOL> self . _check_cluster_list ( cluster_id , cluster_name ) <EOL> self . _check_cluster_get ( cluster_id , cluster_name ) <EOL> self . _check_cluster_update ( cluster_id ) <EOL> self . _check_cluster_scale ( cluster_id ) <EOL> job_exec_id = self . _check_job_execution_create ( cluster_id ) <EOL> self . _check_job_execution_list ( job_exec_id ) <EOL> self . _check_job_execution_get ( job_exec_id ) <EOL> self . _check_job_execution_update ( job_exec_id ) <EOL> self . _check_job_execution_delete ( job_exec_id ) <EOL> self . _check_cluster_delete ( cluster_id ) <EOL>", "answer": "self . _check_deleting_tags ( image_id )"}, {"prompt": "<s> from __future__ import ( absolute_import , division , generators , nested_scopes , print_function , <EOL> unicode_literals , with_statement ) <EOL> import logging <EOL> import select <EOL> from pants . pantsd . pailgun_server import PailgunServer <EOL> from pants . pantsd . service . pants_service import PantsService <EOL> class PailgunService ( PantsService ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , bind_addr , exiter_class , runner_class ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> super ( PailgunService , self ) . __init__ ( ) <EOL> self . _logger = logging . getLogger ( __name__ ) <EOL> self . _bind_addr = bind_addr <EOL> self . _exiter_class = exiter_class <EOL> self . _runner_class = runner_class <EOL> self . _pailgun = None <EOL> @ property <EOL> def pailgun ( self ) : <EOL> if not self . _pailgun : <EOL>", "answer": "self . _pailgun = self . _setup_pailgun ( )"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import os <EOL> import sys <EOL> current_dir = os . path . dirname ( os . path . realpath ( __file__ ) ) <EOL> sys . path . append ( current_dir ) <EOL> import switch_virtualenv <EOL> from compass . utils import flags <EOL> from compass . utils import logsetting <EOL> from compass . utils import setting_wrapper as setting <EOL> flags . init ( ) <EOL> flags . OPTIONS . logfile = setting . WEB_LOGFILE <EOL> logsetting . init ( ) <EOL> from compass . api import api as compass_api <EOL>", "answer": "compass_api . init ( )"}, {"prompt": "<s> from xierpa3 . components . component import Component <EOL> class Sidebar ( Component ) : <EOL>", "answer": "C = Component . C "}, {"prompt": "<s> from SimpleCV import * <EOL> import time <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def identifyGender ( ) : <EOL> f = FaceRecognizer ( ) <EOL> cam = Camera ( ) <EOL> img = cam . getImage ( ) <EOL> cascade = LAUNCH_PATH + \"<STR_LIT:/>\" + \"<STR_LIT>\" <EOL> feat = img . findHaarFeatures ( cascade ) <EOL> if feat : <EOL> crop_image = feat . sortArea ( ) [ - <NUM_LIT:1> ] . crop ( ) <EOL> feat . sortArea ( ) [ - <NUM_LIT:1> ] . draw ( ) <EOL> f . load ( LAUNCH_PATH + \"<STR_LIT:/>\" + \"<STR_LIT>\" ) <EOL> w , h = f . imageSize <EOL> crop_image = crop_image . resize ( w , h ) <EOL> label , confidence = f . predict ( crop_image ) <EOL>", "answer": "print label"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> from pwn import * <EOL> shell = ssh ( host = '<STR_LIT>' , user = '<STR_LIT>' , password = '<STR_LIT>' ) <EOL> log . info ( \"<STR_LIT>\" % shell . whoami ( ) ) <EOL> log . info ( \"<STR_LIT>\" % shell . pwd ( ) ) <EOL> tube = shell . run ( '<STR_LIT>' ) <EOL> tube . send ( \"<STR_LIT>\" ) <EOL> tube . shutdown ( \"<STR_LIT>\" ) <EOL> print tube . recvall ( ) <EOL> shell . set_working_directory ( ) <EOL> log . info ( \"<STR_LIT>\" % shell . pwd ( ) ) <EOL>", "answer": "shell . upload_data ( \"\"\"<STR_LIT>\"\"\" , '<STR_LIT>' )"}, {"prompt": "<s> from numpy import array , sqrt , zeros <EOL> from numpy . random import randn <EOL> from numpy . testing import assert_allclose <EOL> from commpy . channelcoding . ldpc import get_ldpc_code_params , ldpc_bp_decode <EOL> from commpy . utilities import hamming_dist <EOL> import os <EOL> from nose . plugins . attrib import attr <EOL> @ attr ( '<STR_LIT>' ) <EOL> class TestLDPCCode ( object ) : <EOL> @ classmethod <EOL> def setup_class ( cls ) : <EOL> dir = os . path . dirname ( __file__ ) <EOL> ldpc_design_file_1 = os . path . join ( dir , '<STR_LIT>' ) <EOL> cls . ldpc_code_params = get_ldpc_code_params ( ldpc_design_file_1 ) <EOL> @ classmethod <EOL> def teardown_class ( cls ) : <EOL> pass <EOL> def test_ldpc_bp_decode ( self ) : <EOL> N = <NUM_LIT> <EOL> k = <NUM_LIT> <EOL> rate = <NUM_LIT:0.5> <EOL> Es = <NUM_LIT:1.0> <EOL> snr_list = array ( [ <NUM_LIT> , <NUM_LIT> ] ) <EOL> niters = <NUM_LIT> <EOL> tx_codeword = zeros ( N , int ) <EOL> ldpcbp_iters = <NUM_LIT:100> <EOL> fer_array_ref = array ( [ <NUM_LIT> / <NUM_LIT:1000> , <NUM_LIT> / <NUM_LIT> ] ) <EOL> fer_array_test = zeros ( len ( snr_list ) ) <EOL> for idx , ebno in enumerate ( snr_list ) : <EOL> noise_std = <NUM_LIT:1> / sqrt ( ( <NUM_LIT:10> ** ( ebno / <NUM_LIT> ) ) * rate * <NUM_LIT:2> / Es ) <EOL> fer_cnt_bp = <NUM_LIT:0> <EOL> for iter_cnt in xrange ( niters ) : <EOL> awgn_array = noise_std * randn ( N ) <EOL> rx_word = <NUM_LIT:1> - ( <NUM_LIT:2> * tx_codeword ) + awgn_array <EOL> rx_llrs = <NUM_LIT> * rx_word / ( noise_std ** <NUM_LIT:2> ) <EOL> [ dec_word , out_llrs ] = ldpc_bp_decode ( rx_llrs , self . ldpc_code_params , <EOL> ldpcbp_iters ) <EOL> num_bit_errors = hamming_dist ( tx_codeword , dec_word ) <EOL> if num_bit_errors > <NUM_LIT:0> : <EOL> fer_cnt_bp += <NUM_LIT:1> <EOL> if fer_cnt_bp >= <NUM_LIT:200> : <EOL> fer_array_test [ idx ] = float ( fer_cnt_bp ) / ( iter_cnt + <NUM_LIT:1> ) <EOL>", "answer": "break"}, {"prompt": "<s> import py <EOL> from pypy . tool . ansi_print import ansi_log <EOL> log = py . log . Producer ( \"<STR_LIT>\" ) <EOL> py . log . setconsumer ( \"<STR_LIT>\" , ansi_log ) <EOL> from pypy . objspace . flow import model as flowmodel <EOL> from pypy . rpython . ootypesystem import ootype <EOL> from pypy . translator . oosupport . treebuilder import SubOperation <EOL> from pypy . translator . oosupport . metavm import InstructionList , StoreResult <EOL> def render_sub_op ( sub_op , db , generator ) : <EOL> op = sub_op . op <EOL> instr_list = db . genoo . opcodes . get ( op . opname , None ) <EOL> assert instr_list is not None , '<STR_LIT>' % op <EOL> assert isinstance ( instr_list , InstructionList ) <EOL> assert instr_list [ - <NUM_LIT:1> ] is StoreResult , \"<STR_LIT>\" <EOL> db . cts . lltype_to_cts ( op . result . concretetype ) <EOL> for v in op . args : <EOL> db . cts . lltype_to_cts ( v . concretetype ) <EOL> instr_list = InstructionList ( instr_list [ : - <NUM_LIT:1> ] ) <EOL> instr_list . render ( generator , op ) <EOL> class Function ( object ) : <EOL> auto_propagate_exceptions = False <EOL> def __init__ ( self , db , graph , name = None , is_method = False , is_entrypoint = False ) : <EOL> self . db = db <EOL> self . cts = db . genoo . TypeSystem ( db ) <EOL> self . graph = graph <EOL> self . name = self . cts . escape_name ( name or graph . name ) <EOL> self . is_method = is_method <EOL> self . is_entrypoint = is_entrypoint <EOL> self . generator = None <EOL> self . label_counters = { } <EOL> def current_label ( self , prefix = '<STR_LIT:label>' ) : <EOL> current = self . label_counters . get ( prefix , <NUM_LIT:0> ) <EOL> return '<STR_LIT>' % ( prefix , current ) <EOL> def next_label ( self , prefix = '<STR_LIT:label>' ) : <EOL> current = self . label_counters . get ( prefix , <NUM_LIT:0> ) <EOL> self . label_counters [ prefix ] = current + <NUM_LIT:1> <EOL> return self . current_label ( prefix ) <EOL> def get_name ( self ) : <EOL> return self . name <EOL> def __repr__ ( self ) : <EOL> return '<STR_LIT>' % self . name <EOL> def __hash__ ( self ) : <EOL> return hash ( self . graph ) <EOL> def __eq__ ( self , other ) : <EOL> return self . graph == other . graph <EOL> def __ne__ ( self , other ) : <EOL> return not self == other <EOL> def _is_return_block ( self , block ) : <EOL> return ( not block . exits ) and len ( block . inputargs ) == <NUM_LIT:1> <EOL> def _is_raise_block ( self , block ) : <EOL> return ( not block . exits ) and len ( block . inputargs ) == <NUM_LIT:2> <EOL> def _is_exc_handling_block ( self , block ) : <EOL> return block . exitswitch == flowmodel . c_last_exception <EOL> def begin_render ( self ) : <EOL> raise NotImplementedError <EOL> def render_return_block ( self , block ) : <EOL> raise NotImplementedError <EOL> def render_raise_block ( self , block ) : <EOL> raise NotImplementedError <EOL> def begin_try ( self ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> raise NotImplementedError <EOL> def end_try ( self , target_label ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> raise NotImplementedError <EOL> def begin_catch ( self , llexitcase ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> raise NotImplementedError <EOL> def end_catch ( self , target_label ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> raise NotImplementedError <EOL> def render ( self , ilasm ) : <EOL> if self . db . graph_name ( self . graph ) is not None and not self . is_method : <EOL> return <EOL> self . ilasm = ilasm <EOL> self . generator = self . _create_generator ( self . ilasm ) <EOL> graph = self . graph <EOL> self . begin_render ( ) <EOL> self . return_block = None <EOL> self . raise_block = None <EOL> for block in graph . iterblocks ( ) : <EOL> if self . _is_return_block ( block ) : <EOL> self . return_block = block <EOL> elif self . _is_raise_block ( block ) : <EOL> self . raise_block = block <EOL> else : <EOL> self . set_label ( self . _get_block_name ( block ) ) <EOL> if self . _is_exc_handling_block ( block ) : <EOL> self . render_exc_handling_block ( block ) <EOL> else : <EOL> self . render_normal_block ( block ) <EOL> self . before_last_blocks ( ) <EOL> if self . raise_block : <EOL> self . set_label ( self . _get_block_name ( self . raise_block ) ) <EOL> self . render_raise_block ( self . raise_block ) <EOL> if self . return_block : <EOL> self . set_label ( self . _get_block_name ( self . return_block ) ) <EOL> self . render_return_block ( self . return_block ) <EOL> self . end_render ( ) <EOL> if not self . is_method : <EOL> self . db . record_function ( self . graph , self . name ) <EOL> def before_last_blocks ( self ) : <EOL> pass <EOL> def render_exc_handling_block ( self , block ) : <EOL> for op in block . operations [ : - <NUM_LIT:1> ] : <EOL> self . _render_op ( op ) <EOL> anyHandler = False <EOL> for link in block . exits : <EOL> if link . exitcase is None : <EOL> continue <EOL> anyHandler = anyHandler or not self . _auto_propagate ( link , block ) <EOL> if block . operations : <EOL> self . begin_try ( anyHandler ) <EOL>", "answer": "self . _render_op ( block . operations [ - <NUM_LIT:1> ] )"}, {"prompt": "<s> from __future__ import division <EOL> import warnings <EOL> import numpy as np <EOL> import scipy . sparse as sp <EOL> from . base import BaseEstimator , ClassifierMixin , RegressorMixin <EOL> from . utils import check_random_state <EOL> from . utils . validation import check_array <EOL> from . utils . validation import check_consistent_length <EOL> from . utils . random import random_choice_csc <EOL> from . utils . stats import _weighted_percentile <EOL> from . utils . multiclass import class_distribution <EOL> class DummyClassifier ( BaseEstimator , ClassifierMixin ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , strategy = \"<STR_LIT>\" , random_state = None , <EOL> constant = None ) : <EOL> self . strategy = strategy <EOL> self . random_state = random_state <EOL> self . constant = constant <EOL> def fit ( self , X , y , sample_weight = None ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if self . strategy not in ( \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" , <EOL> \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> if self . strategy == \"<STR_LIT>\" and sp . issparse ( y ) : <EOL> y = y . toarray ( ) <EOL> warnings . warn ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' , <EOL> UserWarning ) <EOL> self . sparse_output_ = sp . issparse ( y ) <EOL> if not self . sparse_output_ : <EOL> y = np . atleast_1d ( y ) <EOL> self . output_2d_ = y . ndim == <NUM_LIT:2> <EOL> if y . ndim == <NUM_LIT:1> : <EOL> y = np . reshape ( y , ( - <NUM_LIT:1> , <NUM_LIT:1> ) ) <EOL> self . n_outputs_ = y . shape [ <NUM_LIT:1> ] <EOL> if self . strategy == \"<STR_LIT>\" : <EOL> if self . constant is None : <EOL> raise ValueError ( \"<STR_LIT>\" <EOL> \"<STR_LIT>\" ) <EOL> else : <EOL> constant = np . reshape ( np . atleast_1d ( self . constant ) , ( - <NUM_LIT:1> , <NUM_LIT:1> ) ) <EOL> if constant . shape [ <NUM_LIT:0> ] != self . n_outputs_ : <EOL> raise ValueError ( \"<STR_LIT>\" <EOL> \"<STR_LIT>\" % self . n_outputs_ ) <EOL> ( self . classes_ , <EOL> self . n_classes_ , <EOL> self . class_prior_ ) = class_distribution ( y , sample_weight ) <EOL> if ( self . strategy == \"<STR_LIT>\" and <EOL> any ( constant [ k ] not in self . classes_ [ k ] <EOL> for k in range ( self . n_outputs_ ) ) ) : <EOL> raise ValueError ( \"<STR_LIT>\" <EOL> \"<STR_LIT>\" ) <EOL> if self . n_outputs_ == <NUM_LIT:1> and not self . output_2d_ : <EOL> self . n_classes_ = self . n_classes_ [ <NUM_LIT:0> ] <EOL> self . classes_ = self . classes_ [ <NUM_LIT:0> ] <EOL> self . class_prior_ = self . class_prior_ [ <NUM_LIT:0> ] <EOL> return self <EOL> def predict ( self , X ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if not hasattr ( self , \"<STR_LIT>\" ) : <EOL> raise ValueError ( \"<STR_LIT>\" ) <EOL> X = check_array ( X , accept_sparse = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] ) <EOL> n_samples = int ( X . shape [ <NUM_LIT:0> ] ) <EOL> rs = check_random_state ( self . random_state ) <EOL> n_classes_ = self . n_classes_ <EOL> classes_ = self . classes_ <EOL> class_prior_ = self . class_prior_ <EOL> constant = self . constant <EOL> if self . n_outputs_ == <NUM_LIT:1> : <EOL> n_classes_ = [ n_classes_ ] <EOL> classes_ = [ classes_ ] <EOL> class_prior_ = [ class_prior_ ] <EOL> constant = [ constant ] <EOL> if self . strategy == \"<STR_LIT>\" : <EOL> proba = self . predict_proba ( X ) <EOL> if self . n_outputs_ == <NUM_LIT:1> : <EOL> proba = [ proba ] <EOL> if self . sparse_output_ : <EOL> class_prob = None <EOL> if self . strategy in ( \"<STR_LIT>\" , \"<STR_LIT>\" ) : <EOL> classes_ = [ np . array ( [ cp . argmax ( ) ] ) for cp in class_prior_ ] <EOL> elif self . strategy == \"<STR_LIT>\" : <EOL>", "answer": "class_prob = class_prior_"}, {"prompt": "<s> from django . conf import settings <EOL> STAFF_ONLY = getattr ( settings , '<STR_LIT>' , False ) <EOL> DEFAULT_LIST_ID = getattr ( settings , '<STR_LIT>' , <NUM_LIT:1> ) <EOL> DEFAULT_ASSIGNEE = getattr ( settings , '<STR_LIT>' , None ) <EOL>", "answer": "PUBLIC_SUBMIT_REDIRECT = getattr ( settings , '<STR_LIT>' , '<STR_LIT:/>' ) "}, {"prompt": "<s> from wx . lib . embeddedimage import PyEmbeddedImage <EOL> retriever_logo_liberation = PyEmbeddedImage ( <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL>", "answer": "\"<STR_LIT>\""}, {"prompt": "<s> import re <EOL> def match_tag_equality ( _oid , data , key , term ) : <EOL> return data [ '<STR_LIT>' ] . get ( key ) == term <EOL> def match_tag_exists ( _oid , data , key ) : <EOL> return key in data [ '<STR_LIT>' ] <EOL>", "answer": "def match_any_tag_value ( _oid , data , term ) :"}, {"prompt": "<s> import stawk_db <EOL>", "answer": "import datetime"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> from __future__ import absolute_import <EOL> from slimta . core import SlimtaError <EOL> from slimta . smtp . reply import Reply <EOL> from slimta . policy import RelayPolicy <EOL> __all__ = [ '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ] <EOL> class RelayError ( SlimtaError ) : <EOL> def __init__ ( self , msg , reply = None ) : <EOL> super ( RelayError , self ) . __init__ ( msg ) <EOL> if reply : <EOL> self . reply = reply <EOL> else : <EOL> reply_msg = '<STR_LIT:U+0020>' . join ( ( self . _default_esc , msg ) ) <EOL> self . reply = Reply ( self . _default_code , reply_msg ) <EOL> class PermanentRelayError ( RelayError ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> _default_code = '<STR_LIT>' <EOL> _default_esc = '<STR_LIT>' <EOL> class TransientRelayError ( RelayError ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> _default_code = '<STR_LIT>' <EOL> _default_esc = '<STR_LIT>' <EOL> class Relay ( object ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self ) : <EOL> self . relay_policies = [ ] <EOL> def add_policy ( self , policy ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> if isinstance ( policy , RelayPolicy ) : <EOL> self . relay_policies . append ( policy ) <EOL> else : <EOL> raise TypeError ( '<STR_LIT>' ) <EOL> def _run_policies ( self , envelope ) : <EOL> for policy in self . relay_policies : <EOL> policy . apply ( envelope ) <EOL> def _attempt ( self , envelope , attempts ) : <EOL> self . _run_policies ( envelope ) <EOL> return self . attempt ( envelope , attempts ) <EOL> def attempt ( self , envelope , attempts ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> raise NotImplementedError ( ) <EOL> def kill ( self ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL>", "answer": "pass "}, {"prompt": "<s> from django . conf . urls import patterns , url <EOL> from siteuser . users import views <EOL> from siteuser . settings import USING_SOCIAL_LOGIN <EOL> urlpatterns = patterns ( '<STR_LIT>' , <EOL> url ( r'<STR_LIT>' , views . SiteUserLoginView . as_view ( ) , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , views . SiteUserRegisterView . as_view ( ) , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , views . SiteUserResetPwStepOneView . as_view ( ) , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , views . SiteUserResetPwStepOneDoneView . as_view ( ) , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , views . SiteUserResetPwStepTwoDoneView . as_view ( ) , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , views . SiteUserResetPwStepTwoView . as_view ( ) , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , views . SiteUserChangePwView . as_view ( ) , name = '<STR_LIT>' ) , <EOL> url ( r'<STR_LIT>' , views . SiteUserChangePwDoneView . as_view ( ) , name = '<STR_LIT>' ) , <EOL>", "answer": "url ( r'<STR_LIT>' , views . logout , name = '<STR_LIT>' ) ,"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import codecs <EOL> import serial <EOL> try : <EOL> unicode <EOL> except ( NameError , AttributeError ) : <EOL> unicode = str <EOL> HEXDIGITS = '<STR_LIT>' <EOL> def hex_encode ( data , errors = '<STR_LIT:strict>' ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> return ( serial . to_bytes ( [ int ( h , <NUM_LIT:16> ) for h in data . split ( ) ] ) , len ( data ) ) <EOL> def hex_decode ( data , errors = '<STR_LIT:strict>' ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> return ( unicode ( '<STR_LIT>' . join ( '<STR_LIT>' . format ( ord ( b ) ) for b in serial . iterbytes ( data ) ) ) , len ( data ) ) <EOL> class Codec ( codecs . Codec ) : <EOL> def encode ( self , data , errors = '<STR_LIT:strict>' ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> return serial . to_bytes ( [ int ( h , <NUM_LIT:16> ) for h in data . split ( ) ] ) <EOL> def decode ( self , data , errors = '<STR_LIT:strict>' ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> return unicode ( '<STR_LIT>' . join ( '<STR_LIT>' . format ( ord ( b ) ) for b in serial . iterbytes ( data ) ) ) <EOL> class IncrementalEncoder ( codecs . IncrementalEncoder ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , errors = '<STR_LIT:strict>' ) : <EOL> self . errors = errors <EOL> self . state = <NUM_LIT:0> <EOL> def reset ( self ) : <EOL> self . state = <NUM_LIT:0> <EOL> def getstate ( self ) : <EOL> return self . state <EOL> def setstate ( self , state ) : <EOL> self . state = state <EOL> def encode ( self , data , final = False ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> state = self . state <EOL> encoded = [ ] <EOL> for c in data . upper ( ) : <EOL> if c in HEXDIGITS : <EOL> z = HEXDIGITS . index ( c ) <EOL> if state : <EOL> encoded . append ( z + ( state & <NUM_LIT> ) ) <EOL> state = <NUM_LIT:0> <EOL> else : <EOL> state = <NUM_LIT> + ( z << <NUM_LIT:4> ) <EOL> elif c == '<STR_LIT:U+0020>' : <EOL> if state and self . errors == '<STR_LIT:strict>' : <EOL> raise UnicodeError ( '<STR_LIT>' ) <EOL> state = <NUM_LIT:0> <EOL> else : <EOL> if self . errors == '<STR_LIT:strict>' : <EOL> raise UnicodeError ( '<STR_LIT>' % c ) <EOL> self . state = state <EOL> return serial . to_bytes ( encoded ) <EOL> class IncrementalDecoder ( codecs . IncrementalDecoder ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def decode ( self , data , final = False ) : <EOL> return unicode ( '<STR_LIT>' . join ( '<STR_LIT>' . format ( ord ( b ) ) for b in serial . iterbytes ( data ) ) ) <EOL> class StreamWriter ( Codec , codecs . StreamWriter ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> class StreamReader ( Codec , codecs . StreamReader ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL>", "answer": "def getregentry ( ) :"}, {"prompt": "<s> import py <EOL> import sys , os , re <EOL> from pypy . rlib . rarithmetic import r_longlong <EOL> from pypy . rlib . debug import ll_assert , debug_print <EOL> from pypy . translator . translator import TranslationContext <EOL> from pypy . translator . backendopt import all <EOL> from pypy . translator . c . genc import CStandaloneBuilder , ExternalCompilationInfo <EOL> from pypy . annotation . listdef import s_list_of_strings <EOL> from pypy . tool . udir import udir <EOL> from pypy . tool . autopath import pypydir <EOL> class TestStandalone ( object ) : <EOL> config = None <EOL> def test_hello_world ( self ) : <EOL> def entry_point ( argv ) : <EOL> os . write ( <NUM_LIT:1> , \"<STR_LIT>\" ) <EOL> argv = argv [ <NUM_LIT:1> : ] <EOL> os . write ( <NUM_LIT:1> , \"<STR_LIT>\" + str ( len ( argv ) ) + \"<STR_LIT:\\n>\" ) <EOL> for s in argv : <EOL> os . write ( <NUM_LIT:1> , \"<STR_LIT>\" + str ( s ) + \"<STR_LIT>\" ) <EOL> return <NUM_LIT:0> <EOL> t = TranslationContext ( self . config ) <EOL> t . buildannotator ( ) . build_types ( entry_point , [ s_list_of_strings ] ) <EOL> t . buildrtyper ( ) . specialize ( ) <EOL> cbuilder = CStandaloneBuilder ( t , entry_point , t . config ) <EOL> cbuilder . generate_source ( ) <EOL> cbuilder . compile ( ) <EOL> data = cbuilder . cmdexec ( '<STR_LIT>' ) <EOL> assert data . startswith ( '''<STR_LIT>''' ) <EOL> def test_print ( self ) : <EOL> def entry_point ( argv ) : <EOL> print \"<STR_LIT>\" <EOL> argv = argv [ <NUM_LIT:1> : ] <EOL> print \"<STR_LIT>\" , len ( argv ) <EOL> print \"<STR_LIT>\" , argv <EOL> print \"<STR_LIT>\" , <EOL> print [ len ( s ) for s in argv ] <EOL> return <NUM_LIT:0> <EOL> t = TranslationContext ( self . config ) <EOL> t . buildannotator ( ) . build_types ( entry_point , [ s_list_of_strings ] ) <EOL> t . buildrtyper ( ) . specialize ( ) <EOL> cbuilder = CStandaloneBuilder ( t , entry_point , t . config ) <EOL> cbuilder . generate_source ( ) <EOL> cbuilder . compile ( ) <EOL> data = cbuilder . cmdexec ( '<STR_LIT>' ) <EOL> assert data . startswith ( '''<STR_LIT>''' <EOL> '''<STR_LIT>''' <EOL> '''<STR_LIT>''' <EOL> '''<STR_LIT>''' ) <EOL> def test_counters ( self ) : <EOL> from pypy . rpython . lltypesystem import lltype <EOL> from pypy . rpython . lltypesystem . lloperation import llop <EOL> def entry_point ( argv ) : <EOL> llop . instrument_count ( lltype . Void , '<STR_LIT:test>' , <NUM_LIT:2> ) <EOL> llop . instrument_count ( lltype . Void , '<STR_LIT:test>' , <NUM_LIT:1> ) <EOL> llop . instrument_count ( lltype . Void , '<STR_LIT:test>' , <NUM_LIT:1> ) <EOL> llop . instrument_count ( lltype . Void , '<STR_LIT:test>' , <NUM_LIT:2> ) <EOL> llop . instrument_count ( lltype . Void , '<STR_LIT:test>' , <NUM_LIT:1> ) <EOL> return <NUM_LIT:0> <EOL> t = TranslationContext ( self . config ) <EOL> t . config . translation . instrument = True <EOL> t . buildannotator ( ) . build_types ( entry_point , [ s_list_of_strings ] ) <EOL> t . buildrtyper ( ) . specialize ( ) <EOL> cbuilder = CStandaloneBuilder ( t , entry_point , config = t . config ) <EOL> cbuilder . generate_source ( ) <EOL> cbuilder . compile ( ) <EOL> counters_fname = udir . join ( \"<STR_LIT>\" ) <EOL> os . environ [ '<STR_LIT>' ] = str ( counters_fname ) <EOL> try : <EOL> data = cbuilder . cmdexec ( ) <EOL> finally : <EOL> del os . environ [ '<STR_LIT>' ] <EOL> f = counters_fname . open ( '<STR_LIT:rb>' ) <EOL> counters_data = f . read ( ) <EOL> f . close ( ) <EOL> import struct <EOL> counters = struct . unpack ( \"<STR_LIT>\" , counters_data ) <EOL> assert counters == ( <NUM_LIT:0> , <NUM_LIT:3> , <NUM_LIT:2> ) <EOL> def test_prof_inline ( self ) : <EOL> if sys . platform == '<STR_LIT:win32>' : <EOL> py . test . skip ( \"<STR_LIT>\" ) <EOL> def add ( a , b ) : <EOL> return a + b - b + b - b + b - b + b - b + b - b + b - b + b <EOL> def entry_point ( argv ) : <EOL> tot = <NUM_LIT:0> <EOL> x = int ( argv [ <NUM_LIT:1> ] ) <EOL> while x > <NUM_LIT:0> : <EOL> tot = add ( tot , x ) <EOL> x -= <NUM_LIT:1> <EOL> os . write ( <NUM_LIT:1> , str ( tot ) ) <EOL> return <NUM_LIT:0> <EOL> from pypy . translator . interactive import Translation <EOL> t = Translation ( entry_point , backend = '<STR_LIT:c>' , standalone = True ) <EOL> t . backendopt ( inline_threshold = <NUM_LIT:100> , profile_based_inline = \"<STR_LIT>\" ) <EOL> exe = t . compile ( ) <EOL> out = py . process . cmdexec ( \"<STR_LIT>\" % exe ) <EOL> assert int ( out ) == <NUM_LIT> * <NUM_LIT> / <NUM_LIT:2> <EOL> t = Translation ( entry_point , backend = '<STR_LIT:c>' , standalone = True ) <EOL> t . backendopt ( inline_threshold = all . INLINE_THRESHOLD_FOR_TEST * <NUM_LIT:0.5> , <EOL> profile_based_inline = \"<STR_LIT>\" ) <EOL> exe = t . compile ( ) <EOL> out = py . process . cmdexec ( \"<STR_LIT>\" % exe ) <EOL> assert int ( out ) == <NUM_LIT> * <NUM_LIT> / <NUM_LIT:2> <EOL> def test_frexp ( self ) : <EOL> import math <EOL> def entry_point ( argv ) : <EOL> m , e = math . frexp ( <NUM_LIT:0> ) <EOL> x , y = math . frexp ( <NUM_LIT:0> ) <EOL> print m , x <EOL> return <NUM_LIT:0> <EOL> t = TranslationContext ( self . config ) <EOL> t . buildannotator ( ) . build_types ( entry_point , [ s_list_of_strings ] ) <EOL> t . buildrtyper ( ) . specialize ( ) <EOL> cbuilder = CStandaloneBuilder ( t , entry_point , t . config ) <EOL> cbuilder . generate_source ( ) <EOL> cbuilder . compile ( ) <EOL> data = cbuilder . cmdexec ( '<STR_LIT>' ) <EOL> assert map ( float , data . split ( ) ) == [ <NUM_LIT:0.0> , <NUM_LIT:0.0> ] <EOL> def test_profopt ( self ) : <EOL> def add ( a , b ) : <EOL> return a + b - b + b - b + b - b + b - b + b - b + b - b + b <EOL> def entry_point ( argv ) : <EOL> tot = <NUM_LIT:0> <EOL> x = int ( argv [ <NUM_LIT:1> ] ) <EOL> while x > <NUM_LIT:0> : <EOL> tot = add ( tot , x ) <EOL> x -= <NUM_LIT:1> <EOL> os . write ( <NUM_LIT:1> , str ( tot ) ) <EOL> return <NUM_LIT:0> <EOL> from pypy . translator . interactive import Translation <EOL> t = Translation ( entry_point , backend = '<STR_LIT:c>' , standalone = True , profopt = \"<STR_LIT>\" ) <EOL> t . backendopt ( ) <EOL> exe = t . compile ( ) <EOL> out = py . process . cmdexec ( \"<STR_LIT>\" % exe ) <EOL> assert int ( out ) == <NUM_LIT> * <NUM_LIT> / <NUM_LIT:2> <EOL> t = Translation ( entry_point , backend = '<STR_LIT:c>' , standalone = True , profopt = \"<STR_LIT>\" , <EOL> noprofopt = True ) <EOL> t . backendopt ( ) <EOL> exe = t . compile ( ) <EOL> out = py . process . cmdexec ( \"<STR_LIT>\" % exe ) <EOL> assert int ( out ) == <NUM_LIT> * <NUM_LIT> / <NUM_LIT:2> <EOL> if hasattr ( os , '<STR_LIT>' ) : <EOL> def test_os_setpgrp ( self ) : <EOL> def entry_point ( argv ) : <EOL> os . setpgrp ( ) <EOL> return <NUM_LIT:0> <EOL> t = TranslationContext ( self . config ) <EOL> t . buildannotator ( ) . build_types ( entry_point , [ s_list_of_strings ] ) <EOL> t . buildrtyper ( ) . specialize ( ) <EOL> cbuilder = CStandaloneBuilder ( t , entry_point , t . config ) <EOL> cbuilder . generate_source ( ) <EOL> cbuilder . compile ( ) <EOL> def test_profopt_mac_osx_bug ( self ) : <EOL> if sys . platform == '<STR_LIT:win32>' : <EOL> py . test . skip ( \"<STR_LIT>\" ) <EOL> def entry_point ( argv ) : <EOL> import os <EOL> pid = os . fork ( ) <EOL> if pid : <EOL> os . waitpid ( pid , <NUM_LIT:0> ) <EOL> else : <EOL> os . _exit ( <NUM_LIT:0> ) <EOL> return <NUM_LIT:0> <EOL> from pypy . translator . interactive import Translation <EOL> t = Translation ( entry_point , backend = '<STR_LIT:c>' , standalone = True , profopt = \"<STR_LIT>\" ) <EOL> t . backendopt ( ) <EOL> exe = t . compile ( ) <EOL> t = Translation ( entry_point , backend = '<STR_LIT:c>' , standalone = True , profopt = \"<STR_LIT>\" , <EOL> noprofopt = True ) <EOL> t . backendopt ( ) <EOL> exe = t . compile ( ) <EOL> def test_standalone_large_files ( self ) : <EOL> from pypy . module . posix . test . test_posix2 import need_sparse_files <EOL> need_sparse_files ( ) <EOL> filename = str ( udir . join ( '<STR_LIT>' ) ) <EOL> r4800000000 = r_longlong ( <NUM_LIT> L ) <EOL> def entry_point ( argv ) : <EOL> fd = os . open ( filename , os . O_RDWR | os . O_CREAT , <NUM_LIT:0> <NUM_LIT> ) <EOL> os . lseek ( fd , r4800000000 , <NUM_LIT:0> ) <EOL> os . write ( fd , \"<STR_LIT:$>\" ) <EOL> newpos = os . lseek ( fd , <NUM_LIT:0> , <NUM_LIT:1> ) <EOL> if newpos == r4800000000 + <NUM_LIT:1> : <EOL> print \"<STR_LIT:OK>\" <EOL> else : <EOL> print \"<STR_LIT>\" <EOL> os . close ( fd ) <EOL> return <NUM_LIT:0> <EOL> t = TranslationContext ( self . config ) <EOL> t . buildannotator ( ) . build_types ( entry_point , [ s_list_of_strings ] ) <EOL> t . buildrtyper ( ) . specialize ( ) <EOL> cbuilder = CStandaloneBuilder ( t , entry_point , t . config ) <EOL> cbuilder . generate_source ( ) <EOL> cbuilder . compile ( ) <EOL> data = cbuilder . cmdexec ( '<STR_LIT>' ) <EOL> assert data . strip ( ) == \"<STR_LIT:OK>\" <EOL> def test_separate_files ( self ) : <EOL> fname = py . path . local ( pypydir ) . join ( <EOL> '<STR_LIT>' , '<STR_LIT:c>' , '<STR_LIT:src>' , '<STR_LIT>' ) <EOL> dirname = udir . join ( \"<STR_LIT>\" ) . ensure ( dir = <NUM_LIT:1> ) <EOL> fname2 = dirname . join ( \"<STR_LIT>\" ) <EOL>", "answer": "fname2 . write ( \"\"\"<STR_LIT>\"\"\" )"}, {"prompt": "<s> import os <EOL> from distutils . core import setup <EOL> def read ( fname ) : <EOL> return open ( os . path . join ( os . path . dirname ( __file__ ) , fname ) ) . read ( ) <EOL> setup ( name = '<STR_LIT>' , <EOL> version = '<STR_LIT>' , <EOL> description = '<STR_LIT>' , <EOL> author = '<STR_LIT>' , <EOL>", "answer": "author_email = '<STR_LIT>' ,"}, {"prompt": "<s> from mox3 import mox <EOL> from neutronclient . common import exceptions <EOL> from neutronclient . tests . unit import test_cli20 as neutron_test_cli20 <EOL> import requests <EOL> from gbpclient . gbp import v2_0 as gbpV2_0 <EOL> from gbpclient import gbpshell <EOL> from gbpclient . v2_0 import client as gbpclient <EOL> API_VERSION = neutron_test_cli20 . API_VERSION <EOL> FORMAT = neutron_test_cli20 . FORMAT <EOL> TOKEN = neutron_test_cli20 . TOKEN <EOL> ENDURL = neutron_test_cli20 . ENDURL <EOL> capture_std_streams = neutron_test_cli20 . capture_std_streams <EOL> end_url = neutron_test_cli20 . end_url <EOL> class FakeStdout ( neutron_test_cli20 . FakeStdout ) : <EOL> pass <EOL> class MyResp ( neutron_test_cli20 . MyResp ) : <EOL> pass <EOL> class MyApp ( neutron_test_cli20 . MyApp ) : <EOL> pass <EOL> class MyUrlComparator ( neutron_test_cli20 . MyUrlComparator ) : <EOL>", "answer": "pass"}, {"prompt": "<s> from __future__ import unicode_literals <EOL> import json <EOL> import re <EOL> from . common import InfoExtractor <EOL> from . . utils import int_or_none <EOL> class PodomaticIE ( InfoExtractor ) : <EOL> IE_NAME = '<STR_LIT>' <EOL> _VALID_URL = r'<STR_LIT>' <EOL> _TESTS = [ <EOL> { <EOL> '<STR_LIT:url>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:id>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:title>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : <NUM_LIT> , <EOL> } <EOL> } , <EOL> { <EOL> '<STR_LIT:url>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:id>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : '<STR_LIT>' , <EOL> '<STR_LIT:title>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : <NUM_LIT> , <EOL> } <EOL> } , <EOL> ] <EOL> def _real_extract ( self , url ) : <EOL> mobj = re . match ( self . _VALID_URL , url ) <EOL> video_id = mobj . group ( '<STR_LIT:id>' ) <EOL> channel = mobj . group ( '<STR_LIT>' ) <EOL> json_url = ( ( '<STR_LIT>' + <EOL> '<STR_LIT>' ) % <EOL> ( mobj . group ( '<STR_LIT>' ) , channel , video_id ) ) <EOL> data_json = self . _download_webpage ( <EOL>", "answer": "json_url , video_id , '<STR_LIT>' )"}, {"prompt": "<s> from mlxtend . tf_regressor import TfLinearRegression <EOL>", "answer": "from mlxtend . data import boston_housing_data"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL>", "answer": "from app import db"}, {"prompt": "<s> import os . path <EOL> import hashlib <EOL> import urllib <EOL> class Downloader : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> @ staticmethod <EOL> def request ( url , params = None , on_complete = None ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> params = params or { } <EOL> if params : <EOL> url += \"<STR_LIT:?>\" + urllib . parse . urlencode ( params ) <EOL> return Downloader . download ( url , on_complete = on_complete ) <EOL> @ staticmethod <EOL> def download ( url , checksum = None , on_complete = None ) : <EOL>", "answer": "\"\"\"<STR_LIT>\"\"\""}, {"prompt": "<s> from datetime import time , date , datetime <EOL> from unittest import TestCase <EOL> from django import forms <EOL> from django . conf import settings <EOL> from django . utils . translation import activate , deactivate <EOL> class LocalizedTimeTests ( TestCase ) : <EOL> def setUp ( self ) : <EOL> self . old_TIME_INPUT_FORMATS = settings . TIME_INPUT_FORMATS <EOL> self . old_USE_L10N = settings . USE_L10N <EOL> settings . TIME_INPUT_FORMATS = [ \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> settings . USE_L10N = True <EOL> activate ( '<STR_LIT>' ) <EOL> def tearDown ( self ) : <EOL> settings . TIME_INPUT_FORMATS = self . old_TIME_INPUT_FORMATS <EOL> settings . USE_L10N = self . old_USE_L10N <EOL> deactivate ( ) <EOL> def test_timeField ( self ) : <EOL> \"<STR_LIT>\" <EOL> f = forms . TimeField ( ) <EOL> self . assertRaises ( forms . ValidationError , f . clean , '<STR_LIT>' ) <EOL> result = f . clean ( '<STR_LIT>' ) <EOL> self . assertEqual ( result , time ( <NUM_LIT> , <NUM_LIT:30> , <NUM_LIT:5> ) ) <EOL> text = f . widget . _format_value ( result ) <EOL> self . assertEqual ( text , '<STR_LIT>' ) <EOL> result = f . clean ( '<STR_LIT>' ) <EOL> self . assertEqual ( result , time ( <NUM_LIT> , <NUM_LIT:30> , <NUM_LIT:0> ) ) <EOL> text = f . widget . _format_value ( result ) <EOL> self . assertEqual ( text , \"<STR_LIT>\" ) <EOL> def test_localized_timeField ( self ) : <EOL> \"<STR_LIT>\" <EOL> f = forms . TimeField ( localize = True ) <EOL> self . assertRaises ( forms . ValidationError , f . clean , '<STR_LIT>' ) <EOL> result = f . clean ( '<STR_LIT>' ) <EOL> self . assertEqual ( result , time ( <NUM_LIT> , <NUM_LIT:30> , <NUM_LIT:5> ) ) <EOL>", "answer": "text = f . widget . _format_value ( result )"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import socket <EOL> import sys , os <EOL> sys . path . insert ( <NUM_LIT:0> , os . path . join ( os . path . dirname ( __file__ ) , \"<STR_LIT:..>\" ) ) <EOL> import time <EOL> import datetime <EOL> from splunklib . client import connect <EOL> try : <EOL> from utils import parse <EOL> except ImportError : <EOL> raise Exception ( \"<STR_LIT>\" <EOL> \"<STR_LIT>\" ) <EOL> SPLUNK_HOST = \"<STR_LIT:localhost>\" <EOL> SPLUNK_PORT = <NUM_LIT> <EOL> INGEST_TYPE = [ \"<STR_LIT>\" , \"<STR_LIT>\" , \"<STR_LIT>\" ] <EOL> RULES = { <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : [ \"<STR_LIT>\" ] , <EOL> '<STR_LIT:default>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : \"<STR_LIT>\" % INGEST_TYPE <EOL> } , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT>' : [ \"<STR_LIT>\" ] , <EOL> '<STR_LIT:default>' : \"<STR_LIT:127.0.0.1>\" , <EOL> '<STR_LIT>' : \"<STR_LIT>\" <EOL> } , <EOL> '<STR_LIT:type>' : { <EOL> '<STR_LIT>' : [ \"<STR_LIT>\" ] , <EOL> '<STR_LIT:default>' : SPLUNK_PORT , <EOL> '<STR_LIT>' : \"<STR_LIT>\" % SPLUNK_PORT <EOL> } , <EOL> } <EOL> def feed_index ( service , opts ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> indexname = opts . args [ <NUM_LIT:0> ] <EOL> itype = opts . kwargs [ '<STR_LIT>' ] <EOL> try : <EOL> index = service . indexes [ indexname ] <EOL> except KeyError : <EOL> print \"<STR_LIT>\" % indexname <EOL> return <EOL> if itype in [ \"<STR_LIT>\" , \"<STR_LIT>\" ] : <EOL> stream = index . attach ( ) <EOL> else : <EOL> input_host = opts . kwargs . get ( \"<STR_LIT>\" , SPLUNK_HOST ) <EOL> input_port = int ( opts . kwargs . get ( \"<STR_LIT>\" , SPLUNK_PORT ) ) <EOL> input_name = \"<STR_LIT>\" % ( input_port ) <EOL> if input_name not in service . inputs . list ( ) : <EOL> service . inputs . create ( \"<STR_LIT>\" , input_port , index = indexname ) <EOL> ingest = socket . socket ( socket . AF_INET , socket . SOCK_STREAM ) <EOL> ingest . connect ( ( input_host , input_port ) ) <EOL> count = <NUM_LIT:0> <EOL> lastevent = \"<STR_LIT>\" <EOL> try : <EOL> for i in range ( <NUM_LIT:0> , <NUM_LIT:10> ) : <EOL> for j in range ( <NUM_LIT:0> , <NUM_LIT> ) : <EOL> lastevent = \"<STR_LIT>\" % ( datetime . datetime . now ( ) . isoformat ( ) , i , j ) <EOL> if itype == \"<STR_LIT>\" : <EOL> stream . write ( lastevent + \"<STR_LIT:\\n>\" ) <EOL> elif itype == \"<STR_LIT>\" : <EOL> index . submit ( lastevent + \"<STR_LIT:\\n>\" ) <EOL> else : <EOL> ingest . send ( lastevent + \"<STR_LIT:\\n>\" ) <EOL> count = count + <NUM_LIT:1> <EOL> print \"<STR_LIT>\" % count <EOL> time . sleep ( <NUM_LIT:1> ) <EOL> except KeyboardInterrupt : <EOL> print \"<STR_LIT>\" <EOL>", "answer": "print lastevent"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> from __future__ import print_function , division <EOL> _doctest_depends_on = { '<STR_LIT>' : ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) , '<STR_LIT>' : ( '<STR_LIT>' , ) } <EOL> import sys <EOL> import os <EOL> import shutil <EOL> import tempfile <EOL> from subprocess import STDOUT , CalledProcessError , check_output <EOL> from string import Template <EOL> from sympy . core . cache import cacheit <EOL> from sympy . core . compatibility import range , iterable <EOL> from sympy . core . function import Lambda <EOL> from sympy . core . relational import Eq <EOL> from sympy . core . symbol import Dummy , Symbol <EOL> from sympy . tensor . indexed import Idx , IndexedBase <EOL> from sympy . utilities . codegen import ( make_routine , get_code_generator , <EOL> OutputArgument , InOutArgument , InputArgument , <EOL> CodeGenArgumentListError , Result , ResultBase , CCodeGen ) <EOL> from sympy . utilities . lambdify import implemented_function <EOL> from sympy . utilities . decorator import doctest_depends_on <EOL> class CodeWrapError ( Exception ) : <EOL> pass <EOL> class CodeWrapper ( object ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> _filename = \"<STR_LIT>\" <EOL> _module_basename = \"<STR_LIT>\" <EOL> _module_counter = <NUM_LIT:0> <EOL> @ property <EOL> def filename ( self ) : <EOL> return \"<STR_LIT>\" % ( self . _filename , CodeWrapper . _module_counter ) <EOL> @ property <EOL> def module_name ( self ) : <EOL> return \"<STR_LIT>\" % ( self . _module_basename , CodeWrapper . _module_counter ) <EOL> def __init__ ( self , generator , filepath = None , flags = [ ] , verbose = False ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> self . generator = generator <EOL> self . filepath = filepath <EOL> self . flags = flags <EOL> self . quiet = not verbose <EOL> @ property <EOL> def include_header ( self ) : <EOL> return bool ( self . filepath ) <EOL> @ property <EOL> def include_empty ( self ) : <EOL> return bool ( self . filepath ) <EOL> def _generate_code ( self , main_routine , routines ) : <EOL> routines . append ( main_routine ) <EOL> self . generator . write ( <EOL> routines , self . filename , True , self . include_header , <EOL> self . include_empty ) <EOL> def wrap_code ( self , routine , helpers = [ ] ) : <EOL> workdir = self . filepath or tempfile . mkdtemp ( \"<STR_LIT>\" ) <EOL> if not os . access ( workdir , os . F_OK ) : <EOL> os . mkdir ( workdir ) <EOL> oldwork = os . getcwd ( ) <EOL> os . chdir ( workdir ) <EOL> try : <EOL> sys . path . append ( workdir ) <EOL> self . _generate_code ( routine , helpers ) <EOL> self . _prepare_files ( routine ) <EOL> self . _process_files ( routine ) <EOL> mod = __import__ ( self . module_name ) <EOL> finally : <EOL> sys . path . remove ( workdir ) <EOL> CodeWrapper . _module_counter += <NUM_LIT:1> <EOL> os . chdir ( oldwork ) <EOL> if not self . filepath : <EOL> try : <EOL> shutil . rmtree ( workdir ) <EOL> except OSError : <EOL> pass <EOL> return self . _get_wrapped_function ( mod , routine . name ) <EOL> def _process_files ( self , routine ) : <EOL> command = self . command <EOL> command . extend ( self . flags ) <EOL> try : <EOL> retoutput = check_output ( command , stderr = STDOUT ) <EOL> except CalledProcessError as e : <EOL> raise CodeWrapError ( <EOL> \"<STR_LIT>\" % ( <EOL> \"<STR_LIT:U+0020>\" . join ( command ) , e . output . decode ( ) ) ) <EOL> if not self . quiet : <EOL> print ( retoutput ) <EOL> class DummyWrapper ( CodeWrapper ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> template = \"\"\"<STR_LIT>\"\"\" <EOL> def _prepare_files ( self , routine ) : <EOL> return <EOL> def _generate_code ( self , routine , helpers ) : <EOL> with open ( '<STR_LIT>' % self . module_name , '<STR_LIT:w>' ) as f : <EOL> printed = \"<STR_LIT:U+002CU+0020>\" . join ( <EOL> [ str ( res . expr ) for res in routine . result_variables ] ) <EOL> args = filter ( lambda x : not isinstance ( <EOL> x , OutputArgument ) , routine . arguments ) <EOL> retvals = [ ] <EOL> for val in routine . result_variables : <EOL> if isinstance ( val , Result ) : <EOL> retvals . append ( '<STR_LIT>' ) <EOL> else : <EOL> retvals . append ( val . result_var ) <EOL> print ( DummyWrapper . template % { <EOL> '<STR_LIT:name>' : routine . name , <EOL> '<STR_LIT>' : printed , <EOL> '<STR_LIT:args>' : \"<STR_LIT:U+002CU+0020>\" . join ( [ str ( a . name ) for a in args ] ) , <EOL> '<STR_LIT>' : \"<STR_LIT:U+002CU+0020>\" . join ( [ str ( val ) for val in retvals ] ) <EOL> } , end = \"<STR_LIT>\" , file = f ) <EOL> def _process_files ( self , routine ) : <EOL> return <EOL> @ classmethod <EOL> def _get_wrapped_function ( cls , mod , name ) : <EOL> return getattr ( mod , name ) <EOL> class CythonCodeWrapper ( CodeWrapper ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> setup_template = ( <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT>\" <EOL> \"<STR_LIT:\\n>\" <EOL>", "answer": "\"<STR_LIT>\""}, {"prompt": "<s> from . bundletypes import Coords , Tracks , Listfile , Rotfile , Bundle <EOL> from . sfminittypes import ( read_rot_file , write_rot_file , <EOL> read_trans_soln_file , write_trans_soln_file , <EOL> read_edge_weight_file , write_edge_weight_file , <EOL>", "answer": "read_EGs_file , write_EGs_file )"}, {"prompt": "<s> from atom . api import Bool , Typed , ForwardTyped , Unicode , observe <EOL> from enaml . core . declarative import d_ <EOL> from . action import Action <EOL>", "answer": "from . action_group import ActionGroup"}, {"prompt": "<s> import httplib <EOL> import json <EOL> import unittest <EOL> from swagger import Swagger <EOL> class SwaggerTestCast ( unittest . TestCase ) : <EOL> def setUp ( self ) : <EOL> self . client = Swagger . load ( '<STR_LIT>' ) <EOL> self . data = { <EOL> '<STR_LIT:id>' : <NUM_LIT:0> , <EOL> '<STR_LIT>' : { <EOL> '<STR_LIT:id>' : <NUM_LIT:0> , <EOL> '<STR_LIT:name>' : '<STR_LIT:string>' , <EOL> } , <EOL> '<STR_LIT:name>' : '<STR_LIT>' , <EOL> '<STR_LIT>' : [ <EOL> '<STR_LIT:string>' , <EOL> ] , <EOL> '<STR_LIT>' : [ <EOL> { <EOL> '<STR_LIT:id>' : <NUM_LIT:0> , <EOL> '<STR_LIT:name>' : '<STR_LIT:string>' , <EOL> } <EOL> ] , <EOL> '<STR_LIT:status>' : '<STR_LIT>' , <EOL> } <EOL> @ property <EOL> def pet ( self ) : <EOL> data = json . dumps ( self . data ) <EOL> res = self . client . post ( '<STR_LIT>' , body = data , auth = '<STR_LIT>' ) <EOL> return res . json ( ) <EOL> def test_swagger_version ( self ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> self . assertEqual ( self . client . Version , '<STR_LIT>' ) <EOL> def test_set_headers ( self ) : <EOL> pass <EOL> def test_swagger_default_scheme ( self ) : <EOL> self . assertEqual ( self . client . DefaultScheme , '<STR_LIT:http>' ) <EOL> def test_create_pet_endpoint ( self ) : <EOL> data = json . dumps ( self . data ) <EOL>", "answer": "expected_url = '<STR_LIT>'"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import time <EOL> import random <EOL> from collections import defaultdict , deque <EOL> from itertools import chain <EOL> from twisted . internet import defer , reactor , task <EOL> try : <EOL> from lxml import etree <EOL> except ImportError : <EOL> etree = None <EOL> from nagcat import log , monitor_api , query , test , trend <EOL> from nagcat . runnable import Runnable , RunnableGroup <EOL> class SchedulerPage ( monitor_api . XMLPage ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , scheduler ) : <EOL> super ( SchedulerPage , self ) . __init__ ( ) <EOL> self . scheduler = scheduler <EOL> def xml ( self , request ) : <EOL> sch = etree . Element ( \"<STR_LIT>\" , version = \"<STR_LIT:1.0>\" ) <EOL> data = self . scheduler . stats ( ) <EOL> lat = etree . SubElement ( sch , \"<STR_LIT>\" , <EOL> period = str ( data [ '<STR_LIT>' ] [ '<STR_LIT>' ] ) ) <EOL> etree . SubElement ( lat , \"<STR_LIT>\" ) . text = \"<STR_LIT>\" % data [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> etree . SubElement ( lat , \"<STR_LIT>\" ) . text = \"<STR_LIT>\" % data [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> etree . SubElement ( lat , \"<STR_LIT>\" ) . text = \"<STR_LIT>\" % data [ '<STR_LIT>' ] [ '<STR_LIT>' ] <EOL> tasks = etree . SubElement ( sch , '<STR_LIT>' , <EOL> count = str ( data [ '<STR_LIT>' ] [ '<STR_LIT:count>' ] ) ) <EOL> for task_type in data [ '<STR_LIT>' ] : <EOL> if task_type == \"<STR_LIT:count>\" : <EOL> continue <EOL> task_node = etree . SubElement ( tasks , task_type , <EOL> count = str ( data [ '<STR_LIT>' ] [ task_type ] [ '<STR_LIT:count>' ] ) ) <EOL> for sub_type in data [ '<STR_LIT>' ] [ task_type ] : <EOL> if sub_type == \"<STR_LIT:count>\" : <EOL> continue <EOL> etree . SubElement ( task_node , task_type , type = sub_type , <EOL> count = str ( data [ '<STR_LIT>' ] [ task_type ] [ sub_type ] [ '<STR_LIT:count>' ] ) ) <EOL> return sch <EOL> class Scheduler ( object ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> trend = None <EOL> monitor = None <EOL> def __init__ ( self , <EOL> config = None , <EOL> rradir = None , <EOL> rrdcache = None , <EOL> monitor_port = None , <EOL> default_timeout = <NUM_LIT:15> , <EOL> ** kwargs ) : <EOL> self . _registered = set ( ) <EOL> self . _group_index = defaultdict ( set ) <EOL> self . _startup = True <EOL> self . _shutdown = None <EOL> self . _latency = deque ( [ <NUM_LIT:0> ] , <NUM_LIT> ) <EOL> self . _latency_call = None <EOL> self . _task_stats = { <EOL> '<STR_LIT:count>' : <NUM_LIT:0> , <EOL> '<STR_LIT>' : { '<STR_LIT:count>' : <NUM_LIT:0> } , <EOL> '<STR_LIT>' : { '<STR_LIT:count>' : <NUM_LIT:0> } , <EOL> '<STR_LIT>' : { '<STR_LIT:count>' : <NUM_LIT:0> } , <EOL> } <EOL> self . default_timeout = default_timeout <EOL> if monitor_port : <EOL> self . _monitor_port = monitor_port <EOL> self . monitor = monitor_api . MonitorSite ( ) <EOL> page = SchedulerPage ( self ) <EOL> self . monitor . includeChild ( \"<STR_LIT>\" , page ) <EOL> if rradir : <EOL> self . trend = trend . TrendMaster ( rradir , rrdcache ) <EOL> self . query = query . QueryManager ( self ) <EOL> self . build_tests ( config , ** kwargs ) <EOL> def build_tests ( self , config , ** kwargs ) : <EOL> raise Exception ( \"<STR_LIT>\" ) <EOL> def new_test ( self , config ) : <EOL> new = test . Test ( self , config ) <EOL> self . register ( new ) <EOL> if self . trend : <EOL> self . trend . setup_test_trending ( new , config ) <EOL> return new <EOL> def new_query ( self , config , qcls = None ) : <EOL> return self . query . new_query ( config , qcls ) <EOL> def register ( self , task ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> assert self . _startup <EOL> assert task not in self . _group_index <EOL> assert isinstance ( task , Runnable ) <EOL> log . trace ( \"<STR_LIT>\" , task ) <EOL> task_deps = task . getAllDependencies ( ) <EOL> all_groups = chain . from_iterable ( self . _group_index [ d ] <EOL> for d in task_deps ) <EOL> groups = set ( g for g in all_groups if g . repeat == task . repeat ) <EOL> update_index = set ( task_deps ) <EOL> update_index . add ( task ) <EOL> if not groups : <EOL> group = RunnableGroup ( [ task ] , task . repeat ) <EOL> self . _update_stats ( group ) <EOL> self . _registered . add ( group ) <EOL> log . trace ( \"<STR_LIT>\" , group ) <EOL> else : <EOL> group = groups . pop ( ) <EOL> group . addDependency ( task ) <EOL> log . trace ( \"<STR_LIT>\" , group ) <EOL> for extra_group in groups : <EOL> self . _update_stats ( extra_group , - <NUM_LIT:1> ) <EOL> self . _registered . remove ( extra_group ) <EOL> group . addDependencies ( extra_group ) <EOL> update_index . update ( extra_group . getAllDependencies ( ) ) <EOL>", "answer": "log . trace ( \"<STR_LIT>\" , extra_group )"}, {"prompt": "<s> from SimpleCV import * <EOL> from CardUtil import * <EOL> from PlayingCardFactory import * <EOL> import numpy as np <EOL> def GetParallelSets ( line_fs , parallel_thresh = <NUM_LIT> ) : <EOL> result = [ ] <EOL> sz = len ( line_fs ) <EOL> for i in range ( <NUM_LIT:0> , sz ) : <EOL> for j in range ( <NUM_LIT:0> , sz ) : <EOL> if ( j <= i ) : <EOL> result . append ( np . Inf ) <EOL> else : <EOL> result . append ( np . abs ( line_fs [ i ] . cross ( line_fs [ j ] ) ) ) <EOL> result = np . array ( result ) <EOL> result = result . reshape ( sz , sz ) <EOL> l1 , l2 = np . where ( result < parallel_thresh ) <EOL> idxs = zip ( l1 , l2 ) <EOL> retVal = [ ] <EOL> for idx in idxs : <EOL> retVal . append ( ( line_fs [ idx [ <NUM_LIT:0> ] ] , line_fs [ idx [ <NUM_LIT:1> ] ] ) ) <EOL> return retVal <EOL> pcf = PlayingCardFactory ( ) <EOL> data , labels = GetFullDataSet ( ) <EOL> print len ( data ) <EOL> datapoints = zip ( data , labels ) <EOL> datapoints = datapoints [ <NUM_LIT:0> : <NUM_LIT:200> ] <EOL> result = [ ] <EOL> passing = <NUM_LIT:0> <EOL> for d in datapoints : <EOL> img = d [ <NUM_LIT:0> ] <EOL> label = d [ <NUM_LIT:1> ] <EOL> img = img . edges ( ) <EOL> l = img . findLines ( threshold = <NUM_LIT:10> ) <EOL> if ( l is not None ) : <EOL> v = <NUM_LIT> <EOL> h = <NUM_LIT:30> <EOL> vl = l . filter ( np . abs ( l . angle ( ) ) > v ) <EOL> vl = vl . filter ( vl . length ( ) > img . height / <NUM_LIT:6> ) <EOL>", "answer": "hl = l . filter ( np . abs ( l . angle ( ) ) < h )"}, {"prompt": "<s> from __future__ import unicode_literals <EOL> from django . contrib . auth . models import AnonymousUser <EOL> from django . db . models import Q <EOL> from djblets . util . templatetags . djblets_utils import user_displayname <EOL> from haystack import indexes <EOL> from reviewboard . reviews . models import ReviewRequest <EOL> from reviewboard . search . indexes import BaseSearchIndex <EOL> class ReviewRequestIndex ( BaseSearchIndex , indexes . Indexable ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> model = ReviewRequest <EOL> local_site_attr = '<STR_LIT>' <EOL> review_request_id = indexes . IntegerField ( model_attr = '<STR_LIT>' ) <EOL> summary = indexes . CharField ( model_attr = '<STR_LIT>' ) <EOL>", "answer": "description = indexes . CharField ( model_attr = '<STR_LIT:description>' )"}, {"prompt": "<s> from django . conf . urls import patterns <EOL> from django . conf . urls import url <EOL> from disaster_recovery . backups import views <EOL> urlpatterns = patterns ( <EOL> '<STR_LIT>' , <EOL> url ( r'<STR_LIT>' , views . IndexView . as_view ( ) , name = '<STR_LIT:index>' ) , <EOL>", "answer": "url ( r'<STR_LIT>' , views . DetailView . as_view ( ) , name = '<STR_LIT>' ) ,"}, {"prompt": "<s> from smsapi . client import SmsAPI <EOL> api = SmsAPI ( ) <EOL> api . set_username ( '<STR_LIT>' ) <EOL> api . set_password ( '<STR_LIT>' ) <EOL> api . service ( '<STR_LIT>' ) . action ( '<STR_LIT>' ) <EOL> api . set_content ( '<STR_LIT>' ) <EOL> api . set_to ( '<STR_LIT>' ) <EOL> result = api . execute ( ) <EOL>", "answer": "for r in result :"}, {"prompt": "<s> import unittest <EOL> import time <EOL> import zmq <EOL> from zmq . eventloop . ioloop import IOLoop <EOL> from zmq . eventloop . zmqstream import ZMQStream <EOL> from spyder . core . constants import ZMQ_SPYDER_MGMT_WORKER <EOL> from spyder . core . constants import ZMQ_SPYDER_MGMT_WORKER_QUIT <EOL>", "answer": "from spyder . core . constants import ZMQ_SPYDER_MGMT_WORKER_QUIT_ACK"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import datetime as dt <EOL> from flask import Flask <EOL> from flask . ext import restful <EOL> from webargs import fields , validate <EOL> from webargs . flaskparser import use_args , use_kwargs , parser <EOL> app = Flask ( __name__ ) <EOL> api = restful . Api ( app ) <EOL> class IndexResource ( restful . Resource ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> hello_args = { <EOL> '<STR_LIT:name>' : fields . Str ( missing = '<STR_LIT>' ) <EOL> } <EOL> @ use_args ( hello_args ) <EOL> def get ( self , args ) : <EOL> return { '<STR_LIT:message>' : '<STR_LIT>' . format ( args [ '<STR_LIT:name>' ] ) } <EOL> class AddResource ( restful . Resource ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> add_args = { <EOL> '<STR_LIT:x>' : fields . Float ( required = True ) , <EOL> '<STR_LIT:y>' : fields . Float ( required = True ) , <EOL> } <EOL> @ use_kwargs ( add_args ) <EOL> def post ( self , x , y ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> return { '<STR_LIT:result>' : x + y } <EOL> class DateAddResource ( restful . Resource ) : <EOL> dateadd_args = { <EOL> '<STR_LIT:value>' : fields . DateTime ( required = False ) , <EOL> '<STR_LIT>' : fields . Int ( required = True , validate = validate . Range ( min = <NUM_LIT:1> ) ) , <EOL> '<STR_LIT>' : fields . Str ( missing = '<STR_LIT>' , validate = validate . OneOf ( [ '<STR_LIT>' , '<STR_LIT>' ] ) ) <EOL> } <EOL> @ use_kwargs ( dateadd_args ) <EOL> def post ( self , value , addend , unit ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> value = value or dt . datetime . utcnow ( ) <EOL> if unit == '<STR_LIT>' : <EOL> delta = dt . timedelta ( minutes = addend ) <EOL> else : <EOL> delta = dt . timedelta ( days = addend ) <EOL> result = value + delta <EOL> return { '<STR_LIT:result>' : result . isoformat ( ) } <EOL> @ parser . error_handler <EOL> def handle_request_parsing_error ( err ) : <EOL>", "answer": "\"\"\"<STR_LIT>\"\"\""}, {"prompt": "<s> from __future__ import print_function <EOL> import numba . unittest_support as unittest <EOL> from numba import jit <EOL> class TestFuncInterface ( unittest . TestCase ) : <EOL> def test_jit_function_docstring ( self ) : <EOL> def add ( x , y ) : <EOL> '''<STR_LIT>''' <EOL> return x + y <EOL> c_add = jit ( add ) <EOL> self . assertEqual ( c_add . __doc__ , '<STR_LIT>' ) <EOL> def test_jit_function_name ( self ) : <EOL> def add ( x , y ) : <EOL> return x + y <EOL> c_add = jit ( add ) <EOL> self . assertEqual ( c_add . __name__ , '<STR_LIT>' ) <EOL> def test_jit_function_module ( self ) : <EOL> def add ( x , y ) : <EOL> return x + y <EOL> c_add = jit ( add ) <EOL> self . assertEqual ( c_add . __module__ , add . __module__ ) <EOL> def test_jit_function_code_object ( self ) : <EOL> def add ( x , y ) : <EOL> return x + y <EOL>", "answer": "c_add = jit ( add )"}, {"prompt": "<s> \"\"\"<STR_LIT>\"\"\" <EOL> import socket <EOL>", "answer": "class CachedDnsName ( object ) :"}, {"prompt": "<s> import os <EOL> import re <EOL> import platform <EOL> import shutil <EOL> from xmlrpc . client import Fault <EOL> from string import Template <EOL> from datetime import ( datetime , timedelta ) <EOL> import configparser <EOL> from wordpress_xmlrpc import ( Client , <EOL> WordPressPost , WordPressPage , WordPressTerm , WordPressMedia ) <EOL> from wordpress_xmlrpc . exceptions import InvalidCredentialsError <EOL> from wordpress_xmlrpc . methods . taxonomies import ( GetTerms ) <EOL> from pkg_resources import ( resource_filename , resource_string ) <EOL> from rookout import slog <EOL> from rookout . base import ( list_dir , read_file , write_file ) <EOL> from rookout . conf import PYConf <EOL> class Conf ( object ) : <EOL> TPL_FILE = '<STR_LIT>' <EOL> PRE_NAME = '<STR_LIT:_>' if platform . system ( ) == '<STR_LIT>' else '<STR_LIT:.>' <EOL> INI_FILE = PRE_NAME + '<STR_LIT>' <EOL> CACHE_FILE = PRE_NAME + '<STR_LIT>' <EOL> ARTICLE_TYPES = ( '<STR_LIT>' , '<STR_LIT>' , '<STR_LIT>' ) <EOL> def __init__ ( self , conffile ) : <EOL> self . conffile = conffile <EOL> self . ini = configparser . ConfigParser ( ) <EOL> self . cache = None <EOL> def init ( self , workdir ) : <EOL> if os . path . exists ( self . conffile ) : <EOL> self . read_from_file ( ) <EOL> return True <EOL> tplstr = read_file ( resource_filename ( '<STR_LIT>' , Conf . TPL_FILE ) ) <EOL> inistr = Template ( tplstr ) . substitute ( { <EOL> '<STR_LIT>' : Conf . CACHE_FILE , <EOL> '<STR_LIT>' : workdir , <EOL> } ) <EOL> self . save_to_file ( inistr ) <EOL> self . read_from_file ( ) <EOL> slog . info ( '<STR_LIT>' % self . conffile ) <EOL> return False <EOL> def init_cache ( self , site_name ) : <EOL> self . __site_section = site_name <EOL> self . cache = TermCache ( self . get_site ( '<STR_LIT>' ) ) <EOL> self . cache . init ( ) <EOL> def __missing__ ( self , key ) : <EOL> return None <EOL> def __getattr__ ( self , name ) : <EOL> return self . ini [ name ] <EOL> def get ( self , section , option ) : <EOL> return self . ini . get ( section , option , raw = True , fallback = None ) <EOL> def get_site ( self , option ) : <EOL> return self . get ( self . __site_section , option ) <EOL> def get_user ( self ) : <EOL> return self . get_site ( '<STR_LIT:user>' ) <EOL> def get_password ( self ) : <EOL> return self . get_site ( '<STR_LIT:password>' ) <EOL> def get_url ( self , only_site = False ) : <EOL> url = self . get_site ( '<STR_LIT:url>' ) <EOL> site = None <EOL> if url . endswith ( '<STR_LIT>' ) : <EOL> site = url [ : - <NUM_LIT:11> ] <EOL> elif url . endswith ( '<STR_LIT:/>' ) : <EOL> site = url [ : - <NUM_LIT:1> ] <EOL> url = url + '<STR_LIT>' <EOL> else : <EOL> site = url <EOL> url = url + '<STR_LIT>' <EOL> if only_site : <EOL> return site <EOL> return url <EOL> def save_to_file ( self , inistr ) : <EOL> write_file ( self . conffile , inistr ) <EOL> def read_from_file ( self ) : <EOL> self . ini . read ( self . conffile ) <EOL> def is_article ( self , posttype ) : <EOL> return posttype in Conf . ARTICLE_TYPES <EOL> def get_draft ( self , name ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> draftname = ( self . get_site ( '<STR_LIT>' ) % str ( name ) ) + self . get_site ( '<STR_LIT>' ) <EOL> return self . get_work_path ( '<STR_LIT>' , draftname ) , draftname <EOL> def get_new_draft ( self , name = None ) : <EOL> draftdir = self . get_work_path ( '<STR_LIT>' ) <EOL> draftnames = list ( list_dir ( draftdir ) ) <EOL> draftfile , draftname = None , None <EOL> if name : <EOL> draftfile , draftname = self . get_draft ( name ) <EOL> if draftname in draftnames : <EOL> raise WPError ( '<STR_LIT>' % <EOL> draftname ) <EOL> else : <EOL> name = <NUM_LIT:1> <EOL> draftfile , draftname = self . get_draft ( name ) <EOL> while os . path . exists ( draftfile ) : <EOL> name += <NUM_LIT:1> <EOL> draftfile , draftname = self . get_draft ( name ) <EOL> return draftfile , draftname <EOL> def get_article ( self , name , posttype ) : <EOL> postname = name + self . get_site ( '<STR_LIT>' ) <EOL> if self . is_article ( posttype ) : <EOL> return self . get_work_path ( posttype , postname ) , postname <EOL> return None , None <EOL> def get_path ( self , name , * path ) : <EOL> workdir = os . path . join ( self . get_site ( '<STR_LIT>' ) , name ) <EOL> if path : <EOL> return os . path . abspath ( os . path . join ( workdir , * path ) ) <EOL> return workdir <EOL> def get_work_path ( self , dirname , * path ) : <EOL> workpath = self . get_path ( self . get_site ( dirname ) ) <EOL> if not os . path . exists ( workpath ) : <EOL> os . makedirs ( workpath ) <EOL> if path : <EOL> return os . path . join ( workpath , * path ) <EOL> return workpath <EOL> def get_mdfiles ( self , posttype ) : <EOL> workpath = self . get_work_path ( posttype ) <EOL> for afile in os . listdir ( workpath ) : <EOL> if afile . endswith ( self . get_site ( '<STR_LIT>' ) ) : <EOL> name = afile . split ( '<STR_LIT:.>' ) [ <NUM_LIT:0> ] <EOL> filepath = os . path . join ( workpath , afile ) <EOL> yield ( posttype , name , filepath ) <EOL> class Action ( object ) : <EOL> def __init__ ( self , gconf , gtermcache , gargs , gparser ) : <EOL> self . conf = gconf <EOL> self . conf . site = gargs . site <EOL> self . cache = gtermcache <EOL> self . args = gargs <EOL> self . parser = gparser <EOL> self . _wp = None <EOL> def get_postid ( self , as_list = False ) : <EOL> if not self . args . query : <EOL> return None <EOL> if as_list : <EOL> postids = [ ] <EOL> for postid in self . args . query : <EOL> match = re . match ( r'<STR_LIT>' , postid ) <EOL> if match : <EOL> a = int ( match . group ( <NUM_LIT:1> ) ) <EOL> b = int ( match . group ( <NUM_LIT:2> ) ) <EOL> for i in range ( a , b + <NUM_LIT:1> ) : <EOL> postids . append ( str ( i ) ) <EOL> else : <EOL> postids . append ( postid ) <EOL> return postids <EOL> return self . args . query [ <NUM_LIT:0> ] <EOL> def get_dict_from_query ( self , query ) : <EOL> if query : <EOL> d = { } <EOL> for v in query : <EOL> value = v . split ( '<STR_LIT:=>' ) <EOL> d [ value [ <NUM_LIT:0> ] ] = value [ <NUM_LIT:1> ] <EOL> return d <EOL> return None <EOL> def get_term_query ( self ) : <EOL> typ = self . args . type <EOL> q = self . args . query <EOL> query = [ ] <EOL> if typ == '<STR_LIT>' : <EOL> query = q <EOL> else : <EOL> if typ == '<STR_LIT>' : <EOL> typ = '<STR_LIT>' <EOL> query . append ( typ ) <EOL> if q and len ( q ) > <NUM_LIT:0> : <EOL> query . append ( q [ <NUM_LIT:0> ] ) <EOL> return query <EOL> def get_terms_from_wp ( self , query , force = False ) : <EOL> if not query or len ( query ) == <NUM_LIT:0> : <EOL> slog . error ( '<STR_LIT>' <EOL> '<STR_LIT>' ) <EOL> return None <EOL> taxname = query [ <NUM_LIT:0> ] <EOL> slug = query [ <NUM_LIT:1> ] if len ( query ) > <NUM_LIT:1> else None <EOL> terms = self . cache [ taxname ] <EOL> if not terms or force : <EOL> results = self . wpcall ( GetTerms ( taxname ) ) <EOL> if results : <EOL> self . cache . save_terms ( results , taxname ) <EOL> if terms and slug : <EOL> return terms [ slug ] <EOL> return terms <EOL> def print_result ( self , result ) : <EOL> if isinstance ( result , WordPressTerm ) : <EOL> slog . info ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' , <EOL> result . id , result . group , <EOL> result . taxonomy_id , result . name , result . slug , <EOL> result . parent , result . count ) <EOL> elif isinstance ( result , WordPressPost ) : <EOL> slog . info ( '<STR_LIT>' <EOL> '<STR_LIT>' , <EOL> result . id , str ( result . date ) , str ( result . date_modified ) , <EOL> result . slug , result . title , <EOL> result . post_status , result . post_type ) <EOL> elif isinstance ( result , WordPressMedia ) : <EOL> slog . info ( '<STR_LIT>' <EOL> '<STR_LIT>' <EOL> '<STR_LIT>' , <EOL> result . id , result . parent , result . title , <EOL> result . description , result . caption , str ( result . date_created ) , <EOL> result . link , <EOL> result . thumbnail , result . metadata ) <EOL> else : <EOL> slog . info ( result ) <EOL> def print_results ( self , results ) : <EOL> if isinstance ( results , list ) : <EOL> for result in results : <EOL> self . print_result ( result ) <EOL> elif isinstance ( results , dict ) : <EOL> for k , v in results . items ( ) : <EOL> slog . info ( '<STR_LIT>' % ( k , str ( v ) ) ) <EOL> else : <EOL> self . print_result ( results ) <EOL> def get_datetime ( self , datestring ) : <EOL> dt = datetime . strptime ( datestring , '<STR_LIT>' ) <EOL> return dt - timedelta ( hours = <NUM_LIT:8> ) <EOL> def wpcall ( self , method ) : <EOL> if not self . _wp : <EOL> self . _wp = Client ( self . conf . get_url ( ) , <EOL> self . conf . get_user ( ) , <EOL> self . conf . get_password ( ) ) <EOL> try : <EOL> results = self . _wp . call ( method ) <EOL> except InvalidCredentialsError as e : <EOL> slog . error ( e ) <EOL> return None <EOL> except Fault as e : <EOL> slog . error ( e ) <EOL> return None <EOL> return results <EOL> def go ( self ) : <EOL> pass <EOL> def build ( self ) : <EOL> if self . args . type : <EOL> self . go ( ) <EOL> elif self . parser : <EOL> self . parser . print_help ( ) <EOL> class TermCache ( PYConf ) : <EOL> \"\"\"<STR_LIT>\"\"\" <EOL> def __init__ ( self , filepath ) : <EOL> self . cachefile = filepath <EOL> def init ( self ) : <EOL> if os . path . exists ( self . cachefile ) : <EOL> super ( ) . read_from_file ( self . cachefile ) <EOL> def save_to_file ( self ) : <EOL> super ( ) . save_to_file ( self . cachefile ) <EOL> def save_terms ( self , terms , taxname ) : <EOL> termdict = PYConf ( ) <EOL> for term in terms : <EOL> self . save_term ( term , taxname , termdict ) <EOL> self [ taxname ] = termdict <EOL> self . save_to_file ( ) <EOL> def save_term ( self , term , taxname , termdict = None ) : <EOL> if termdict == None : <EOL> termdict = self [ taxname ] <EOL> if termdict == None : <EOL> termdict = PYConf ( ) <EOL> self [ taxname ] = termdict <EOL> termdict [ term . slug ] = PYConf ( { <EOL> '<STR_LIT:id>' : term . id , <EOL> '<STR_LIT>' : term . group , <EOL> '<STR_LIT>' : term . taxonomy , <EOL> '<STR_LIT>' : term . taxonomy_id , <EOL> '<STR_LIT:name>' : term . name , <EOL> '<STR_LIT>' : term . slug , <EOL> '<STR_LIT:description>' : term . description , <EOL>", "answer": "'<STR_LIT>' : term . parent ,"}, {"prompt": "<s> from . client import UberClient , UberException , UberLocationNotFound <EOL> from . models import * <EOL>", "answer": "from . geolocation import geolocate , GeolocationExcetion "}]